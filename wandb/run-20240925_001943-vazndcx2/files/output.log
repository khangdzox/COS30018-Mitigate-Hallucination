

  0%|▎                                                                                                                                                                 | 1/500 [00:42<5:53:34, 42.51s/it]
{'loss': 1.9488, 'grad_norm': 2.207639455795288, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.0}


  1%|▉                                                                                                                                                                 | 3/500 [02:01<5:31:03, 39.97s/it]

  1%|█▎                                                                                                                                                                | 4/500 [02:40<5:30:13, 39.95s/it]

  1%|█▌                                                                                                                                                                | 5/500 [03:19<5:25:05, 39.40s/it]

  1%|█▉                                                                                                                                                                | 6/500 [04:01<5:33:03, 40.45s/it]

  1%|██▎                                                                                                                                                               | 7/500 [04:41<5:31:02, 40.29s/it]

  2%|██▌                                                                                                                                                               | 8/500 [05:22<5:31:17, 40.40s/it]

  2%|██▉                                                                                                                                                               | 9/500 [06:04<5:34:41, 40.90s/it]

  2%|███▏                                                                                                                                                             | 10/500 [06:45<5:34:40, 40.98s/it]

  2%|███▌                                                                                                                                                             | 11/500 [07:28<5:38:00, 41.47s/it]

  2%|███▊                                                                                                                                                             | 12/500 [08:09<5:35:54, 41.30s/it]

  3%|████▏                                                                                                                                                            | 13/500 [08:51<5:38:36, 41.72s/it]

  3%|████▌                                                                                                                                                            | 14/500 [09:33<5:36:49, 41.58s/it]

  3%|████▊                                                                                                                                                            | 15/500 [10:13<5:34:14, 41.35s/it]

  3%|█████▏                                                                                                                                                           | 16/500 [10:56<5:36:05, 41.66s/it]

  3%|█████▍                                                                                                                                                           | 17/500 [11:35<5:30:11, 41.02s/it]

  4%|█████▊                                                                                                                                                           | 18/500 [12:17<5:30:07, 41.09s/it]

  4%|██████                                                                                                                                                           | 19/500 [12:57<5:27:51, 40.90s/it]

  4%|██████▍                                                                                                                                                          | 20/500 [13:38<5:26:38, 40.83s/it]

  4%|██████▊                                                                                                                                                          | 21/500 [14:19<5:26:52, 40.94s/it]

  4%|███████                                                                                                                                                          | 22/500 [15:00<5:25:44, 40.89s/it]

  5%|███████▍                                                                                                                                                         | 23/500 [15:41<5:26:20, 41.05s/it]

  5%|███████▋                                                                                                                                                         | 24/500 [16:23<5:26:57, 41.21s/it]

  5%|████████                                                                                                                                                         | 25/500 [17:04<5:25:33, 41.12s/it]

  5%|████████▎                                                                                                                                                        | 26/500 [17:45<5:26:09, 41.29s/it]

  5%|████████▋                                                                                                                                                        | 27/500 [18:26<5:23:19, 41.01s/it]
{'loss': 0.0576, 'grad_norm': 0.5647863149642944, 'learning_rate': 0.00019969805343919821, 'epoch': 0.0}

  6%|█████████                                                                                                                                                        | 28/500 [19:06<5:21:28, 40.87s/it]


  6%|█████████▋                                                                                                                                                       | 30/500 [20:29<5:22:38, 41.19s/it]

  6%|█████████▉                                                                                                                                                       | 31/500 [21:12<5:25:21, 41.62s/it]

  6%|██████████▎                                                                                                                                                      | 32/500 [21:53<5:23:32, 41.48s/it]

  7%|██████████▋                                                                                                                                                      | 33/500 [22:33<5:19:59, 41.11s/it]

  7%|██████████▉                                                                                                                                                      | 34/500 [23:14<5:18:20, 40.99s/it]

  7%|███████████▎                                                                                                                                                     | 35/500 [23:55<5:17:47, 41.01s/it]

  7%|███████████▌                                                                                                                                                     | 36/500 [24:37<5:18:23, 41.17s/it]

  7%|███████████▉                                                                                                                                                     | 37/500 [25:17<5:16:08, 40.97s/it]

  8%|████████████▏                                                                                                                                                    | 38/500 [25:59<5:16:23, 41.09s/it]

  8%|████████████▌                                                                                                                                                    | 39/500 [26:40<5:16:13, 41.16s/it]

  8%|████████████▉                                                                                                                                                    | 40/500 [27:21<5:16:13, 41.25s/it]

  8%|█████████████▏                                                                                                                                                   | 41/500 [28:03<5:17:25, 41.49s/it]

  8%|█████████████▌                                                                                                                                                   | 42/500 [28:47<5:20:46, 42.02s/it]

  9%|█████████████▊                                                                                                                                                   | 43/500 [29:29<5:21:21, 42.19s/it]

  9%|██████████████▏                                                                                                                                                  | 44/500 [30:13<5:24:00, 42.63s/it]

  9%|██████████████▍                                                                                                                                                  | 45/500 [30:54<5:19:11, 42.09s/it]

  9%|██████████████▊                                                                                                                                                  | 46/500 [31:36<5:18:56, 42.15s/it]

  9%|███████████████▏                                                                                                                                                 | 47/500 [32:17<5:16:20, 41.90s/it]

 10%|███████████████▍                                                                                                                                                 | 48/500 [32:58<5:13:28, 41.61s/it]

 10%|███████████████▊                                                                                                                                                 | 49/500 [33:39<5:09:45, 41.21s/it]

 10%|████████████████                                                                                                                                                 | 50/500 [34:26<5:22:05, 42.95s/it]

 10%|████████████████▍                                                                                                                                                | 51/500 [35:08<5:20:07, 42.78s/it]

 10%|████████████████▋                                                                                                                                                | 52/500 [35:52<5:22:22, 43.18s/it]

 11%|█████████████████                                                                                                                                                | 53/500 [36:33<5:16:21, 42.47s/it]

 11%|█████████████████▍                                                                                                                                               | 54/500 [37:14<5:11:56, 41.97s/it]

 11%|█████████████████▋                                                                                                                                               | 55/500 [37:54<5:07:04, 41.40s/it]

 ... (more hidden) ...
{'loss': 0.0003, 'grad_norm': 0.022917961701750755, 'learning_rate': 0.00019649409730077935, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.037820860743522644, 'learning_rate': 0.00019632206087123296, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.06782130151987076, 'learning_rate': 0.000196145982960926, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.08147301524877548, 'learning_rate': 0.00019596587095773495, 'epoch': 0.0}
{'loss': 0.0027, 'grad_norm': 0.17314109206199646, 'learning_rate': 0.00019578173241879872, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.10285378992557526, 'learning_rate': 0.00019559357507020162, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.07102896273136139, 'learning_rate': 0.00019540140680664913, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.03365343436598778, 'learning_rate': 0.00019520523569113677, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.031999796628952026, 'learning_rate': 0.0001950050699546116, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.04584983363747597, 'learning_rate': 0.00019480091799562704, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.03766440972685814, 'learning_rate': 0.00019459278837999046, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.021271293982863426, 'learning_rate': 0.00019438068984040365, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.01841471716761589, 'learning_rate': 0.00019416463127609656, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.012171072885394096, 'learning_rate': 0.00019394462175245381, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.012839977629482746, 'learning_rate': 0.00019372067050063438, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.01287623681128025, 'learning_rate': 0.00019349278691718427, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.01225416548550129, 'learning_rate': 0.00019326098056364222, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.012422044761478901, 'learning_rate': 0.00019302526116613864, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.009795553982257843, 'learning_rate': 0.00019278563861498723, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.010659596882760525, 'learning_rate': 0.00019254212296427044, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.011661041527986526, 'learning_rate': 0.0001922947244314172, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.014846536330878735, 'learning_rate': 0.00019204345339677442, 'epoch': 0.0}
 ... (more hidden) ...Traceback (most recent call last):
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_LoRA.py", line 243, in <module>
    main()
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_LoRA.py", line 239, in main
    trainer.train()
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\trl\trainer\sft_trainer.py", line 451, in train
    output = super().train(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 1948, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 2289, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3328, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3373, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\amp\autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\peft_model.py", line 1577, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\tuners\tuners_utils.py", line 188, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1189, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1001, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 750, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 309, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt