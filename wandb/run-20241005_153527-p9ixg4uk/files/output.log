
  0%|                                                                                                                                                   | 0/500 [00:00<?, ?it/s]


  0%|▌                                                                                                                                        | 2/500 [00:15<1:04:16,  7.74s/it]
{'loss': 2.2935, 'grad_norm': 4.569986343383789, 'learning_rate': 4e-05, 'epoch': 0.0}

  1%|▊                                                                                                                                        | 3/500 [00:23<1:03:43,  7.69s/it]

  1%|█                                                                                                                                        | 4/500 [00:30<1:03:16,  7.65s/it]

  1%|█▎                                                                                                                                       | 5/500 [00:38<1:03:18,  7.67s/it]

  1%|█▋                                                                                                                                       | 6/500 [00:46<1:03:17,  7.69s/it]

  1%|█▉                                                                                                                                       | 7/500 [00:53<1:03:13,  7.69s/it]

  2%|██▏                                                                                                                                      | 8/500 [01:01<1:02:52,  7.67s/it]

  2%|██▍                                                                                                                                      | 9/500 [01:09<1:02:40,  7.66s/it]

  2%|██▋                                                                                                                                     | 10/500 [01:16<1:02:24,  7.64s/it]

  2%|██▉                                                                                                                                     | 11/500 [01:24<1:03:38,  7.81s/it]

  2%|███▎                                                                                                                                    | 12/500 [01:32<1:03:10,  7.77s/it]


  3%|███▊                                                                                                                                    | 14/500 [01:47<1:02:24,  7.70s/it]

  3%|████                                                                                                                                    | 15/500 [01:55<1:02:33,  7.74s/it]
{'loss': 2.4736, 'grad_norm': 5.525104999542236, 'learning_rate': 0.0005600000000000001, 'epoch': 0.0}

  3%|████▎                                                                                                                                   | 16/500 [02:03<1:02:25,  7.74s/it]

  3%|████▌                                                                                                                                   | 17/500 [02:11<1:02:04,  7.71s/it]

  4%|████▉                                                                                                                                   | 18/500 [02:18<1:01:18,  7.63s/it]


  4%|█████▍                                                                                                                                  | 20/500 [02:33<1:01:00,  7.63s/it]
{'loss': 2.2098, 'grad_norm': 4.802478313446045, 'learning_rate': 0.00076, 'epoch': 0.0}


  4%|█████▉                                                                                                                                  | 22/500 [02:49<1:01:46,  7.76s/it]
{'loss': 2.327, 'grad_norm': 4.409629821777344, 'learning_rate': 0.00084, 'epoch': 0.0}

  5%|██████▎                                                                                                                                 | 23/500 [02:57<1:01:23,  7.72s/it]

  5%|██████▌                                                                                                                                 | 24/500 [03:04<1:01:06,  7.70s/it]

  5%|██████▊                                                                                                                                 | 25/500 [03:12<1:00:48,  7.68s/it]


  5%|███████▎                                                                                                                                | 27/500 [03:27<1:00:08,  7.63s/it]
{'loss': 2.419, 'grad_norm': nan, 'learning_rate': 0.001, 'epoch': 0.0}

  6%|███████▋                                                                                                                                  | 28/500 [03:35<59:51,  7.61s/it]

  6%|████████                                                                                                                                  | 29/500 [03:42<59:41,  7.60s/it]

  6%|████████▎                                                                                                                                 | 30/500 [03:50<59:37,  7.61s/it]

  6%|████████▍                                                                                                                               | 31/500 [03:58<1:00:46,  7.78s/it]


  7%|████████▉                                                                                                                               | 33/500 [04:14<1:00:03,  7.72s/it]

  7%|█████████▍                                                                                                                                | 34/500 [04:21<59:55,  7.72s/it]
{'loss': 2.2722, 'grad_norm': 18.062898635864258, 'learning_rate': 0.0009998250366089847, 'epoch': 0.01}

  7%|█████████▌                                                                                                                              | 35/500 [04:29<1:00:01,  7.75s/it]

  7%|█████████▉                                                                                                                                | 36/500 [04:37<59:33,  7.70s/it]

  7%|██████████▏                                                                                                                               | 37/500 [04:44<59:01,  7.65s/it]


  8%|██████████▊                                                                                                                               | 39/500 [04:59<58:28,  7.61s/it]
{'loss': 2.2574, 'grad_norm': 6.221225738525391, 'learning_rate': 0.0009991144576886823, 'epoch': 0.01}


  8%|███████████▎                                                                                                                              | 41/500 [05:15<59:45,  7.81s/it]
{'loss': 2.3382, 'grad_norm': 4.482851982116699, 'learning_rate': 0.000998677345729831, 'epoch': 0.01}

  8%|███████████▌                                                                                                                              | 42/500 [05:23<59:13,  7.76s/it]

  9%|███████████▊                                                                                                                              | 43/500 [05:30<58:36,  7.69s/it]


  9%|████████████▍                                                                                                                             | 45/500 [05:46<58:07,  7.67s/it]

  9%|████████████▋                                                                                                                             | 46/500 [05:53<58:12,  7.69s/it]
{'loss': 2.1871, 'grad_norm': 4.060608863830566, 'learning_rate': 0.0009972030340333, 'epoch': 0.01}

  9%|████████████▉                                                                                                                             | 47/500 [06:01<58:00,  7.68s/it]

 10%|█████████████▏                                                                                                                            | 48/500 [06:09<57:52,  7.68s/it]

 10%|█████████████▌                                                                                                                            | 49/500 [06:16<57:45,  7.68s/it]

 10%|█████████████▊                                                                                                                            | 50/500 [06:24<57:31,  7.67s/it]

 10%|██████████████                                                                                                                            | 51/500 [06:32<58:55,  7.88s/it]

 10%|██████████████▎                                                                                                                           | 52/500 [06:40<58:28,  7.83s/it]


 11%|██████████████▉                                                                                                                           | 54/500 [06:56<57:44,  7.77s/it]

 11%|███████████████▏                                                                                                                          | 55/500 [07:03<57:26,  7.74s/it]
{'loss': 2.2099, 'grad_norm': 4.698726654052734, 'learning_rate': 0.0009931806517013613, 'epoch': 0.01}

 11%|███████████████▍                                                                                                                          | 56/500 [07:11<57:00,  7.70s/it]

 11%|███████████████▋                                                                                                                          | 57/500 [07:19<56:47,  7.69s/it]

 12%|████████████████                                                                                                                          | 58/500 [07:26<56:28,  7.67s/it]


 12%|████████████████▌                                                                                                                         | 60/500 [07:42<56:20,  7.68s/it]
{'loss': 2.2587, 'grad_norm': 5.4722981452941895, 'learning_rate': 0.0009901899829374047, 'epoch': 0.01}


 12%|█████████████████                                                                                                                         | 62/500 [07:58<57:22,  7.86s/it]

 13%|█████████████████▍                                                                                                                        | 63/500 [08:05<56:42,  7.79s/it]
{'loss': 2.3274, 'grad_norm': 5.783200740814209, 'learning_rate': 0.0009881380604901964, 'epoch': 0.01}

 13%|█████████████████▋                                                                                                                        | 64/500 [08:13<56:21,  7.76s/it]

 13%|█████████████████▉                                                                                                                        | 65/500 [08:21<56:07,  7.74s/it]

 13%|██████████████████▏                                                                                                                       | 66/500 [08:28<55:44,  7.71s/it]


 14%|██████████████████▊                                                                                                                       | 68/500 [08:44<55:24,  7.70s/it]

 14%|███████████████████                                                                                                                       | 69/500 [08:52<55:35,  7.74s/it]

 14%|███████████████████▎                                                                                                                      | 70/500 [08:59<55:33,  7.75s/it]

 14%|███████████████████▌                                                                                                                      | 71/500 [09:08<56:31,  7.91s/it]
{'loss': 2.2432, 'grad_norm': 40.40855026245117, 'learning_rate': 0.0009817292077210658, 'epoch': 0.01}

 14%|███████████████████▊                                                                                                                      | 72/500 [09:15<55:49,  7.83s/it]

 15%|████████████████████▏                                                                                                                     | 73/500 [09:23<55:07,  7.75s/it]

 15%|████████████████████▍                                                                                                                     | 74/500 [09:31<54:47,  7.72s/it]


 15%|████████████████████▉                                                                                                                     | 76/500 [09:46<54:34,  7.72s/it]

 15%|█████████████████████▎                                                                                                                    | 77/500 [09:54<54:29,  7.73s/it]
{'loss': 2.2739, 'grad_norm': 4.126314640045166, 'learning_rate': 0.0009760366073392245, 'epoch': 0.01}

 16%|█████████████████████▌                                                                                                                    | 78/500 [10:01<54:13,  7.71s/it]

 16%|█████████████████████▊                                                                                                                    | 79/500 [10:09<54:01,  7.70s/it]

 16%|██████████████████████                                                                                                                    | 80/500 [10:17<53:55,  7.70s/it]

 16%|██████████████████████▎                                                                                                                   | 81/500 [10:25<55:09,  7.90s/it]

 16%|██████████████████████▋                                                                                                                   | 82/500 [10:33<54:24,  7.81s/it]

 17%|██████████████████████▉                                                                                                                   | 83/500 [10:40<53:58,  7.77s/it]


 17%|███████████████████████▍                                                                                                                  | 85/500 [10:56<53:39,  7.76s/it]
{'loss': 2.1493, 'grad_norm': 9.539240837097168, 'learning_rate': 0.0009672822322997304, 'epoch': 0.01}

 17%|███████████████████████▋                                                                                                                  | 86/500 [11:04<53:21,  7.73s/it]

 17%|████████████████████████                                                                                                                  | 87/500 [11:11<53:11,  7.73s/it]

 18%|████████████████████████▎                                                                                                                 | 88/500 [11:19<52:53,  7.70s/it]Traceback (most recent call last):
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 243, in <module>
    main()
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 239, in main
    trainer.train()
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\trl\trainer\sft_trainer.py", line 451, in train
    output = super().train(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 1948, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 2289, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3328, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3373, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\amp\autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\peft_model.py", line 1577, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\tuners\tuners_utils.py", line 188, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1189, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1001, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 734, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 672, in forward
    attn_output = self.o_proj(attn_output)
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\bitsandbytes\nn\modules.py", line 477, in forward
    out = bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\bitsandbytes\autograd\_functions.py", line 579, in matmul_4bit
    return MatMul4Bit.apply(A, B, out, bias, quant_state)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\autograd\function.py", line 558, in apply
    @classmethod
KeyboardInterrupt