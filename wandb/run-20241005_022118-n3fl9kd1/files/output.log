

  1%|█▍                                                                                                                                         | 1/100 [00:02<03:59,  2.42s/it]

  2%|██▊                                                                                                                                        | 2/100 [00:04<03:38,  2.23s/it]

  3%|████▏                                                                                                                                      | 3/100 [00:06<03:30,  2.17s/it]

  4%|█████▌                                                                                                                                     | 4/100 [00:08<03:23,  2.12s/it]

  5%|██████▉                                                                                                                                    | 5/100 [00:10<03:19,  2.10s/it]

  6%|████████▎                                                                                                                                  | 6/100 [00:12<03:16,  2.09s/it]

  7%|█████████▋                                                                                                                                 | 7/100 [00:14<03:17,  2.12s/it]
  8%|███████████                                                                                                                                | 8/100 [00:17<03:15,  2.13s/it]Traceback (most recent call last):
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 241, in <module>
    main()
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 237, in main
    trainer.train()
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\trl\trainer\sft_trainer.py", line 451, in train
    output = super().train(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 1948, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 2294, in _inner_training_loop
    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
{'loss': 2.2972, 'grad_norm': 1.5472549200057983, 'learning_rate': 2.9528747416929467e-05, 'epoch': 0.0}