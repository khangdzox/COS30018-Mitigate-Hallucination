
  0%|                                                                                                                                                  | 0/110 [00:00<?, ?it/s]

  1%|█▎                                                                                                                                        | 1/110 [00:02<04:16,  2.35s/it]

  2%|██▌                                                                                                                                       | 2/110 [00:04<03:49,  2.13s/it]

  3%|███▊                                                                                                                                      | 3/110 [00:06<03:39,  2.05s/it]

  4%|█████                                                                                                                                     | 4/110 [00:08<03:34,  2.02s/it]

  5%|██████▎                                                                                                                                   | 5/110 [00:10<03:30,  2.00s/it]

  5%|███████▌                                                                                                                                  | 6/110 [00:12<03:26,  1.99s/it]

  6%|████████▊                                                                                                                                 | 7/110 [00:14<03:23,  1.98s/it]

  7%|██████████                                                                                                                                | 8/110 [00:16<03:20,  1.97s/it]

  8%|███████████▎                                                                                                                              | 9/110 [00:18<03:18,  1.96s/it]

  9%|████████████▍                                                                                                                            | 10/110 [00:19<03:15,  1.96s/it]

 10%|█████████████▋                                                                                                                           | 11/110 [00:22<03:31,  2.14s/it]

 11%|██████████████▉                                                                                                                          | 12/110 [00:24<03:22,  2.07s/it]

 12%|████████████████▏                                                                                                                        | 13/110 [00:26<03:15,  2.02s/it]

 13%|█████████████████▍                                                                                                                       | 14/110 [00:28<03:10,  1.98s/it]

 14%|██████████████████▋                                                                                                                      | 15/110 [00:30<03:05,  1.95s/it]

 15%|███████████████████▉                                                                                                                     | 16/110 [00:32<03:02,  1.94s/it]
{'loss': 2.2052, 'grad_norm': 6.8720703125, 'learning_rate': 0.00019714900382928675, 'epoch': 0.0}
 15%|█████████████████████▏                                                                                                                   | 17/110 [00:33<02:59,  1.93s/it][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.3 seconds.), retrying request
 16%|██████████████████████▍                                                                                                                  | 18/110 [00:35<02:56,  1.92s/it]

 17%|███████████████████████▋                                                                                                                 | 19/110 [00:37<02:53,  1.91s/it]

 18%|████████████████████████▉                                                                                                                | 20/110 [00:39<02:51,  1.91s/it]

 19%|██████████████████████████▏                                                                                                              | 21/110 [00:42<03:16,  2.20s/it]

 20%|███████████████████████████▍                                                                                                             | 22/110 [00:44<03:05,  2.11s/it]

 21%|████████████████████████████▋                                                                                                            | 23/110 [00:46<02:57,  2.04s/it]

 22%|█████████████████████████████▉                                                                                                           | 24/110 [00:48<02:51,  1.99s/it]

 24%|████████████████████████████████▍                                                                                                        | 26/110 [00:51<02:42,  1.94s/it]
{'loss': 2.2198, 'grad_norm': 6.192437171936035, 'learning_rate': 0.00018734082006171299, 'epoch': 0.0}

 25%|█████████████████████████████████▋                                                                                                       | 27/110 [00:53<02:39,  1.92s/it]

 25%|██████████████████████████████████▊                                                                                                      | 28/110 [00:55<02:36,  1.90s/it]

 26%|████████████████████████████████████                                                                                                     | 29/110 [00:57<02:33,  1.89s/it]

 27%|█████████████████████████████████████▎                                                                                                   | 30/110 [00:59<02:32,  1.90s/it]

 28%|██████████████████████████████████████▌                                                                                                  | 31/110 [01:01<02:42,  2.06s/it]

 29%|███████████████████████████████████████▊                                                                                                 | 32/110 [01:03<02:36,  2.00s/it]

 30%|█████████████████████████████████████████                                                                                                | 33/110 [01:05<02:32,  1.98s/it]

 31%|██████████████████████████████████████████▎                                                                                              | 34/110 [01:07<02:28,  1.95s/it]

 32%|███████████████████████████████████████████▌                                                                                             | 35/110 [01:09<02:24,  1.92s/it]Traceback (most recent call last):
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 245, in <module>
    main()
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 241, in main
    trainer.train()
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\trl\trainer\sft_trainer.py", line 451, in train
    output = super().train(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 1948, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 2289, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3328, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3373, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\amp\autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\peft_model.py", line 1577, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\tuners\tuners_utils.py", line 188, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1189, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1001, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 734, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 619, in forward
    value_states = self.v_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\tuners\lora\bnb.py", line 473, in forward
    result = result.clone()
             ^^^^^^^^^^^^^^
KeyboardInterrupt