
  0%|                                                                                                                                                   | 0/500 [00:00<?, ?it/s]

  0%|▎                                                                                                                                        | 1/500 [00:08<1:07:38,  8.13s/it]

  0%|▌                                                                                                                                        | 2/500 [00:16<1:06:36,  8.03s/it]

  1%|▊                                                                                                                                        | 3/500 [00:23<1:05:55,  7.96s/it]


  1%|█▎                                                                                                                                       | 5/500 [00:39<1:05:25,  7.93s/it]

  1%|█▋                                                                                                                                       | 6/500 [00:47<1:05:22,  7.94s/it]
{'loss': 2.2462, 'grad_norm': 4.294117450714111, 'learning_rate': 0.014000000000000002, 'epoch': 0.0}

  1%|█▉                                                                                                                                       | 7/500 [00:55<1:05:18,  7.95s/it]

  2%|██▏                                                                                                                                      | 8/500 [01:03<1:04:54,  7.92s/it]

  2%|██▍                                                                                                                                      | 9/500 [01:11<1:04:43,  7.91s/it]

  2%|██▋                                                                                                                                     | 10/500 [01:19<1:04:33,  7.90s/it]

  2%|██▉                                                                                                                                     | 11/500 [01:28<1:06:44,  8.19s/it]

  2%|███▎                                                                                                                                    | 12/500 [01:36<1:06:01,  8.12s/it]

  3%|███▌                                                                                                                                    | 13/500 [01:44<1:05:29,  8.07s/it]


  3%|████                                                                                                                                    | 15/500 [01:59<1:04:32,  7.99s/it]
{'loss': 2.244, 'grad_norm': 12.951199531555176, 'learning_rate': 0.028000000000000004, 'epoch': 0.0}

  3%|████▎                                                                                                                                   | 16/500 [02:07<1:04:09,  7.95s/it]

  3%|████▌                                                                                                                                   | 17/500 [02:15<1:03:59,  7.95s/it]

  4%|████▉                                                                                                                                   | 18/500 [02:23<1:03:22,  7.89s/it]

  4%|█████▏                                                                                                                                  | 19/500 [02:31<1:03:29,  7.92s/it]

  4%|█████▍                                                                                                                                  | 20/500 [02:39<1:03:11,  7.90s/it]

  4%|█████▋                                                                                                                                  | 21/500 [02:48<1:05:21,  8.19s/it]

  4%|█████▉                                                                                                                                  | 22/500 [02:56<1:04:37,  8.11s/it]

  5%|██████▎                                                                                                                                 | 23/500 [03:04<1:04:13,  8.08s/it]

  5%|██████▌                                                                                                                                 | 24/500 [03:12<1:03:56,  8.06s/it]

  5%|██████▊                                                                                                                                 | 25/500 [03:20<1:03:39,  8.04s/it]

  5%|███████                                                                                                                                 | 26/500 [03:28<1:03:22,  8.02s/it]


  6%|███████▌                                                                                                                                | 28/500 [03:43<1:02:47,  7.98s/it]

  6%|███████▉                                                                                                                                | 29/500 [03:51<1:02:38,  7.98s/it]

  6%|████████▏                                                                                                                               | 30/500 [03:59<1:02:36,  7.99s/it]
{'loss': 1.6745, 'grad_norm': 9.444182395935059, 'learning_rate': 0.07, 'epoch': 0.0}

  6%|████████▍                                                                                                                               | 31/500 [04:08<1:03:58,  8.18s/it]

  6%|████████▋                                                                                                                               | 32/500 [04:16<1:03:42,  8.17s/it]

  7%|████████▉                                                                                                                               | 33/500 [04:24<1:03:31,  8.16s/it]

  7%|█████████▏                                                                                                                              | 34/500 [04:32<1:03:08,  8.13s/it]

  7%|█████████▌                                                                                                                              | 35/500 [04:40<1:02:47,  8.10s/it]

  7%|█████████▊                                                                                                                              | 36/500 [04:48<1:02:28,  8.08s/it]

  7%|██████████                                                                                                                              | 37/500 [04:56<1:02:02,  8.04s/it]

  8%|██████████▎                                                                                                                             | 38/500 [05:04<1:01:47,  8.02s/it]

  8%|██████████▌                                                                                                                             | 39/500 [05:12<1:01:32,  8.01s/it]


  8%|███████████▏                                                                                                                            | 41/500 [05:30<1:03:52,  8.35s/it]
{'loss': 1.2342, 'grad_norm': 3.8172881603240967, 'learning_rate': 0.06990741420108817, 'epoch': 0.01}

  8%|███████████▍                                                                                                                            | 42/500 [05:38<1:03:12,  8.28s/it]

  9%|███████████▋                                                                                                                            | 43/500 [05:46<1:02:33,  8.21s/it]

  9%|███████████▉                                                                                                                            | 44/500 [05:54<1:02:25,  8.21s/it]

  9%|████████████▏                                                                                                                           | 45/500 [06:02<1:02:16,  8.21s/it]

  9%|████████████▌                                                                                                                           | 46/500 [06:11<1:02:29,  8.26s/it]

  9%|████████████▊                                                                                                                           | 47/500 [06:19<1:02:41,  8.30s/it]


 10%|█████████████▎                                                                                                                          | 49/500 [06:36<1:02:43,  8.34s/it]
{'loss': 3.9822, 'grad_norm': 428.29559326171875, 'learning_rate': 0.069779000726587, 'epoch': 0.01}

 10%|█████████████▌                                                                                                                          | 50/500 [06:44<1:02:34,  8.34s/it]

 10%|█████████████▊                                                                                                                          | 51/500 [06:53<1:04:10,  8.58s/it]

 10%|██████████████▏                                                                                                                         | 52/500 [07:01<1:03:14,  8.47s/it]

 11%|██████████████▍                                                                                                                         | 53/500 [07:10<1:02:26,  8.38s/it]Traceback (most recent call last):
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 243, in <module>
    main()
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_QLoRA.py", line 239, in main
    trainer.train()
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\trl\trainer\sft_trainer.py", line 451, in train
    output = super().train(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 1948, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 2289, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3328, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\trainer.py", line 3373, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\utils\operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\amp\autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\peft_model.py", line 1577, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\tuners\tuners_utils.py", line 188, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1189, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1001, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 734, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 619, in forward
    value_states = self.v_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\tuners\lora\bnb.py", line 467, in forward
    result = self.base_layer(x, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\accelerate\hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\bitsandbytes\nn\modules.py", line 479, in forward
    out = out.to(inp_dtype)
          ^^^^^^^^^^^^^^^^^
KeyboardInterrupt