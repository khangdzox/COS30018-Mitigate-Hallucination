{
  "best_metric": 1.1186294555664062,
  "best_model_checkpoint": "Finetuning/Fine-tuned_checkpoint/medical_3\\checkpoint-40",
  "epoch": 0.0008751681963877433,
  "eval_steps": 20,
  "global_step": 40,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 2.187920490969358e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.3,
      "step": 1
    },
    {
      "epoch": 4.375840981938716e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.134,
      "step": 2
    },
    {
      "epoch": 6.563761472908074e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.2576,
      "step": 3
    },
    {
      "epoch": 8.751681963877433e-05,
      "grad_norm": 3.582977533340454,
      "learning_rate": 4e-05,
      "loss": 2.0945,
      "step": 4
    },
    {
      "epoch": 0.00010939602454846791,
      "grad_norm": 3.747514247894287,
      "learning_rate": 8e-05,
      "loss": 1.8236,
      "step": 5
    },
    {
      "epoch": 0.0001312752294581615,
      "grad_norm": 3.6239430904388428,
      "learning_rate": 0.00012,
      "loss": 1.8854,
      "step": 6
    },
    {
      "epoch": 0.00015315443436785507,
      "grad_norm": NaN,
      "learning_rate": 0.00012,
      "loss": 2.0524,
      "step": 7
    },
    {
      "epoch": 0.00017503363927754865,
      "grad_norm": 3.4393887519836426,
      "learning_rate": 0.00016,
      "loss": 2.0364,
      "step": 8
    },
    {
      "epoch": 0.00019691284418724223,
      "grad_norm": NaN,
      "learning_rate": 0.00016,
      "loss": 2.0879,
      "step": 9
    },
    {
      "epoch": 0.00021879204909693582,
      "grad_norm": 10.043916702270508,
      "learning_rate": 0.0002,
      "loss": 2.2239,
      "step": 10
    },
    {
      "epoch": 0.0002406712540066294,
      "grad_norm": 4.174642086029053,
      "learning_rate": 0.0001995959595959596,
      "loss": 2.11,
      "step": 11
    },
    {
      "epoch": 0.000262550458916323,
      "grad_norm": 5.000838279724121,
      "learning_rate": 0.0001991919191919192,
      "loss": 2.2663,
      "step": 12
    },
    {
      "epoch": 0.00028442966382601656,
      "grad_norm": 10.119012832641602,
      "learning_rate": 0.00019878787878787878,
      "loss": 2.1576,
      "step": 13
    },
    {
      "epoch": 0.00030630886873571014,
      "grad_norm": 6.535268783569336,
      "learning_rate": 0.00019838383838383837,
      "loss": 2.1494,
      "step": 14
    },
    {
      "epoch": 0.0003281880736454037,
      "grad_norm": 7.976975917816162,
      "learning_rate": 0.000197979797979798,
      "loss": 1.7698,
      "step": 15
    },
    {
      "epoch": 0.0003500672785550973,
      "grad_norm": NaN,
      "learning_rate": 0.000197979797979798,
      "loss": 1.6329,
      "step": 16
    },
    {
      "epoch": 0.0003719464834647909,
      "grad_norm": 7.913826942443848,
      "learning_rate": 0.0001975757575757576,
      "loss": 1.5018,
      "step": 17
    },
    {
      "epoch": 0.00039382568837448447,
      "grad_norm": NaN,
      "learning_rate": 0.0001975757575757576,
      "loss": 1.7756,
      "step": 18
    },
    {
      "epoch": 0.00041570489328417805,
      "grad_norm": 28.892213821411133,
      "learning_rate": 0.0001971717171717172,
      "loss": 1.4315,
      "step": 19
    },
    {
      "epoch": 0.00043758409819387163,
      "grad_norm": 30.55006217956543,
      "learning_rate": 0.00019676767676767677,
      "loss": 1.7918,
      "step": 20
    },
    {
      "epoch": 0.00043758409819387163,
      "eval_loss": 1.5775611400604248,
      "eval_runtime": 1207.3533,
      "eval_samples_per_second": 0.347,
      "eval_steps_per_second": 0.347,
      "step": 20
    },
    {
      "epoch": 0.0004594633031035652,
      "grad_norm": 16.522403717041016,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.5203,
      "step": 21
    },
    {
      "epoch": 0.0004813425080132588,
      "grad_norm": 13.282205581665039,
      "learning_rate": 0.00019595959595959596,
      "loss": 1.8017,
      "step": 22
    },
    {
      "epoch": 0.0005032217129229524,
      "grad_norm": 9.916335105895996,
      "learning_rate": 0.00019555555555555556,
      "loss": 1.4519,
      "step": 23
    },
    {
      "epoch": 0.000525100917832646,
      "grad_norm": 6.676116466522217,
      "learning_rate": 0.00019515151515151516,
      "loss": 1.202,
      "step": 24
    },
    {
      "epoch": 0.0005469801227423396,
      "grad_norm": 6.057275295257568,
      "learning_rate": 0.00019474747474747476,
      "loss": 1.2828,
      "step": 25
    },
    {
      "epoch": 0.0005688593276520331,
      "grad_norm": 7.44789981842041,
      "learning_rate": 0.00019434343434343435,
      "loss": 1.0523,
      "step": 26
    },
    {
      "epoch": 0.0005907385325617268,
      "grad_norm": 6.50221061706543,
      "learning_rate": 0.00019393939393939395,
      "loss": 1.2899,
      "step": 27
    },
    {
      "epoch": 0.0006126177374714203,
      "grad_norm": 6.900063991546631,
      "learning_rate": 0.00019353535353535355,
      "loss": 1.2485,
      "step": 28
    },
    {
      "epoch": 0.0006344969423811139,
      "grad_norm": 6.068929672241211,
      "learning_rate": 0.00019313131313131315,
      "loss": 1.0439,
      "step": 29
    },
    {
      "epoch": 0.0006563761472908074,
      "grad_norm": 7.316030025482178,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.2418,
      "step": 30
    },
    {
      "epoch": 0.0006782553522005011,
      "grad_norm": 5.879920959472656,
      "learning_rate": 0.00019232323232323232,
      "loss": 1.1358,
      "step": 31
    },
    {
      "epoch": 0.0007001345571101946,
      "grad_norm": 5.274486064910889,
      "learning_rate": 0.00019191919191919191,
      "loss": 0.9103,
      "step": 32
    },
    {
      "epoch": 0.0007220137620198882,
      "grad_norm": 5.948697566986084,
      "learning_rate": 0.0001915151515151515,
      "loss": 0.7902,
      "step": 33
    },
    {
      "epoch": 0.0007438929669295818,
      "grad_norm": 7.261547565460205,
      "learning_rate": 0.00019111111111111114,
      "loss": 1.0552,
      "step": 34
    },
    {
      "epoch": 0.0007657721718392754,
      "grad_norm": 6.084803104400635,
      "learning_rate": 0.00019070707070707073,
      "loss": 0.8835,
      "step": 35
    },
    {
      "epoch": 0.0007876513767489689,
      "grad_norm": 7.025145053863525,
      "learning_rate": 0.0001903030303030303,
      "loss": 0.9343,
      "step": 36
    },
    {
      "epoch": 0.0008095305816586626,
      "grad_norm": 7.298849582672119,
      "learning_rate": 0.0001898989898989899,
      "loss": 0.8876,
      "step": 37
    },
    {
      "epoch": 0.0008314097865683561,
      "grad_norm": 4.5801215171813965,
      "learning_rate": 0.0001894949494949495,
      "loss": 0.6371,
      "step": 38
    },
    {
      "epoch": 0.0008532889914780497,
      "grad_norm": 6.978671073913574,
      "learning_rate": 0.0001890909090909091,
      "loss": 0.9304,
      "step": 39
    },
    {
      "epoch": 0.0008751681963877433,
      "grad_norm": 5.251047134399414,
      "learning_rate": 0.0001886868686868687,
      "loss": 0.7401,
      "step": 40
    },
    {
      "epoch": 0.0008751681963877433,
      "eval_loss": 1.1186294555664062,
      "eval_runtime": 1247.1505,
      "eval_samples_per_second": 0.336,
      "eval_steps_per_second": 0.336,
      "step": 40
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 40,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1882026719797248.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
