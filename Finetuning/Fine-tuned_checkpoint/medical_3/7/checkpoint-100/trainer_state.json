{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0021879204909693584,
  "eval_steps": 10,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 2.187920490969358e-05,
      "grad_norm": 1.580640435218811,
      "learning_rate": 5e-05,
      "loss": 2.0846,
      "step": 1
    },
    {
      "epoch": 4.375840981938716e-05,
      "grad_norm": 1.5699187517166138,
      "learning_rate": 0.0001,
      "loss": 2.0846,
      "step": 2
    },
    {
      "epoch": 6.563761472908074e-05,
      "grad_norm": 1.6981853246688843,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.0563,
      "step": 3
    },
    {
      "epoch": 8.751681963877433e-05,
      "grad_norm": 1.4897511005401611,
      "learning_rate": 0.0002,
      "loss": 1.9907,
      "step": 4
    },
    {
      "epoch": 0.00010939602454846791,
      "grad_norm": 1.4658472537994385,
      "learning_rate": 0.00019995608365087946,
      "loss": 1.8937,
      "step": 5
    },
    {
      "epoch": 0.0001312752294581615,
      "grad_norm": 1.3722202777862549,
      "learning_rate": 0.00019982437317643217,
      "loss": 1.7641,
      "step": 6
    },
    {
      "epoch": 0.00015315443436785507,
      "grad_norm": 1.584060788154602,
      "learning_rate": 0.0001996049842615217,
      "loss": 1.6525,
      "step": 7
    },
    {
      "epoch": 0.00017503363927754865,
      "grad_norm": 2.343679666519165,
      "learning_rate": 0.00019929810960135172,
      "loss": 1.5525,
      "step": 8
    },
    {
      "epoch": 0.00019691284418724223,
      "grad_norm": 2.647089719772339,
      "learning_rate": 0.0001989040187322164,
      "loss": 1.4333,
      "step": 9
    },
    {
      "epoch": 0.00021879204909693582,
      "grad_norm": 2.4940171241760254,
      "learning_rate": 0.00019842305779475968,
      "loss": 1.3038,
      "step": 10
    },
    {
      "epoch": 0.00021879204909693582,
      "eval_loss": 1.166077971458435,
      "eval_runtime": 1119.8799,
      "eval_samples_per_second": 0.374,
      "eval_steps_per_second": 0.188,
      "step": 10
    },
    {
      "epoch": 0.0002406712540066294,
      "grad_norm": 2.3195536136627197,
      "learning_rate": 0.0001978556492299504,
      "loss": 1.1663,
      "step": 11
    },
    {
      "epoch": 0.000262550458916323,
      "grad_norm": 3.082750082015991,
      "learning_rate": 0.0001972022914080411,
      "loss": 1.0308,
      "step": 12
    },
    {
      "epoch": 0.00028442966382601656,
      "grad_norm": 2.8669238090515137,
      "learning_rate": 0.00019646355819083589,
      "loss": 0.8794,
      "step": 13
    },
    {
      "epoch": 0.00030630886873571014,
      "grad_norm": 3.05716872215271,
      "learning_rate": 0.00019564009842765225,
      "loss": 0.7289,
      "step": 14
    },
    {
      "epoch": 0.0003281880736454037,
      "grad_norm": 2.8889000415802,
      "learning_rate": 0.00019473263538541914,
      "loss": 0.5969,
      "step": 15
    },
    {
      "epoch": 0.0003500672785550973,
      "grad_norm": 2.640842914581299,
      "learning_rate": 0.0001937419661134121,
      "loss": 0.4786,
      "step": 16
    },
    {
      "epoch": 0.0003719464834647909,
      "grad_norm": 2.4136240482330322,
      "learning_rate": 0.00019266896074318334,
      "loss": 0.372,
      "step": 17
    },
    {
      "epoch": 0.00039382568837448447,
      "grad_norm": 2.493450880050659,
      "learning_rate": 0.00019151456172430183,
      "loss": 0.2952,
      "step": 18
    },
    {
      "epoch": 0.00041570489328417805,
      "grad_norm": 1.9308421611785889,
      "learning_rate": 0.00019027978299657436,
      "loss": 0.2332,
      "step": 19
    },
    {
      "epoch": 0.00043758409819387163,
      "grad_norm": 1.338556170463562,
      "learning_rate": 0.00018896570909947475,
      "loss": 0.1835,
      "step": 20
    },
    {
      "epoch": 0.00043758409819387163,
      "eval_loss": 0.1485919952392578,
      "eval_runtime": 794.2542,
      "eval_samples_per_second": 0.528,
      "eval_steps_per_second": 0.264,
      "step": 20
    },
    {
      "epoch": 0.0004594633031035652,
      "grad_norm": 1.2277685403823853,
      "learning_rate": 0.0001875734942195637,
      "loss": 0.1489,
      "step": 21
    },
    {
      "epoch": 0.0004813425080132588,
      "grad_norm": 0.9437645077705383,
      "learning_rate": 0.00018610436117673555,
      "loss": 0.1182,
      "step": 22
    },
    {
      "epoch": 0.0005032217129229524,
      "grad_norm": 0.8800113201141357,
      "learning_rate": 0.0001845596003501826,
      "loss": 0.0945,
      "step": 23
    },
    {
      "epoch": 0.000525100917832646,
      "grad_norm": 0.8308767080307007,
      "learning_rate": 0.0001829405685450202,
      "loss": 0.0749,
      "step": 24
    },
    {
      "epoch": 0.0005469801227423396,
      "grad_norm": 0.8225266933441162,
      "learning_rate": 0.00018124868780056814,
      "loss": 0.0579,
      "step": 25
    },
    {
      "epoch": 0.0005688593276520331,
      "grad_norm": 0.9762867093086243,
      "learning_rate": 0.00017948544414133534,
      "loss": 0.0475,
      "step": 26
    },
    {
      "epoch": 0.0005907385325617268,
      "grad_norm": 0.9043094515800476,
      "learning_rate": 0.00017765238627180424,
      "loss": 0.0394,
      "step": 27
    },
    {
      "epoch": 0.0006126177374714203,
      "grad_norm": 0.4667856693267822,
      "learning_rate": 0.00017575112421616202,
      "loss": 0.0323,
      "step": 28
    },
    {
      "epoch": 0.0006344969423811139,
      "grad_norm": 1.1865237951278687,
      "learning_rate": 0.00017378332790417273,
      "loss": 0.0294,
      "step": 29
    },
    {
      "epoch": 0.0006563761472908074,
      "grad_norm": 1.1353851556777954,
      "learning_rate": 0.00017175072570443312,
      "loss": 0.028,
      "step": 30
    },
    {
      "epoch": 0.0006563761472908074,
      "eval_loss": 0.02710363082587719,
      "eval_runtime": 739.8706,
      "eval_samples_per_second": 0.566,
      "eval_steps_per_second": 0.284,
      "step": 30
    },
    {
      "epoch": 0.0006782553522005011,
      "grad_norm": 0.16953690350055695,
      "learning_rate": 0.00016965510290629972,
      "loss": 0.027,
      "step": 31
    },
    {
      "epoch": 0.0007001345571101946,
      "grad_norm": 0.10214273631572723,
      "learning_rate": 0.00016749830015182107,
      "loss": 0.0267,
      "step": 32
    },
    {
      "epoch": 0.0007220137620198882,
      "grad_norm": 0.07852333039045334,
      "learning_rate": 0.00016528221181905217,
      "loss": 0.0263,
      "step": 33
    },
    {
      "epoch": 0.0007438929669295818,
      "grad_norm": 0.07510285824537277,
      "learning_rate": 0.00016300878435817113,
      "loss": 0.0258,
      "step": 34
    },
    {
      "epoch": 0.0007657721718392754,
      "grad_norm": 0.18302114307880402,
      "learning_rate": 0.00016068001458185936,
      "loss": 0.0256,
      "step": 35
    },
    {
      "epoch": 0.0007876513767489689,
      "grad_norm": 0.10316465049982071,
      "learning_rate": 0.0001582979479114472,
      "loss": 0.0252,
      "step": 36
    },
    {
      "epoch": 0.0008095305816586626,
      "grad_norm": 0.07715078443288803,
      "learning_rate": 0.00015586467658036524,
      "loss": 0.0248,
      "step": 37
    },
    {
      "epoch": 0.0008314097865683561,
      "grad_norm": 0.07027019560337067,
      "learning_rate": 0.0001533823377964791,
      "loss": 0.0244,
      "step": 38
    },
    {
      "epoch": 0.0008532889914780497,
      "grad_norm": 0.06848329305648804,
      "learning_rate": 0.00015085311186492206,
      "loss": 0.0239,
      "step": 39
    },
    {
      "epoch": 0.0008751681963877433,
      "grad_norm": 0.06984332203865051,
      "learning_rate": 0.00014827922027307451,
      "loss": 0.0235,
      "step": 40
    },
    {
      "epoch": 0.0008751681963877433,
      "eval_loss": 0.023098617792129517,
      "eval_runtime": 720.2107,
      "eval_samples_per_second": 0.582,
      "eval_steps_per_second": 0.292,
      "step": 40
    },
    {
      "epoch": 0.0008970474012974369,
      "grad_norm": 0.07239625602960587,
      "learning_rate": 0.0001456629237393713,
      "loss": 0.023,
      "step": 41
    },
    {
      "epoch": 0.0009189266062071304,
      "grad_norm": 0.07364992797374725,
      "learning_rate": 0.00014300652022765207,
      "loss": 0.0225,
      "step": 42
    },
    {
      "epoch": 0.0009408058111168241,
      "grad_norm": 0.0753818154335022,
      "learning_rate": 0.00014031234292879725,
      "loss": 0.022,
      "step": 43
    },
    {
      "epoch": 0.0009626850160265176,
      "grad_norm": 0.07540987432003021,
      "learning_rate": 0.00013758275821142382,
      "loss": 0.0216,
      "step": 44
    },
    {
      "epoch": 0.0009845642209362112,
      "grad_norm": 0.07561742514371872,
      "learning_rate": 0.0001348201635434399,
      "loss": 0.0213,
      "step": 45
    },
    {
      "epoch": 0.0010064434258459049,
      "grad_norm": 0.06554003804922104,
      "learning_rate": 0.00013202698538628376,
      "loss": 0.0208,
      "step": 46
    },
    {
      "epoch": 0.0010283226307555983,
      "grad_norm": 0.07369997352361679,
      "learning_rate": 0.00012920567706369758,
      "loss": 0.0201,
      "step": 47
    },
    {
      "epoch": 0.001050201835665292,
      "grad_norm": 0.07163280248641968,
      "learning_rate": 0.00012635871660690676,
      "loss": 0.0196,
      "step": 48
    },
    {
      "epoch": 0.0010720810405749855,
      "grad_norm": 0.06851347535848618,
      "learning_rate": 0.00012348860457809838,
      "loss": 0.0192,
      "step": 49
    },
    {
      "epoch": 0.0010939602454846792,
      "grad_norm": 0.06588610261678696,
      "learning_rate": 0.00012059786187410984,
      "loss": 0.0187,
      "step": 50
    },
    {
      "epoch": 0.0010939602454846792,
      "eval_loss": 0.01844501495361328,
      "eval_runtime": 481.7109,
      "eval_samples_per_second": 0.87,
      "eval_steps_per_second": 0.436,
      "step": 50
    },
    {
      "epoch": 0.0011158394503943726,
      "grad_norm": 0.06265567243099213,
      "learning_rate": 0.0001176890275122573,
      "loss": 0.0184,
      "step": 51
    },
    {
      "epoch": 0.0011377186553040662,
      "grad_norm": 0.06097807735204697,
      "learning_rate": 0.00011476465640024814,
      "loss": 0.018,
      "step": 52
    },
    {
      "epoch": 0.0011595978602137599,
      "grad_norm": 0.05912882462143898,
      "learning_rate": 0.00011182731709213659,
      "loss": 0.0177,
      "step": 53
    },
    {
      "epoch": 0.0011814770651234535,
      "grad_norm": 0.0513119176030159,
      "learning_rate": 0.00010887958953229349,
      "loss": 0.0177,
      "step": 54
    },
    {
      "epoch": 0.001203356270033147,
      "grad_norm": 0.05747387930750847,
      "learning_rate": 0.00010592406278937144,
      "loss": 0.017,
      "step": 55
    },
    {
      "epoch": 0.0012252354749428406,
      "grad_norm": 0.057761117815971375,
      "learning_rate": 0.00010296333278225599,
      "loss": 0.0167,
      "step": 56
    },
    {
      "epoch": 0.0012471146798525342,
      "grad_norm": 0.0577438659965992,
      "learning_rate": 0.0001,
      "loss": 0.0164,
      "step": 57
    },
    {
      "epoch": 0.0012689938847622278,
      "grad_norm": 0.06022476404905319,
      "learning_rate": 9.703666721774402e-05,
      "loss": 0.016,
      "step": 58
    },
    {
      "epoch": 0.0012908730896719213,
      "grad_norm": 0.05493997037410736,
      "learning_rate": 9.407593721062859e-05,
      "loss": 0.016,
      "step": 59
    },
    {
      "epoch": 0.0013127522945816149,
      "grad_norm": 0.062389347702264786,
      "learning_rate": 9.112041046770653e-05,
      "loss": 0.0155,
      "step": 60
    },
    {
      "epoch": 0.0013127522945816149,
      "eval_loss": 0.01502259261906147,
      "eval_runtime": 523.9228,
      "eval_samples_per_second": 0.8,
      "eval_steps_per_second": 0.401,
      "step": 60
    },
    {
      "epoch": 0.0013346314994913085,
      "grad_norm": 0.06598544120788574,
      "learning_rate": 8.817268290786343e-05,
      "loss": 0.015,
      "step": 61
    },
    {
      "epoch": 0.0013565107044010022,
      "grad_norm": 0.06934947520494461,
      "learning_rate": 8.523534359975189e-05,
      "loss": 0.0146,
      "step": 62
    },
    {
      "epoch": 0.0013783899093106956,
      "grad_norm": 0.0731767937541008,
      "learning_rate": 8.231097248774274e-05,
      "loss": 0.0141,
      "step": 63
    },
    {
      "epoch": 0.0014002691142203892,
      "grad_norm": 0.0757141262292862,
      "learning_rate": 7.940213812589018e-05,
      "loss": 0.0138,
      "step": 64
    },
    {
      "epoch": 0.0014221483191300829,
      "grad_norm": 0.0828150287270546,
      "learning_rate": 7.651139542190164e-05,
      "loss": 0.013,
      "step": 65
    },
    {
      "epoch": 0.0014440275240397765,
      "grad_norm": 0.08769932389259338,
      "learning_rate": 7.364128339309326e-05,
      "loss": 0.0124,
      "step": 66
    },
    {
      "epoch": 0.00146590672894947,
      "grad_norm": 0.0938054621219635,
      "learning_rate": 7.079432293630244e-05,
      "loss": 0.0117,
      "step": 67
    },
    {
      "epoch": 0.0014877859338591635,
      "grad_norm": 0.08622083812952042,
      "learning_rate": 6.797301461371625e-05,
      "loss": 0.0117,
      "step": 68
    },
    {
      "epoch": 0.0015096651387688572,
      "grad_norm": 0.09209834784269333,
      "learning_rate": 6.517983645656014e-05,
      "loss": 0.011,
      "step": 69
    },
    {
      "epoch": 0.0015315443436785508,
      "grad_norm": 0.10951003432273865,
      "learning_rate": 6.24172417885762e-05,
      "loss": 0.0096,
      "step": 70
    },
    {
      "epoch": 0.0015315443436785508,
      "eval_loss": 0.008884548209607601,
      "eval_runtime": 696.8794,
      "eval_samples_per_second": 0.601,
      "eval_steps_per_second": 0.301,
      "step": 70
    },
    {
      "epoch": 0.0015534235485882442,
      "grad_norm": 0.11584746837615967,
      "learning_rate": 5.96876570712028e-05,
      "loss": 0.0088,
      "step": 71
    },
    {
      "epoch": 0.0015753027534979379,
      "grad_norm": 0.12046119570732117,
      "learning_rate": 5.699347977234799e-05,
      "loss": 0.0081,
      "step": 72
    },
    {
      "epoch": 0.0015971819584076315,
      "grad_norm": 0.12743990123271942,
      "learning_rate": 5.43370762606287e-05,
      "loss": 0.0068,
      "step": 73
    },
    {
      "epoch": 0.0016190611633173251,
      "grad_norm": 0.12735743820667267,
      "learning_rate": 5.172077972692553e-05,
      "loss": 0.0062,
      "step": 74
    },
    {
      "epoch": 0.0016409403682270186,
      "grad_norm": 0.12958215177059174,
      "learning_rate": 4.914688813507797e-05,
      "loss": 0.0055,
      "step": 75
    },
    {
      "epoch": 0.0016628195731367122,
      "grad_norm": 0.13087323307991028,
      "learning_rate": 4.661766220352097e-05,
      "loss": 0.005,
      "step": 76
    },
    {
      "epoch": 0.0016846987780464058,
      "grad_norm": 0.12928934395313263,
      "learning_rate": 4.4135323419634766e-05,
      "loss": 0.004,
      "step": 77
    },
    {
      "epoch": 0.0017065779829560995,
      "grad_norm": 0.13139045238494873,
      "learning_rate": 4.170205208855281e-05,
      "loss": 0.0036,
      "step": 78
    },
    {
      "epoch": 0.0017284571878657929,
      "grad_norm": 0.12467991560697556,
      "learning_rate": 3.931998541814069e-05,
      "loss": 0.0028,
      "step": 79
    },
    {
      "epoch": 0.0017503363927754865,
      "grad_norm": 0.12641015648841858,
      "learning_rate": 3.69912156418289e-05,
      "loss": 0.0024,
      "step": 80
    },
    {
      "epoch": 0.0017503363927754865,
      "eval_loss": 0.0020659388974308968,
      "eval_runtime": 689.0037,
      "eval_samples_per_second": 0.608,
      "eval_steps_per_second": 0.305,
      "step": 80
    },
    {
      "epoch": 0.0017722155976851802,
      "grad_norm": 0.11465157568454742,
      "learning_rate": 3.471778818094785e-05,
      "loss": 0.0022,
      "step": 81
    },
    {
      "epoch": 0.0017940948025948738,
      "grad_norm": 0.09618759155273438,
      "learning_rate": 3.250169984817898e-05,
      "loss": 0.0015,
      "step": 82
    },
    {
      "epoch": 0.0018159740075045672,
      "grad_norm": 0.09516734629869461,
      "learning_rate": 3.034489709370033e-05,
      "loss": 0.0015,
      "step": 83
    },
    {
      "epoch": 0.0018378532124142608,
      "grad_norm": 0.07374022901058197,
      "learning_rate": 2.8249274295566875e-05,
      "loss": 0.001,
      "step": 84
    },
    {
      "epoch": 0.0018597324173239545,
      "grad_norm": 0.06819531321525574,
      "learning_rate": 2.6216672095827256e-05,
      "loss": 0.001,
      "step": 85
    },
    {
      "epoch": 0.0018816116222336481,
      "grad_norm": 0.05355338752269745,
      "learning_rate": 2.4248875783837987e-05,
      "loss": 0.0007,
      "step": 86
    },
    {
      "epoch": 0.0019034908271433415,
      "grad_norm": 0.056428682059049606,
      "learning_rate": 2.234761372819577e-05,
      "loss": 0.0008,
      "step": 87
    },
    {
      "epoch": 0.0019253700320530352,
      "grad_norm": 0.05778578296303749,
      "learning_rate": 2.0514555858664663e-05,
      "loss": 0.002,
      "step": 88
    },
    {
      "epoch": 0.0019472492369627288,
      "grad_norm": 0.043106306344270706,
      "learning_rate": 1.875131219943187e-05,
      "loss": 0.0006,
      "step": 89
    },
    {
      "epoch": 0.0019691284418724224,
      "grad_norm": 0.03921862319111824,
      "learning_rate": 1.7059431454979824e-05,
      "loss": 0.0006,
      "step": 90
    },
    {
      "epoch": 0.0019691284418724224,
      "eval_loss": 0.00053803576156497,
      "eval_runtime": 690.4972,
      "eval_samples_per_second": 0.607,
      "eval_steps_per_second": 0.304,
      "step": 90
    },
    {
      "epoch": 0.001991007646782116,
      "grad_norm": 0.03355185315012932,
      "learning_rate": 1.5440399649817385e-05,
      "loss": 0.0005,
      "step": 91
    },
    {
      "epoch": 0.0020128868516918097,
      "grad_norm": 0.049932513386011124,
      "learning_rate": 1.3895638823264446e-05,
      "loss": 0.0018,
      "step": 92
    },
    {
      "epoch": 0.002034766056601503,
      "grad_norm": 0.027336351573467255,
      "learning_rate": 1.2426505780436326e-05,
      "loss": 0.0004,
      "step": 93
    },
    {
      "epoch": 0.0020566452615111966,
      "grad_norm": 0.024707773700356483,
      "learning_rate": 1.103429090052528e-05,
      "loss": 0.0004,
      "step": 94
    },
    {
      "epoch": 0.00207852446642089,
      "grad_norm": 0.02544325403869152,
      "learning_rate": 9.720217003425647e-06,
      "loss": 0.0004,
      "step": 95
    },
    {
      "epoch": 0.002100403671330584,
      "grad_norm": 0.04186389967799187,
      "learning_rate": 8.485438275698154e-06,
      "loss": 0.0016,
      "step": 96
    },
    {
      "epoch": 0.0021222828762402775,
      "grad_norm": 0.044137921184301376,
      "learning_rate": 7.331039256816663e-06,
      "loss": 0.0017,
      "step": 97
    },
    {
      "epoch": 0.002144162081149971,
      "grad_norm": 0.022227274253964424,
      "learning_rate": 6.258033886587911e-06,
      "loss": 0.0004,
      "step": 98
    },
    {
      "epoch": 0.0021660412860596647,
      "grad_norm": 0.021759381517767906,
      "learning_rate": 5.267364614580861e-06,
      "loss": 0.0004,
      "step": 99
    },
    {
      "epoch": 0.0021879204909693584,
      "grad_norm": 0.025012889876961708,
      "learning_rate": 4.359901572347758e-06,
      "loss": 0.0004,
      "step": 100
    },
    {
      "epoch": 0.0021879204909693584,
      "eval_loss": 0.0003718832740560174,
      "eval_runtime": 698.7058,
      "eval_samples_per_second": 0.6,
      "eval_steps_per_second": 0.301,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9226239030067200.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
