{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0015315443436785508,
  "eval_steps": 500,
  "global_step": 70,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 2.187920490969358e-05,
      "grad_norm": 2.207639455795288,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.9488,
      "step": 1
    },
    {
      "epoch": 4.375840981938716e-05,
      "grad_norm": 2.1808557510375977,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.9488,
      "step": 2
    },
    {
      "epoch": 6.563761472908074e-05,
      "grad_norm": 2.169074058532715,
      "learning_rate": 4e-05,
      "loss": 1.9415,
      "step": 3
    },
    {
      "epoch": 8.751681963877433e-05,
      "grad_norm": 2.061099052429199,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.9206,
      "step": 4
    },
    {
      "epoch": 0.00010939602454846791,
      "grad_norm": 2.0105860233306885,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.8874,
      "step": 5
    },
    {
      "epoch": 0.0001312752294581615,
      "grad_norm": 1.975155234336853,
      "learning_rate": 8e-05,
      "loss": 1.8425,
      "step": 6
    },
    {
      "epoch": 0.00015315443436785507,
      "grad_norm": 1.9714572429656982,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.7837,
      "step": 7
    },
    {
      "epoch": 0.00017503363927754865,
      "grad_norm": 1.8994066715240479,
      "learning_rate": 0.00010666666666666667,
      "loss": 1.7141,
      "step": 8
    },
    {
      "epoch": 0.00019691284418724223,
      "grad_norm": 1.8724703788757324,
      "learning_rate": 0.00012,
      "loss": 1.6298,
      "step": 9
    },
    {
      "epoch": 0.00021879204909693582,
      "grad_norm": 1.959097146987915,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.5378,
      "step": 10
    },
    {
      "epoch": 0.0002406712540066294,
      "grad_norm": 2.1745142936706543,
      "learning_rate": 0.00014666666666666666,
      "loss": 1.4415,
      "step": 11
    },
    {
      "epoch": 0.000262550458916323,
      "grad_norm": 2.607661724090576,
      "learning_rate": 0.00016,
      "loss": 1.3404,
      "step": 12
    },
    {
      "epoch": 0.00028442966382601656,
      "grad_norm": 3.190854072570801,
      "learning_rate": 0.00017333333333333334,
      "loss": 1.2263,
      "step": 13
    },
    {
      "epoch": 0.00030630886873571014,
      "grad_norm": 3.342180013656616,
      "learning_rate": 0.0001866666666666667,
      "loss": 1.1137,
      "step": 14
    },
    {
      "epoch": 0.0003281880736454037,
      "grad_norm": 3.4205572605133057,
      "learning_rate": 0.0002,
      "loss": 1.0028,
      "step": 15
    },
    {
      "epoch": 0.0003500672785550973,
      "grad_norm": 2.9263808727264404,
      "learning_rate": 0.00019999790210013988,
      "loss": 0.883,
      "step": 16
    },
    {
      "epoch": 0.0003719464834647909,
      "grad_norm": 3.520387649536133,
      "learning_rate": 0.0001999916084885832,
      "loss": 0.7542,
      "step": 17
    },
    {
      "epoch": 0.00039382568837448447,
      "grad_norm": 3.553908109664917,
      "learning_rate": 0.0001999811194293973,
      "loss": 0.6119,
      "step": 18
    },
    {
      "epoch": 0.00041570489328417805,
      "grad_norm": 3.627412796020508,
      "learning_rate": 0.00019996643536268204,
      "loss": 0.4801,
      "step": 19
    },
    {
      "epoch": 0.00043758409819387163,
      "grad_norm": 3.0959208011627197,
      "learning_rate": 0.00019994755690455152,
      "loss": 0.3542,
      "step": 20
    },
    {
      "epoch": 0.0004594633031035652,
      "grad_norm": 2.9648001194000244,
      "learning_rate": 0.00019992448484710797,
      "loss": 0.2749,
      "step": 21
    },
    {
      "epoch": 0.0004813425080132588,
      "grad_norm": 3.2515716552734375,
      "learning_rate": 0.0001998972201584088,
      "loss": 0.2131,
      "step": 22
    },
    {
      "epoch": 0.0005032217129229524,
      "grad_norm": 2.1878955364227295,
      "learning_rate": 0.00019986576398242566,
      "loss": 0.1572,
      "step": 23
    },
    {
      "epoch": 0.000525100917832646,
      "grad_norm": 1.5718523263931274,
      "learning_rate": 0.00019983011763899673,
      "loss": 0.1132,
      "step": 24
    },
    {
      "epoch": 0.0005469801227423396,
      "grad_norm": 1.2340595722198486,
      "learning_rate": 0.00019979028262377118,
      "loss": 0.0878,
      "step": 25
    },
    {
      "epoch": 0.0005688593276520331,
      "grad_norm": 1.176327109336853,
      "learning_rate": 0.00019974626060814647,
      "loss": 0.0703,
      "step": 26
    },
    {
      "epoch": 0.0005907385325617268,
      "grad_norm": 0.5647863149642944,
      "learning_rate": 0.00019969805343919821,
      "loss": 0.0576,
      "step": 27
    },
    {
      "epoch": 0.0006126177374714203,
      "grad_norm": 0.5570607781410217,
      "learning_rate": 0.00019964566313960264,
      "loss": 0.0554,
      "step": 28
    },
    {
      "epoch": 0.0006344969423811139,
      "grad_norm": 0.1793261468410492,
      "learning_rate": 0.00019958909190755187,
      "loss": 0.0538,
      "step": 29
    },
    {
      "epoch": 0.0006563761472908074,
      "grad_norm": 0.2550106346607208,
      "learning_rate": 0.0001995283421166614,
      "loss": 0.0531,
      "step": 30
    },
    {
      "epoch": 0.0006782553522005011,
      "grad_norm": 0.11415762454271317,
      "learning_rate": 0.00019946341631587087,
      "loss": 0.0524,
      "step": 31
    },
    {
      "epoch": 0.0007001345571101946,
      "grad_norm": 0.1023230031132698,
      "learning_rate": 0.0001993943172293368,
      "loss": 0.0517,
      "step": 32
    },
    {
      "epoch": 0.0007220137620198882,
      "grad_norm": 0.11778868734836578,
      "learning_rate": 0.00019932104775631846,
      "loss": 0.051,
      "step": 33
    },
    {
      "epoch": 0.0007438929669295818,
      "grad_norm": 0.08875364810228348,
      "learning_rate": 0.00019924361097105623,
      "loss": 0.0499,
      "step": 34
    },
    {
      "epoch": 0.0007657721718392754,
      "grad_norm": 0.09308381378650665,
      "learning_rate": 0.00019916201012264254,
      "loss": 0.0489,
      "step": 35
    },
    {
      "epoch": 0.0007876513767489689,
      "grad_norm": 0.0945400595664978,
      "learning_rate": 0.0001990762486348855,
      "loss": 0.0479,
      "step": 36
    },
    {
      "epoch": 0.0008095305816586626,
      "grad_norm": 0.1023479551076889,
      "learning_rate": 0.00019898633010616542,
      "loss": 0.0464,
      "step": 37
    },
    {
      "epoch": 0.0008314097865683561,
      "grad_norm": 0.10884969681501389,
      "learning_rate": 0.00019889225830928365,
      "loss": 0.045,
      "step": 38
    },
    {
      "epoch": 0.0008532889914780497,
      "grad_norm": 0.11365334689617157,
      "learning_rate": 0.0001987940371913044,
      "loss": 0.0435,
      "step": 39
    },
    {
      "epoch": 0.0008751681963877433,
      "grad_norm": 0.11925841122865677,
      "learning_rate": 0.00019869167087338907,
      "loss": 0.0415,
      "step": 40
    },
    {
      "epoch": 0.0008970474012974369,
      "grad_norm": 0.11861640959978104,
      "learning_rate": 0.00019858516365062334,
      "loss": 0.0399,
      "step": 41
    },
    {
      "epoch": 0.0009189266062071304,
      "grad_norm": 0.11594705283641815,
      "learning_rate": 0.00019847451999183694,
      "loss": 0.0379,
      "step": 42
    },
    {
      "epoch": 0.0009408058111168241,
      "grad_norm": 0.11197011917829514,
      "learning_rate": 0.0001983597445394162,
      "loss": 0.0358,
      "step": 43
    },
    {
      "epoch": 0.0009626850160265176,
      "grad_norm": 0.09586818516254425,
      "learning_rate": 0.00019824084210910925,
      "loss": 0.0345,
      "step": 44
    },
    {
      "epoch": 0.0009845642209362112,
      "grad_norm": 0.10439009219408035,
      "learning_rate": 0.0001981178176898239,
      "loss": 0.0328,
      "step": 45
    },
    {
      "epoch": 0.0010064434258459049,
      "grad_norm": 0.10716534405946732,
      "learning_rate": 0.00019799067644341844,
      "loss": 0.0311,
      "step": 46
    },
    {
      "epoch": 0.0010283226307555983,
      "grad_norm": 0.1142977625131607,
      "learning_rate": 0.0001978594237044849,
      "loss": 0.0294,
      "step": 47
    },
    {
      "epoch": 0.001050201835665292,
      "grad_norm": 0.12401028722524643,
      "learning_rate": 0.0001977240649801253,
      "loss": 0.0278,
      "step": 48
    },
    {
      "epoch": 0.0010720810405749855,
      "grad_norm": 0.1462494283914566,
      "learning_rate": 0.00019758460594972068,
      "loss": 0.0257,
      "step": 49
    },
    {
      "epoch": 0.0010939602454846792,
      "grad_norm": 0.17686037719249725,
      "learning_rate": 0.00019744105246469263,
      "loss": 0.0227,
      "step": 50
    },
    {
      "epoch": 0.0011158394503943726,
      "grad_norm": 0.184061199426651,
      "learning_rate": 0.00019729341054825782,
      "loss": 0.0194,
      "step": 51
    },
    {
      "epoch": 0.0011377186553040662,
      "grad_norm": 0.24457122385501862,
      "learning_rate": 0.00019714168639517544,
      "loss": 0.0139,
      "step": 52
    },
    {
      "epoch": 0.0011595978602137599,
      "grad_norm": 0.2658323645591736,
      "learning_rate": 0.00019698588637148703,
      "loss": 0.0064,
      "step": 53
    },
    {
      "epoch": 0.0011814770651234535,
      "grad_norm": 0.10777610540390015,
      "learning_rate": 0.0001968260170142496,
      "loss": 0.0014,
      "step": 54
    },
    {
      "epoch": 0.001203356270033147,
      "grad_norm": 0.04989726096391678,
      "learning_rate": 0.00019666208503126112,
      "loss": 0.0013,
      "step": 55
    },
    {
      "epoch": 0.0012252354749428406,
      "grad_norm": 0.022917961701750755,
      "learning_rate": 0.00019649409730077935,
      "loss": 0.0003,
      "step": 56
    },
    {
      "epoch": 0.0012471146798525342,
      "grad_norm": 0.037820860743522644,
      "learning_rate": 0.00019632206087123296,
      "loss": 0.0003,
      "step": 57
    },
    {
      "epoch": 0.0012689938847622278,
      "grad_norm": 0.06782130151987076,
      "learning_rate": 0.000196145982960926,
      "loss": 0.0005,
      "step": 58
    },
    {
      "epoch": 0.0012908730896719213,
      "grad_norm": 0.08147301524877548,
      "learning_rate": 0.00019596587095773495,
      "loss": 0.0007,
      "step": 59
    },
    {
      "epoch": 0.0013127522945816149,
      "grad_norm": 0.17314109206199646,
      "learning_rate": 0.00019578173241879872,
      "loss": 0.0027,
      "step": 60
    },
    {
      "epoch": 0.0013346314994913085,
      "grad_norm": 0.10285378992557526,
      "learning_rate": 0.00019559357507020162,
      "loss": 0.0009,
      "step": 61
    },
    {
      "epoch": 0.0013565107044010022,
      "grad_norm": 0.07102896273136139,
      "learning_rate": 0.00019540140680664913,
      "loss": 0.0007,
      "step": 62
    },
    {
      "epoch": 0.0013783899093106956,
      "grad_norm": 0.03365343436598778,
      "learning_rate": 0.00019520523569113677,
      "loss": 0.0004,
      "step": 63
    },
    {
      "epoch": 0.0014002691142203892,
      "grad_norm": 0.031999796628952026,
      "learning_rate": 0.0001950050699546116,
      "loss": 0.0003,
      "step": 64
    },
    {
      "epoch": 0.0014221483191300829,
      "grad_norm": 0.04584983363747597,
      "learning_rate": 0.00019480091799562704,
      "loss": 0.0003,
      "step": 65
    },
    {
      "epoch": 0.0014440275240397765,
      "grad_norm": 0.03766440972685814,
      "learning_rate": 0.00019459278837999046,
      "loss": 0.0002,
      "step": 66
    },
    {
      "epoch": 0.00146590672894947,
      "grad_norm": 0.021271293982863426,
      "learning_rate": 0.00019438068984040365,
      "loss": 0.0002,
      "step": 67
    },
    {
      "epoch": 0.0014877859338591635,
      "grad_norm": 0.01841471716761589,
      "learning_rate": 0.00019416463127609656,
      "loss": 0.0002,
      "step": 68
    },
    {
      "epoch": 0.0015096651387688572,
      "grad_norm": 0.012171072885394096,
      "learning_rate": 0.00019394462175245381,
      "loss": 0.0001,
      "step": 69
    },
    {
      "epoch": 0.0015315443436785508,
      "grad_norm": 0.012839977629482746,
      "learning_rate": 0.00019372067050063438,
      "loss": 0.0001,
      "step": 70
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 5,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3254411657871360.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
