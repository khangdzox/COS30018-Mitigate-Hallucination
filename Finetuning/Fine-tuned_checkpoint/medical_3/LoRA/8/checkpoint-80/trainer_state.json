{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0024221322332816106,
  "eval_steps": 500,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 3.0276652916020135e-05,
      "grad_norm": 1.4668304920196533,
      "learning_rate": 5e-05,
      "loss": 1.8623,
      "step": 1
    },
    {
      "epoch": 6.055330583204027e-05,
      "grad_norm": 1.6593025922775269,
      "learning_rate": 0.0001,
      "loss": 1.9597,
      "step": 2
    },
    {
      "epoch": 9.08299587480604e-05,
      "grad_norm": 1.7948641777038574,
      "learning_rate": 0.00015000000000000001,
      "loss": 1.9895,
      "step": 3
    },
    {
      "epoch": 0.00012110661166408054,
      "grad_norm": 1.5621790885925293,
      "learning_rate": 0.0002,
      "loss": 2.1578,
      "step": 4
    },
    {
      "epoch": 0.00015138326458010066,
      "grad_norm": 1.4498673677444458,
      "learning_rate": 0.00019995608365087946,
      "loss": 2.0584,
      "step": 5
    },
    {
      "epoch": 0.0001816599174961208,
      "grad_norm": 1.382967233657837,
      "learning_rate": 0.00019982437317643217,
      "loss": 1.8342,
      "step": 6
    },
    {
      "epoch": 0.00021193657041214094,
      "grad_norm": 1.5250414609909058,
      "learning_rate": 0.0001996049842615217,
      "loss": 1.9802,
      "step": 7
    },
    {
      "epoch": 0.00024221322332816108,
      "grad_norm": 1.6097261905670166,
      "learning_rate": 0.00019929810960135172,
      "loss": 1.7037,
      "step": 8
    },
    {
      "epoch": 0.0002724898762441812,
      "grad_norm": 1.8662399053573608,
      "learning_rate": 0.0001989040187322164,
      "loss": 1.6309,
      "step": 9
    },
    {
      "epoch": 0.00030276652916020133,
      "grad_norm": 2.1611287593841553,
      "learning_rate": 0.00019842305779475968,
      "loss": 1.4286,
      "step": 10
    },
    {
      "epoch": 0.0003330431820762215,
      "grad_norm": 2.061006784439087,
      "learning_rate": 0.0001978556492299504,
      "loss": 1.5334,
      "step": 11
    },
    {
      "epoch": 0.0003633198349922416,
      "grad_norm": 2.125108003616333,
      "learning_rate": 0.0001972022914080411,
      "loss": 1.3817,
      "step": 12
    },
    {
      "epoch": 0.0003935964879082617,
      "grad_norm": 2.0617692470550537,
      "learning_rate": 0.00019646355819083589,
      "loss": 1.4894,
      "step": 13
    },
    {
      "epoch": 0.0004238731408242819,
      "grad_norm": 2.238469362258911,
      "learning_rate": 0.00019564009842765225,
      "loss": 1.2419,
      "step": 14
    },
    {
      "epoch": 0.000454149793740302,
      "grad_norm": 2.0489492416381836,
      "learning_rate": 0.00019473263538541914,
      "loss": 1.1458,
      "step": 15
    },
    {
      "epoch": 0.00048442644665632216,
      "grad_norm": 1.867798089981079,
      "learning_rate": 0.0001937419661134121,
      "loss": 1.077,
      "step": 16
    },
    {
      "epoch": 0.0005147030995723423,
      "grad_norm": 2.242382287979126,
      "learning_rate": 0.00019266896074318334,
      "loss": 1.1701,
      "step": 17
    },
    {
      "epoch": 0.0005449797524883624,
      "grad_norm": 2.5701630115509033,
      "learning_rate": 0.00019151456172430183,
      "loss": 1.1077,
      "step": 18
    },
    {
      "epoch": 0.0005752564054043826,
      "grad_norm": 2.1306097507476807,
      "learning_rate": 0.00019027978299657436,
      "loss": 0.9783,
      "step": 19
    },
    {
      "epoch": 0.0006055330583204027,
      "grad_norm": 1.8122090101242065,
      "learning_rate": 0.00018896570909947475,
      "loss": 1.0273,
      "step": 20
    },
    {
      "epoch": 0.0006358097112364228,
      "grad_norm": 1.670584797859192,
      "learning_rate": 0.0001875734942195637,
      "loss": 0.9027,
      "step": 21
    },
    {
      "epoch": 0.000666086364152443,
      "grad_norm": 1.6872596740722656,
      "learning_rate": 0.00018610436117673555,
      "loss": 0.8324,
      "step": 22
    },
    {
      "epoch": 0.000696363017068463,
      "grad_norm": 1.849846363067627,
      "learning_rate": 0.0001845596003501826,
      "loss": 0.9805,
      "step": 23
    },
    {
      "epoch": 0.0007266396699844832,
      "grad_norm": 1.6319371461868286,
      "learning_rate": 0.0001829405685450202,
      "loss": 0.8242,
      "step": 24
    },
    {
      "epoch": 0.0007569163229005034,
      "grad_norm": 1.4492262601852417,
      "learning_rate": 0.00018124868780056814,
      "loss": 0.8579,
      "step": 25
    },
    {
      "epoch": 0.0007871929758165234,
      "grad_norm": 1.2127891778945923,
      "learning_rate": 0.00017948544414133534,
      "loss": 0.7515,
      "step": 26
    },
    {
      "epoch": 0.0008174696287325436,
      "grad_norm": 1.3559280633926392,
      "learning_rate": 0.00017765238627180424,
      "loss": 0.8632,
      "step": 27
    },
    {
      "epoch": 0.0008477462816485638,
      "grad_norm": 1.3536165952682495,
      "learning_rate": 0.00017575112421616202,
      "loss": 0.8199,
      "step": 28
    },
    {
      "epoch": 0.0008780229345645839,
      "grad_norm": 1.385805606842041,
      "learning_rate": 0.00017378332790417273,
      "loss": 0.8939,
      "step": 29
    },
    {
      "epoch": 0.000908299587480604,
      "grad_norm": 0.9772305488586426,
      "learning_rate": 0.00017175072570443312,
      "loss": 0.653,
      "step": 30
    },
    {
      "epoch": 0.0009385762403966242,
      "grad_norm": 1.664683222770691,
      "learning_rate": 0.00016965510290629972,
      "loss": 0.8508,
      "step": 31
    },
    {
      "epoch": 0.0009688528933126443,
      "grad_norm": 1.182698369026184,
      "learning_rate": 0.00016749830015182107,
      "loss": 0.6437,
      "step": 32
    },
    {
      "epoch": 0.0009991295462286644,
      "grad_norm": 1.2136520147323608,
      "learning_rate": 0.00016528221181905217,
      "loss": 0.5938,
      "step": 33
    },
    {
      "epoch": 0.0010294061991446845,
      "grad_norm": 1.352786898612976,
      "learning_rate": 0.00016300878435817113,
      "loss": 0.673,
      "step": 34
    },
    {
      "epoch": 0.0010596828520607047,
      "grad_norm": 1.1194936037063599,
      "learning_rate": 0.00016068001458185936,
      "loss": 0.6741,
      "step": 35
    },
    {
      "epoch": 0.0010899595049767249,
      "grad_norm": 1.9088859558105469,
      "learning_rate": 0.0001582979479114472,
      "loss": 0.6247,
      "step": 36
    },
    {
      "epoch": 0.001120236157892745,
      "grad_norm": 1.1167515516281128,
      "learning_rate": 0.00015586467658036524,
      "loss": 0.6006,
      "step": 37
    },
    {
      "epoch": 0.0011505128108087652,
      "grad_norm": 1.3872231245040894,
      "learning_rate": 0.0001533823377964791,
      "loss": 0.6133,
      "step": 38
    },
    {
      "epoch": 0.0011807894637247851,
      "grad_norm": 1.2771130800247192,
      "learning_rate": 0.00015085311186492206,
      "loss": 0.5103,
      "step": 39
    },
    {
      "epoch": 0.0012110661166408053,
      "grad_norm": 1.259818196296692,
      "learning_rate": 0.00014827922027307451,
      "loss": 0.5808,
      "step": 40
    },
    {
      "epoch": 0.0012413427695568255,
      "grad_norm": 0.9952660799026489,
      "learning_rate": 0.0001456629237393713,
      "loss": 0.5877,
      "step": 41
    },
    {
      "epoch": 0.0012716194224728456,
      "grad_norm": 1.2354487180709839,
      "learning_rate": 0.00014300652022765207,
      "loss": 0.437,
      "step": 42
    },
    {
      "epoch": 0.0013018960753888658,
      "grad_norm": 1.0839240550994873,
      "learning_rate": 0.00014031234292879725,
      "loss": 0.4279,
      "step": 43
    },
    {
      "epoch": 0.001332172728304886,
      "grad_norm": 1.1316877603530884,
      "learning_rate": 0.00013758275821142382,
      "loss": 0.4053,
      "step": 44
    },
    {
      "epoch": 0.001362449381220906,
      "grad_norm": 1.326482892036438,
      "learning_rate": 0.0001348201635434399,
      "loss": 0.4811,
      "step": 45
    },
    {
      "epoch": 0.001392726034136926,
      "grad_norm": 0.9464036226272583,
      "learning_rate": 0.00013202698538628376,
      "loss": 0.4375,
      "step": 46
    },
    {
      "epoch": 0.0014230026870529463,
      "grad_norm": 0.8832843899726868,
      "learning_rate": 0.00012920567706369758,
      "loss": 0.3273,
      "step": 47
    },
    {
      "epoch": 0.0014532793399689664,
      "grad_norm": 1.110411286354065,
      "learning_rate": 0.00012635871660690676,
      "loss": 0.3015,
      "step": 48
    },
    {
      "epoch": 0.0014835559928849866,
      "grad_norm": 1.3554366827011108,
      "learning_rate": 0.00012348860457809838,
      "loss": 0.3406,
      "step": 49
    },
    {
      "epoch": 0.0015138326458010067,
      "grad_norm": 1.3713183403015137,
      "learning_rate": 0.00012059786187410984,
      "loss": 0.3368,
      "step": 50
    },
    {
      "epoch": 0.001544109298717027,
      "grad_norm": 1.253024697303772,
      "learning_rate": 0.0001176890275122573,
      "loss": 1.0374,
      "step": 51
    },
    {
      "epoch": 0.0015743859516330469,
      "grad_norm": 1.3566477298736572,
      "learning_rate": 0.00011476465640024814,
      "loss": 1.0865,
      "step": 52
    },
    {
      "epoch": 0.001604662604549067,
      "grad_norm": 1.2665836811065674,
      "learning_rate": 0.00011182731709213659,
      "loss": 1.0419,
      "step": 53
    },
    {
      "epoch": 0.0016349392574650872,
      "grad_norm": 1.2099765539169312,
      "learning_rate": 0.00010887958953229349,
      "loss": 1.251,
      "step": 54
    },
    {
      "epoch": 0.0016652159103811074,
      "grad_norm": 1.2934011220932007,
      "learning_rate": 0.00010592406278937144,
      "loss": 1.1204,
      "step": 55
    },
    {
      "epoch": 0.0016954925632971275,
      "grad_norm": 1.05939781665802,
      "learning_rate": 0.00010296333278225599,
      "loss": 0.9628,
      "step": 56
    },
    {
      "epoch": 0.0017257692162131477,
      "grad_norm": 1.1220546960830688,
      "learning_rate": 0.0001,
      "loss": 1.0332,
      "step": 57
    },
    {
      "epoch": 0.0017560458691291679,
      "grad_norm": 0.9845422506332397,
      "learning_rate": 9.703666721774402e-05,
      "loss": 0.8024,
      "step": 58
    },
    {
      "epoch": 0.0017863225220451878,
      "grad_norm": 1.0648114681243896,
      "learning_rate": 9.407593721062859e-05,
      "loss": 0.9536,
      "step": 59
    },
    {
      "epoch": 0.001816599174961208,
      "grad_norm": 1.0252389907836914,
      "learning_rate": 9.112041046770653e-05,
      "loss": 0.9636,
      "step": 60
    },
    {
      "epoch": 0.0018468758278772281,
      "grad_norm": 1.0196503400802612,
      "learning_rate": 8.817268290786343e-05,
      "loss": 1.071,
      "step": 61
    },
    {
      "epoch": 0.0018771524807932483,
      "grad_norm": 1.1029592752456665,
      "learning_rate": 8.523534359975189e-05,
      "loss": 1.0879,
      "step": 62
    },
    {
      "epoch": 0.0019074291337092685,
      "grad_norm": 0.9431998133659363,
      "learning_rate": 8.231097248774274e-05,
      "loss": 0.9685,
      "step": 63
    },
    {
      "epoch": 0.0019377057866252886,
      "grad_norm": 0.9531177282333374,
      "learning_rate": 7.940213812589018e-05,
      "loss": 0.9068,
      "step": 64
    },
    {
      "epoch": 0.001967982439541309,
      "grad_norm": 0.8924325108528137,
      "learning_rate": 7.651139542190164e-05,
      "loss": 0.7742,
      "step": 65
    },
    {
      "epoch": 0.0019982590924573287,
      "grad_norm": 0.885455310344696,
      "learning_rate": 7.364128339309326e-05,
      "loss": 0.8924,
      "step": 66
    },
    {
      "epoch": 0.002028535745373349,
      "grad_norm": 1.068449854850769,
      "learning_rate": 7.079432293630244e-05,
      "loss": 0.8731,
      "step": 67
    },
    {
      "epoch": 0.002058812398289369,
      "grad_norm": 1.0463415384292603,
      "learning_rate": 6.797301461371625e-05,
      "loss": 0.6456,
      "step": 68
    },
    {
      "epoch": 0.0020890890512053895,
      "grad_norm": 1.0465760231018066,
      "learning_rate": 6.517983645656014e-05,
      "loss": 0.7769,
      "step": 69
    },
    {
      "epoch": 0.0021193657041214094,
      "grad_norm": 0.9121266007423401,
      "learning_rate": 6.24172417885762e-05,
      "loss": 0.7056,
      "step": 70
    },
    {
      "epoch": 0.0021496423570374294,
      "grad_norm": 0.9966779351234436,
      "learning_rate": 5.96876570712028e-05,
      "loss": 0.7491,
      "step": 71
    },
    {
      "epoch": 0.0021799190099534497,
      "grad_norm": 0.9276207685470581,
      "learning_rate": 5.699347977234799e-05,
      "loss": 0.729,
      "step": 72
    },
    {
      "epoch": 0.0022101956628694697,
      "grad_norm": 1.0599206686019897,
      "learning_rate": 5.43370762606287e-05,
      "loss": 0.6187,
      "step": 73
    },
    {
      "epoch": 0.00224047231578549,
      "grad_norm": 1.1952755451202393,
      "learning_rate": 5.172077972692553e-05,
      "loss": 0.7836,
      "step": 74
    },
    {
      "epoch": 0.00227074896870151,
      "grad_norm": 0.9379297494888306,
      "learning_rate": 4.914688813507797e-05,
      "loss": 0.6953,
      "step": 75
    },
    {
      "epoch": 0.0023010256216175304,
      "grad_norm": 1.0822131633758545,
      "learning_rate": 4.661766220352097e-05,
      "loss": 0.9317,
      "step": 76
    },
    {
      "epoch": 0.0023313022745335503,
      "grad_norm": 1.0163710117340088,
      "learning_rate": 4.4135323419634766e-05,
      "loss": 0.7919,
      "step": 77
    },
    {
      "epoch": 0.0023615789274495703,
      "grad_norm": 1.2942957878112793,
      "learning_rate": 4.170205208855281e-05,
      "loss": 0.827,
      "step": 78
    },
    {
      "epoch": 0.0023918555803655907,
      "grad_norm": 0.9978819489479065,
      "learning_rate": 3.931998541814069e-05,
      "loss": 0.6758,
      "step": 79
    },
    {
      "epoch": 0.0024221322332816106,
      "grad_norm": 0.9904923439025879,
      "learning_rate": 3.69912156418289e-05,
      "loss": 0.6467,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4520767024742400.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
