{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0009080229502800684,
  "eval_steps": 500,
  "global_step": 40,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 2.2700573757001707e-05,
      "grad_norm": 0.9501461982727051,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.9633,
      "step": 1
    },
    {
      "epoch": 4.5401147514003414e-05,
      "grad_norm": 1.0185853242874146,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.9197,
      "step": 2
    },
    {
      "epoch": 6.810172127100512e-05,
      "grad_norm": 1.1307960748672485,
      "learning_rate": 0.0002,
      "loss": 1.8523,
      "step": 3
    },
    {
      "epoch": 9.080229502800683e-05,
      "grad_norm": 1.051649808883667,
      "learning_rate": 0.00019994755690455152,
      "loss": 1.8885,
      "step": 4
    },
    {
      "epoch": 0.00011350286878500855,
      "grad_norm": 1.0204728841781616,
      "learning_rate": 0.00019979028262377118,
      "loss": 1.8144,
      "step": 5
    },
    {
      "epoch": 0.00013620344254201025,
      "grad_norm": 0.984409749507904,
      "learning_rate": 0.0001995283421166614,
      "loss": 1.8067,
      "step": 6
    },
    {
      "epoch": 0.00015890401629901197,
      "grad_norm": 1.2277554273605347,
      "learning_rate": 0.00019916201012264254,
      "loss": 1.7299,
      "step": 7
    },
    {
      "epoch": 0.00018160459005601366,
      "grad_norm": 1.8049137592315674,
      "learning_rate": 0.00019869167087338907,
      "loss": 1.7179,
      "step": 8
    },
    {
      "epoch": 0.00020430516381301537,
      "grad_norm": 1.8770530223846436,
      "learning_rate": 0.0001981178176898239,
      "loss": 1.5376,
      "step": 9
    },
    {
      "epoch": 0.0002270057375700171,
      "grad_norm": 1.6093263626098633,
      "learning_rate": 0.00019744105246469263,
      "loss": 1.4271,
      "step": 10
    },
    {
      "epoch": 0.0002497063113270188,
      "grad_norm": 1.4771573543548584,
      "learning_rate": 0.00019666208503126112,
      "loss": 1.3775,
      "step": 11
    },
    {
      "epoch": 0.0002724068850840205,
      "grad_norm": 1.6203402280807495,
      "learning_rate": 0.00019578173241879872,
      "loss": 1.3661,
      "step": 12
    },
    {
      "epoch": 0.0002951074588410222,
      "grad_norm": 1.7377996444702148,
      "learning_rate": 0.00019480091799562704,
      "loss": 1.1979,
      "step": 13
    },
    {
      "epoch": 0.00031780803259802393,
      "grad_norm": 1.9253300428390503,
      "learning_rate": 0.00019372067050063438,
      "loss": 1.1097,
      "step": 14
    },
    {
      "epoch": 0.0003405086063550256,
      "grad_norm": 2.057133913040161,
      "learning_rate": 0.00019254212296427044,
      "loss": 1.0522,
      "step": 15
    },
    {
      "epoch": 0.0003632091801120273,
      "grad_norm": 2.060406446456909,
      "learning_rate": 0.00019126651152015403,
      "loss": 0.8713,
      "step": 16
    },
    {
      "epoch": 0.00038590975386902903,
      "grad_norm": 1.8746546506881714,
      "learning_rate": 0.00018989517410853955,
      "loss": 0.7238,
      "step": 17
    },
    {
      "epoch": 0.00040861032762603075,
      "grad_norm": 1.8379669189453125,
      "learning_rate": 0.00018842954907300236,
      "loss": 0.6903,
      "step": 18
    },
    {
      "epoch": 0.00043131090138303247,
      "grad_norm": 1.7415162324905396,
      "learning_rate": 0.00018687117365181512,
      "loss": 0.6258,
      "step": 19
    },
    {
      "epoch": 0.0004540114751400342,
      "grad_norm": 1.6827548742294312,
      "learning_rate": 0.00018522168236559695,
      "loss": 0.606,
      "step": 20
    },
    {
      "epoch": 0.00047671204889703585,
      "grad_norm": 1.5342785120010376,
      "learning_rate": 0.00018348280530292713,
      "loss": 0.6074,
      "step": 21
    },
    {
      "epoch": 0.0004994126226540376,
      "grad_norm": 1.1195968389511108,
      "learning_rate": 0.0001816563663057211,
      "loss": 0.4628,
      "step": 22
    },
    {
      "epoch": 0.0005221131964110393,
      "grad_norm": 1.1261191368103027,
      "learning_rate": 0.00017974428105627208,
      "loss": 0.4481,
      "step": 23
    },
    {
      "epoch": 0.000544813770168041,
      "grad_norm": 1.0615310668945312,
      "learning_rate": 0.00017774855506796496,
      "loss": 0.4287,
      "step": 24
    },
    {
      "epoch": 0.0005675143439250427,
      "grad_norm": 0.9740415215492249,
      "learning_rate": 0.00017567128158176953,
      "loss": 0.4236,
      "step": 25
    },
    {
      "epoch": 0.0005902149176820444,
      "grad_norm": 1.1370452642440796,
      "learning_rate": 0.00017351463937072004,
      "loss": 0.3944,
      "step": 26
    },
    {
      "epoch": 0.0006129154914390462,
      "grad_norm": 0.9661886692047119,
      "learning_rate": 0.00017128089045468294,
      "loss": 0.408,
      "step": 27
    },
    {
      "epoch": 0.0006356160651960479,
      "grad_norm": 0.9698948860168457,
      "learning_rate": 0.00016897237772781044,
      "loss": 0.3523,
      "step": 28
    },
    {
      "epoch": 0.0006583166389530496,
      "grad_norm": 0.9142641425132751,
      "learning_rate": 0.00016659152250116812,
      "loss": 0.2934,
      "step": 29
    },
    {
      "epoch": 0.0006810172127100512,
      "grad_norm": 0.8831595182418823,
      "learning_rate": 0.000164140821963114,
      "loss": 0.2698,
      "step": 30
    },
    {
      "epoch": 0.0007037177864670529,
      "grad_norm": 0.905476987361908,
      "learning_rate": 0.00016162284656009274,
      "loss": 0.3109,
      "step": 31
    },
    {
      "epoch": 0.0007264183602240546,
      "grad_norm": 0.6676744818687439,
      "learning_rate": 0.00015904023730059228,
      "loss": 0.2956,
      "step": 32
    },
    {
      "epoch": 0.0007491189339810563,
      "grad_norm": 0.8665741086006165,
      "learning_rate": 0.00015639570298509064,
      "loss": 0.3313,
      "step": 33
    },
    {
      "epoch": 0.0007718195077380581,
      "grad_norm": 0.6626325845718384,
      "learning_rate": 0.0001536920173648984,
      "loss": 0.3163,
      "step": 34
    },
    {
      "epoch": 0.0007945200814950598,
      "grad_norm": 0.5097549557685852,
      "learning_rate": 0.00015093201623287631,
      "loss": 0.2335,
      "step": 35
    },
    {
      "epoch": 0.0008172206552520615,
      "grad_norm": 0.6233903765678406,
      "learning_rate": 0.00014811859444908052,
      "loss": 0.2419,
      "step": 36
    },
    {
      "epoch": 0.0008399212290090632,
      "grad_norm": 0.5715733170509338,
      "learning_rate": 0.00014525470290445392,
      "loss": 0.1935,
      "step": 37
    },
    {
      "epoch": 0.0008626218027660649,
      "grad_norm": 0.5108813047409058,
      "learning_rate": 0.00014234334542574906,
      "loss": 0.253,
      "step": 38
    },
    {
      "epoch": 0.0008853223765230667,
      "grad_norm": 0.4806022644042969,
      "learning_rate": 0.00013938757562492873,
      "loss": 0.2199,
      "step": 39
    },
    {
      "epoch": 0.0009080229502800684,
      "grad_norm": 0.4637565612792969,
      "learning_rate": 0.00013639049369634876,
      "loss": 0.2181,
      "step": 40
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5388700233498624.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
