{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.002270057375700171,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 2.2700573757001707e-05,
      "grad_norm": 0.9501461982727051,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.9633,
      "step": 1
    },
    {
      "epoch": 4.5401147514003414e-05,
      "grad_norm": 1.0185853242874146,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.9197,
      "step": 2
    },
    {
      "epoch": 6.810172127100512e-05,
      "grad_norm": 1.1307960748672485,
      "learning_rate": 0.0002,
      "loss": 1.8523,
      "step": 3
    },
    {
      "epoch": 9.080229502800683e-05,
      "grad_norm": 1.051649808883667,
      "learning_rate": 0.00019994755690455152,
      "loss": 1.8885,
      "step": 4
    },
    {
      "epoch": 0.00011350286878500855,
      "grad_norm": 1.0204728841781616,
      "learning_rate": 0.00019979028262377118,
      "loss": 1.8144,
      "step": 5
    },
    {
      "epoch": 0.00013620344254201025,
      "grad_norm": 0.984409749507904,
      "learning_rate": 0.0001995283421166614,
      "loss": 1.8067,
      "step": 6
    },
    {
      "epoch": 0.00015890401629901197,
      "grad_norm": 1.2277554273605347,
      "learning_rate": 0.00019916201012264254,
      "loss": 1.7299,
      "step": 7
    },
    {
      "epoch": 0.00018160459005601366,
      "grad_norm": 1.8049137592315674,
      "learning_rate": 0.00019869167087338907,
      "loss": 1.7179,
      "step": 8
    },
    {
      "epoch": 0.00020430516381301537,
      "grad_norm": 1.8770530223846436,
      "learning_rate": 0.0001981178176898239,
      "loss": 1.5376,
      "step": 9
    },
    {
      "epoch": 0.0002270057375700171,
      "grad_norm": 1.6093263626098633,
      "learning_rate": 0.00019744105246469263,
      "loss": 1.4271,
      "step": 10
    },
    {
      "epoch": 0.0002497063113270188,
      "grad_norm": 1.4771573543548584,
      "learning_rate": 0.00019666208503126112,
      "loss": 1.3775,
      "step": 11
    },
    {
      "epoch": 0.0002724068850840205,
      "grad_norm": 1.6203402280807495,
      "learning_rate": 0.00019578173241879872,
      "loss": 1.3661,
      "step": 12
    },
    {
      "epoch": 0.0002951074588410222,
      "grad_norm": 1.7377996444702148,
      "learning_rate": 0.00019480091799562704,
      "loss": 1.1979,
      "step": 13
    },
    {
      "epoch": 0.00031780803259802393,
      "grad_norm": 1.9253300428390503,
      "learning_rate": 0.00019372067050063438,
      "loss": 1.1097,
      "step": 14
    },
    {
      "epoch": 0.0003405086063550256,
      "grad_norm": 2.057133913040161,
      "learning_rate": 0.00019254212296427044,
      "loss": 1.0522,
      "step": 15
    },
    {
      "epoch": 0.0003632091801120273,
      "grad_norm": 2.060406446456909,
      "learning_rate": 0.00019126651152015403,
      "loss": 0.8713,
      "step": 16
    },
    {
      "epoch": 0.00038590975386902903,
      "grad_norm": 1.8746546506881714,
      "learning_rate": 0.00018989517410853955,
      "loss": 0.7238,
      "step": 17
    },
    {
      "epoch": 0.00040861032762603075,
      "grad_norm": 1.8379669189453125,
      "learning_rate": 0.00018842954907300236,
      "loss": 0.6903,
      "step": 18
    },
    {
      "epoch": 0.00043131090138303247,
      "grad_norm": 1.7415162324905396,
      "learning_rate": 0.00018687117365181512,
      "loss": 0.6258,
      "step": 19
    },
    {
      "epoch": 0.0004540114751400342,
      "grad_norm": 1.6827548742294312,
      "learning_rate": 0.00018522168236559695,
      "loss": 0.606,
      "step": 20
    },
    {
      "epoch": 0.00047671204889703585,
      "grad_norm": 1.5342785120010376,
      "learning_rate": 0.00018348280530292713,
      "loss": 0.6074,
      "step": 21
    },
    {
      "epoch": 0.0004994126226540376,
      "grad_norm": 1.1195968389511108,
      "learning_rate": 0.0001816563663057211,
      "loss": 0.4628,
      "step": 22
    },
    {
      "epoch": 0.0005221131964110393,
      "grad_norm": 1.1261191368103027,
      "learning_rate": 0.00017974428105627208,
      "loss": 0.4481,
      "step": 23
    },
    {
      "epoch": 0.000544813770168041,
      "grad_norm": 1.0615310668945312,
      "learning_rate": 0.00017774855506796496,
      "loss": 0.4287,
      "step": 24
    },
    {
      "epoch": 0.0005675143439250427,
      "grad_norm": 0.9740415215492249,
      "learning_rate": 0.00017567128158176953,
      "loss": 0.4236,
      "step": 25
    },
    {
      "epoch": 0.0005902149176820444,
      "grad_norm": 1.1370452642440796,
      "learning_rate": 0.00017351463937072004,
      "loss": 0.3944,
      "step": 26
    },
    {
      "epoch": 0.0006129154914390462,
      "grad_norm": 0.9661886692047119,
      "learning_rate": 0.00017128089045468294,
      "loss": 0.408,
      "step": 27
    },
    {
      "epoch": 0.0006356160651960479,
      "grad_norm": 0.9698948860168457,
      "learning_rate": 0.00016897237772781044,
      "loss": 0.3523,
      "step": 28
    },
    {
      "epoch": 0.0006583166389530496,
      "grad_norm": 0.9142641425132751,
      "learning_rate": 0.00016659152250116812,
      "loss": 0.2934,
      "step": 29
    },
    {
      "epoch": 0.0006810172127100512,
      "grad_norm": 0.8831595182418823,
      "learning_rate": 0.000164140821963114,
      "loss": 0.2698,
      "step": 30
    },
    {
      "epoch": 0.0007037177864670529,
      "grad_norm": 0.905476987361908,
      "learning_rate": 0.00016162284656009274,
      "loss": 0.3109,
      "step": 31
    },
    {
      "epoch": 0.0007264183602240546,
      "grad_norm": 0.6676744818687439,
      "learning_rate": 0.00015904023730059228,
      "loss": 0.2956,
      "step": 32
    },
    {
      "epoch": 0.0007491189339810563,
      "grad_norm": 0.8665741086006165,
      "learning_rate": 0.00015639570298509064,
      "loss": 0.3313,
      "step": 33
    },
    {
      "epoch": 0.0007718195077380581,
      "grad_norm": 0.6626325845718384,
      "learning_rate": 0.0001536920173648984,
      "loss": 0.3163,
      "step": 34
    },
    {
      "epoch": 0.0007945200814950598,
      "grad_norm": 0.5097549557685852,
      "learning_rate": 0.00015093201623287631,
      "loss": 0.2335,
      "step": 35
    },
    {
      "epoch": 0.0008172206552520615,
      "grad_norm": 0.6233903765678406,
      "learning_rate": 0.00014811859444908052,
      "loss": 0.2419,
      "step": 36
    },
    {
      "epoch": 0.0008399212290090632,
      "grad_norm": 0.5715733170509338,
      "learning_rate": 0.00014525470290445392,
      "loss": 0.1935,
      "step": 37
    },
    {
      "epoch": 0.0008626218027660649,
      "grad_norm": 0.5108813047409058,
      "learning_rate": 0.00014234334542574906,
      "loss": 0.253,
      "step": 38
    },
    {
      "epoch": 0.0008853223765230667,
      "grad_norm": 0.4806022644042969,
      "learning_rate": 0.00013938757562492873,
      "loss": 0.2199,
      "step": 39
    },
    {
      "epoch": 0.0009080229502800684,
      "grad_norm": 0.4637565612792969,
      "learning_rate": 0.00013639049369634876,
      "loss": 0.2181,
      "step": 40
    },
    {
      "epoch": 0.0009307235240370701,
      "grad_norm": 0.5331452488899231,
      "learning_rate": 0.00013335524316508208,
      "loss": 0.1799,
      "step": 41
    },
    {
      "epoch": 0.0009534240977940717,
      "grad_norm": 0.5737295150756836,
      "learning_rate": 0.00013028500758979506,
      "loss": 0.1742,
      "step": 42
    },
    {
      "epoch": 0.0009761246715510734,
      "grad_norm": 0.4107550084590912,
      "learning_rate": 0.0001271830072236343,
      "loss": 0.1393,
      "step": 43
    },
    {
      "epoch": 0.0009988252453080751,
      "grad_norm": 0.4251871109008789,
      "learning_rate": 0.00012405249563662537,
      "loss": 0.1886,
      "step": 44
    },
    {
      "epoch": 0.001021525819065077,
      "grad_norm": 0.4731592833995819,
      "learning_rate": 0.00012089675630312754,
      "loss": 0.1657,
      "step": 45
    },
    {
      "epoch": 0.0010442263928220786,
      "grad_norm": 0.4348730146884918,
      "learning_rate": 0.0001177190991579223,
      "loss": 0.1453,
      "step": 46
    },
    {
      "epoch": 0.0010669269665790804,
      "grad_norm": 0.3554372787475586,
      "learning_rate": 0.00011452285712454904,
      "loss": 0.127,
      "step": 47
    },
    {
      "epoch": 0.001089627540336082,
      "grad_norm": 0.35831737518310547,
      "learning_rate": 0.00011131138261952845,
      "loss": 0.1167,
      "step": 48
    },
    {
      "epoch": 0.0011123281140930836,
      "grad_norm": 0.41575273871421814,
      "learning_rate": 0.00010808804403614043,
      "loss": 0.128,
      "step": 49
    },
    {
      "epoch": 0.0011350286878500854,
      "grad_norm": 0.35241252183914185,
      "learning_rate": 0.00010485622221144484,
      "loss": 0.103,
      "step": 50
    },
    {
      "epoch": 0.001157729261607087,
      "grad_norm": 0.7976404428482056,
      "learning_rate": 0.00010161930688025017,
      "loss": 0.7983,
      "step": 51
    },
    {
      "epoch": 0.0011804298353640889,
      "grad_norm": 0.8319048881530762,
      "learning_rate": 9.838069311974986e-05,
      "loss": 0.8259,
      "step": 52
    },
    {
      "epoch": 0.0012031304091210905,
      "grad_norm": 0.8559367060661316,
      "learning_rate": 9.514377778855521e-05,
      "loss": 0.6783,
      "step": 53
    },
    {
      "epoch": 0.0012258309828780923,
      "grad_norm": 0.7016587853431702,
      "learning_rate": 9.19119559638596e-05,
      "loss": 0.631,
      "step": 54
    },
    {
      "epoch": 0.001248531556635094,
      "grad_norm": 0.6487762331962585,
      "learning_rate": 8.868861738047158e-05,
      "loss": 0.5311,
      "step": 55
    },
    {
      "epoch": 0.0012712321303920957,
      "grad_norm": 0.5879743695259094,
      "learning_rate": 8.5477142875451e-05,
      "loss": 0.5807,
      "step": 56
    },
    {
      "epoch": 0.0012939327041490973,
      "grad_norm": 0.5547593832015991,
      "learning_rate": 8.228090084207774e-05,
      "loss": 0.5233,
      "step": 57
    },
    {
      "epoch": 0.0013166332779060992,
      "grad_norm": 0.5915609002113342,
      "learning_rate": 7.91032436968725e-05,
      "loss": 0.5088,
      "step": 58
    },
    {
      "epoch": 0.0013393338516631008,
      "grad_norm": 0.5596252679824829,
      "learning_rate": 7.594750436337467e-05,
      "loss": 0.5775,
      "step": 59
    },
    {
      "epoch": 0.0013620344254201024,
      "grad_norm": 0.6582928895950317,
      "learning_rate": 7.281699277636572e-05,
      "loss": 0.5157,
      "step": 60
    },
    {
      "epoch": 0.0013847349991771042,
      "grad_norm": 0.5352616906166077,
      "learning_rate": 6.971499241020495e-05,
      "loss": 0.5414,
      "step": 61
    },
    {
      "epoch": 0.0014074355729341058,
      "grad_norm": 0.465904176235199,
      "learning_rate": 6.664475683491796e-05,
      "loss": 0.4226,
      "step": 62
    },
    {
      "epoch": 0.0014301361466911076,
      "grad_norm": 0.521146297454834,
      "learning_rate": 6.360950630365126e-05,
      "loss": 0.431,
      "step": 63
    },
    {
      "epoch": 0.0014528367204481093,
      "grad_norm": 0.47249120473861694,
      "learning_rate": 6.061242437507131e-05,
      "loss": 0.3988,
      "step": 64
    },
    {
      "epoch": 0.001475537294205111,
      "grad_norm": 0.4760763347148895,
      "learning_rate": 5.765665457425102e-05,
      "loss": 0.4347,
      "step": 65
    },
    {
      "epoch": 0.0014982378679621127,
      "grad_norm": 0.5001295804977417,
      "learning_rate": 5.474529709554612e-05,
      "loss": 0.3396,
      "step": 66
    },
    {
      "epoch": 0.0015209384417191145,
      "grad_norm": 0.5212888717651367,
      "learning_rate": 5.1881405550919493e-05,
      "loss": 0.3977,
      "step": 67
    },
    {
      "epoch": 0.0015436390154761161,
      "grad_norm": 0.5642649531364441,
      "learning_rate": 4.9067983767123736e-05,
      "loss": 0.3566,
      "step": 68
    },
    {
      "epoch": 0.001566339589233118,
      "grad_norm": 0.46865710616111755,
      "learning_rate": 4.630798263510162e-05,
      "loss": 0.3429,
      "step": 69
    },
    {
      "epoch": 0.0015890401629901196,
      "grad_norm": 0.410768985748291,
      "learning_rate": 4.360429701490934e-05,
      "loss": 0.3782,
      "step": 70
    },
    {
      "epoch": 0.0016117407367471214,
      "grad_norm": 0.4851166307926178,
      "learning_rate": 4.0959762699407766e-05,
      "loss": 0.3628,
      "step": 71
    },
    {
      "epoch": 0.001634441310504123,
      "grad_norm": 0.45856234431266785,
      "learning_rate": 3.8377153439907266e-05,
      "loss": 0.3146,
      "step": 72
    },
    {
      "epoch": 0.0016571418842611246,
      "grad_norm": 0.38426893949508667,
      "learning_rate": 3.585917803688603e-05,
      "loss": 0.375,
      "step": 73
    },
    {
      "epoch": 0.0016798424580181264,
      "grad_norm": 0.4884875416755676,
      "learning_rate": 3.340847749883191e-05,
      "loss": 0.3327,
      "step": 74
    },
    {
      "epoch": 0.001702543031775128,
      "grad_norm": 0.474949449300766,
      "learning_rate": 3.102762227218957e-05,
      "loss": 0.2332,
      "step": 75
    },
    {
      "epoch": 0.0017252436055321299,
      "grad_norm": 0.3983084261417389,
      "learning_rate": 2.8719109545317103e-05,
      "loss": 0.2757,
      "step": 76
    },
    {
      "epoch": 0.0017479441792891315,
      "grad_norm": 0.4876188337802887,
      "learning_rate": 2.6485360629279977e-05,
      "loss": 0.2877,
      "step": 77
    },
    {
      "epoch": 0.0017706447530461333,
      "grad_norm": 0.43216419219970703,
      "learning_rate": 2.432871841823047e-05,
      "loss": 0.2817,
      "step": 78
    },
    {
      "epoch": 0.001793345326803135,
      "grad_norm": 0.39772599935531616,
      "learning_rate": 2.2251444932035094e-05,
      "loss": 0.2552,
      "step": 79
    },
    {
      "epoch": 0.0018160459005601367,
      "grad_norm": 0.5923653244972229,
      "learning_rate": 2.025571894372794e-05,
      "loss": 0.2663,
      "step": 80
    },
    {
      "epoch": 0.0018387464743171383,
      "grad_norm": 0.4710267186164856,
      "learning_rate": 1.8343633694278895e-05,
      "loss": 0.2224,
      "step": 81
    },
    {
      "epoch": 0.0018614470480741402,
      "grad_norm": 0.447916716337204,
      "learning_rate": 1.65171946970729e-05,
      "loss": 0.2672,
      "step": 82
    },
    {
      "epoch": 0.0018841476218311418,
      "grad_norm": 0.41834619641304016,
      "learning_rate": 1.4778317634403083e-05,
      "loss": 0.2127,
      "step": 83
    },
    {
      "epoch": 0.0019068481955881434,
      "grad_norm": 0.3589397668838501,
      "learning_rate": 1.3128826348184887e-05,
      "loss": 0.2163,
      "step": 84
    },
    {
      "epoch": 0.0019295487693451452,
      "grad_norm": 0.327827513217926,
      "learning_rate": 1.1570450926997655e-05,
      "loss": 0.1672,
      "step": 85
    },
    {
      "epoch": 0.0019522493431021468,
      "grad_norm": 0.4783332645893097,
      "learning_rate": 1.010482589146048e-05,
      "loss": 0.1879,
      "step": 86
    },
    {
      "epoch": 0.0019749499168591486,
      "grad_norm": 0.47257786989212036,
      "learning_rate": 8.733488479845997e-06,
      "loss": 0.1878,
      "step": 87
    },
    {
      "epoch": 0.0019976504906161503,
      "grad_norm": 0.41355761885643005,
      "learning_rate": 7.457877035729588e-06,
      "loss": 0.2046,
      "step": 88
    },
    {
      "epoch": 0.002020351064373152,
      "grad_norm": 0.36557942628860474,
      "learning_rate": 6.2793294993656494e-06,
      "loss": 0.1517,
      "step": 89
    },
    {
      "epoch": 0.002043051638130154,
      "grad_norm": 0.3291955888271332,
      "learning_rate": 5.199082004372957e-06,
      "loss": 0.139,
      "step": 90
    },
    {
      "epoch": 0.0020657522118871555,
      "grad_norm": 0.37223905324935913,
      "learning_rate": 4.2182675812012965e-06,
      "loss": 0.1835,
      "step": 91
    },
    {
      "epoch": 0.002088452785644157,
      "grad_norm": 0.42029887437820435,
      "learning_rate": 3.3379149687388867e-06,
      "loss": 0.1424,
      "step": 92
    },
    {
      "epoch": 0.0021111533594011587,
      "grad_norm": 0.3281061053276062,
      "learning_rate": 2.5589475353073988e-06,
      "loss": 0.1412,
      "step": 93
    },
    {
      "epoch": 0.0021338539331581608,
      "grad_norm": 0.33877384662628174,
      "learning_rate": 1.882182310176095e-06,
      "loss": 0.1253,
      "step": 94
    },
    {
      "epoch": 0.0021565545069151624,
      "grad_norm": 0.33831751346588135,
      "learning_rate": 1.30832912661093e-06,
      "loss": 0.1039,
      "step": 95
    },
    {
      "epoch": 0.002179255080672164,
      "grad_norm": 0.327972412109375,
      "learning_rate": 8.379898773574924e-07,
      "loss": 0.1502,
      "step": 96
    },
    {
      "epoch": 0.0022019556544291656,
      "grad_norm": 0.3562649190425873,
      "learning_rate": 4.7165788333860536e-07,
      "loss": 0.1154,
      "step": 97
    },
    {
      "epoch": 0.002224656228186167,
      "grad_norm": 0.34951114654541016,
      "learning_rate": 2.0971737622883515e-07,
      "loss": 0.0952,
      "step": 98
    },
    {
      "epoch": 0.0022473568019431693,
      "grad_norm": 0.4032289385795593,
      "learning_rate": 5.2443095448506674e-08,
      "loss": 0.1381,
      "step": 99
    },
    {
      "epoch": 0.002270057375700171,
      "grad_norm": 0.328935444355011,
      "learning_rate": 0.0,
      "loss": 0.1012,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.287573914640384e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
