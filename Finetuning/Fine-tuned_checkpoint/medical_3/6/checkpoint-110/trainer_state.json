{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.001203356270033147,
  "eval_steps": 500,
  "global_step": 110,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.093960245484679e-05,
      "grad_norm": 1.0242396593093872,
      "learning_rate": 5e-05,
      "loss": 2.0733,
      "step": 1
    },
    {
      "epoch": 2.187920490969358e-05,
      "grad_norm": 0.9776245951652527,
      "learning_rate": 0.0001,
      "loss": 1.9535,
      "step": 2
    },
    {
      "epoch": 3.281880736454037e-05,
      "grad_norm": 1.0376955270767212,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.0561,
      "step": 3
    },
    {
      "epoch": 4.375840981938716e-05,
      "grad_norm": 1.0147705078125,
      "learning_rate": 0.0002,
      "loss": 1.9442,
      "step": 4
    },
    {
      "epoch": 5.4698012274233954e-05,
      "grad_norm": 1.1505610942840576,
      "learning_rate": 0.00019995608365087946,
      "loss": 1.9148,
      "step": 5
    },
    {
      "epoch": 6.563761472908074e-05,
      "grad_norm": 1.0595108270645142,
      "learning_rate": 0.00019982437317643217,
      "loss": 1.6863,
      "step": 6
    },
    {
      "epoch": 7.657721718392754e-05,
      "grad_norm": 1.0574089288711548,
      "learning_rate": 0.0001996049842615217,
      "loss": 1.6141,
      "step": 7
    },
    {
      "epoch": 8.751681963877433e-05,
      "grad_norm": 1.7780367136001587,
      "learning_rate": 0.00019929810960135172,
      "loss": 1.7915,
      "step": 8
    },
    {
      "epoch": 9.845642209362112e-05,
      "grad_norm": 2.0293233394622803,
      "learning_rate": 0.0001989040187322164,
      "loss": 1.6091,
      "step": 9
    },
    {
      "epoch": 0.00010939602454846791,
      "grad_norm": 1.9153163433074951,
      "learning_rate": 0.00019842305779475968,
      "loss": 1.484,
      "step": 10
    },
    {
      "epoch": 0.0001203356270033147,
      "grad_norm": 1.5648244619369507,
      "learning_rate": 0.0001978556492299504,
      "loss": 1.4541,
      "step": 11
    },
    {
      "epoch": 0.0001312752294581615,
      "grad_norm": 1.5738213062286377,
      "learning_rate": 0.0001972022914080411,
      "loss": 1.2738,
      "step": 12
    },
    {
      "epoch": 0.00014221483191300828,
      "grad_norm": 1.6260019540786743,
      "learning_rate": 0.00019646355819083589,
      "loss": 1.2725,
      "step": 13
    },
    {
      "epoch": 0.00015315443436785507,
      "grad_norm": 1.7248927354812622,
      "learning_rate": 0.00019564009842765225,
      "loss": 1.2093,
      "step": 14
    },
    {
      "epoch": 0.00016409403682270186,
      "grad_norm": 1.8059455156326294,
      "learning_rate": 0.00019473263538541914,
      "loss": 1.0104,
      "step": 15
    },
    {
      "epoch": 0.00017503363927754865,
      "grad_norm": 2.0730271339416504,
      "learning_rate": 0.0001937419661134121,
      "loss": 1.2103,
      "step": 16
    },
    {
      "epoch": 0.00018597324173239544,
      "grad_norm": 2.051058530807495,
      "learning_rate": 0.00019266896074318334,
      "loss": 0.9748,
      "step": 17
    },
    {
      "epoch": 0.00019691284418724223,
      "grad_norm": 2.3292670249938965,
      "learning_rate": 0.00019151456172430183,
      "loss": 0.8247,
      "step": 18
    },
    {
      "epoch": 0.00020785244664208902,
      "grad_norm": 2.1737160682678223,
      "learning_rate": 0.00019027978299657436,
      "loss": 0.7545,
      "step": 19
    },
    {
      "epoch": 0.00021879204909693582,
      "grad_norm": 2.019963264465332,
      "learning_rate": 0.00018896570909947475,
      "loss": 0.6955,
      "step": 20
    },
    {
      "epoch": 0.0002297316515517826,
      "grad_norm": 2.164401054382324,
      "learning_rate": 0.0001875734942195637,
      "loss": 0.5876,
      "step": 21
    },
    {
      "epoch": 0.0002406712540066294,
      "grad_norm": 2.1652872562408447,
      "learning_rate": 0.00018610436117673555,
      "loss": 0.5839,
      "step": 22
    },
    {
      "epoch": 0.0002516108564614762,
      "grad_norm": 1.9167407751083374,
      "learning_rate": 0.0001845596003501826,
      "loss": 0.4888,
      "step": 23
    },
    {
      "epoch": 0.000262550458916323,
      "grad_norm": 1.7806936502456665,
      "learning_rate": 0.0001829405685450202,
      "loss": 0.4097,
      "step": 24
    },
    {
      "epoch": 0.0002734900613711698,
      "grad_norm": 1.449623465538025,
      "learning_rate": 0.00018124868780056814,
      "loss": 0.3875,
      "step": 25
    },
    {
      "epoch": 0.00028442966382601656,
      "grad_norm": 1.5019389390945435,
      "learning_rate": 0.00017948544414133534,
      "loss": 0.3721,
      "step": 26
    },
    {
      "epoch": 0.0002953692662808634,
      "grad_norm": 1.5567094087600708,
      "learning_rate": 0.00017765238627180424,
      "loss": 0.3986,
      "step": 27
    },
    {
      "epoch": 0.00030630886873571014,
      "grad_norm": 1.2572498321533203,
      "learning_rate": 0.00017575112421616202,
      "loss": 0.3467,
      "step": 28
    },
    {
      "epoch": 0.00031724847119055696,
      "grad_norm": 1.285851001739502,
      "learning_rate": 0.00017378332790417273,
      "loss": 0.2897,
      "step": 29
    },
    {
      "epoch": 0.0003281880736454037,
      "grad_norm": 1.4543633460998535,
      "learning_rate": 0.00017175072570443312,
      "loss": 0.2646,
      "step": 30
    },
    {
      "epoch": 0.00033912767610025054,
      "grad_norm": 1.0032862424850464,
      "learning_rate": 0.00016965510290629972,
      "loss": 0.2842,
      "step": 31
    },
    {
      "epoch": 0.0003500672785550973,
      "grad_norm": 0.9372451305389404,
      "learning_rate": 0.00016749830015182107,
      "loss": 0.2698,
      "step": 32
    },
    {
      "epoch": 0.0003610068810099441,
      "grad_norm": 1.0589643716812134,
      "learning_rate": 0.00016528221181905217,
      "loss": 0.3328,
      "step": 33
    },
    {
      "epoch": 0.0003719464834647909,
      "grad_norm": 0.9284632205963135,
      "learning_rate": 0.00016300878435817113,
      "loss": 0.3051,
      "step": 34
    },
    {
      "epoch": 0.0003828860859196377,
      "grad_norm": 0.7329256534576416,
      "learning_rate": 0.00016068001458185936,
      "loss": 0.2109,
      "step": 35
    },
    {
      "epoch": 0.00039382568837448447,
      "grad_norm": 0.6316235661506653,
      "learning_rate": 0.0001582979479114472,
      "loss": 0.1887,
      "step": 36
    },
    {
      "epoch": 0.0004047652908293313,
      "grad_norm": 0.7803580164909363,
      "learning_rate": 0.00015586467658036524,
      "loss": 0.2303,
      "step": 37
    },
    {
      "epoch": 0.00041570489328417805,
      "grad_norm": 0.8538179397583008,
      "learning_rate": 0.0001533823377964791,
      "loss": 0.1681,
      "step": 38
    },
    {
      "epoch": 0.00042664449573902487,
      "grad_norm": 0.6802884340286255,
      "learning_rate": 0.00015085311186492206,
      "loss": 0.2009,
      "step": 39
    },
    {
      "epoch": 0.00043758409819387163,
      "grad_norm": 0.7329952716827393,
      "learning_rate": 0.00014827922027307451,
      "loss": 0.1515,
      "step": 40
    },
    {
      "epoch": 0.00044852370064871845,
      "grad_norm": 0.8752326369285583,
      "learning_rate": 0.0001456629237393713,
      "loss": 0.2093,
      "step": 41
    },
    {
      "epoch": 0.0004594633031035652,
      "grad_norm": 0.7181556820869446,
      "learning_rate": 0.00014300652022765207,
      "loss": 0.155,
      "step": 42
    },
    {
      "epoch": 0.00047040290555841203,
      "grad_norm": 0.7093514800071716,
      "learning_rate": 0.00014031234292879725,
      "loss": 0.141,
      "step": 43
    },
    {
      "epoch": 0.0004813425080132588,
      "grad_norm": 0.7047356367111206,
      "learning_rate": 0.00013758275821142382,
      "loss": 0.137,
      "step": 44
    },
    {
      "epoch": 0.0004922821104681056,
      "grad_norm": 0.5620920658111572,
      "learning_rate": 0.0001348201635434399,
      "loss": 0.1171,
      "step": 45
    },
    {
      "epoch": 0.0005032217129229524,
      "grad_norm": 0.7582538723945618,
      "learning_rate": 0.00013202698538628376,
      "loss": 0.1622,
      "step": 46
    },
    {
      "epoch": 0.0005141613153777991,
      "grad_norm": 0.5246575474739075,
      "learning_rate": 0.00012920567706369758,
      "loss": 0.1074,
      "step": 47
    },
    {
      "epoch": 0.000525100917832646,
      "grad_norm": 0.4565621316432953,
      "learning_rate": 0.00012635871660690676,
      "loss": 0.0783,
      "step": 48
    },
    {
      "epoch": 0.0005360405202874928,
      "grad_norm": 0.3968377411365509,
      "learning_rate": 0.00012348860457809838,
      "loss": 0.0927,
      "step": 49
    },
    {
      "epoch": 0.0005469801227423396,
      "grad_norm": 0.47463560104370117,
      "learning_rate": 0.00012059786187410984,
      "loss": 0.0968,
      "step": 50
    },
    {
      "epoch": 0.0005579197251971863,
      "grad_norm": 1.7709033489227295,
      "learning_rate": 0.0001176890275122573,
      "loss": 0.7685,
      "step": 51
    },
    {
      "epoch": 0.0005688593276520331,
      "grad_norm": 1.4278419017791748,
      "learning_rate": 0.00011476465640024814,
      "loss": 0.8087,
      "step": 52
    },
    {
      "epoch": 0.0005797989301068799,
      "grad_norm": 1.2586045265197754,
      "learning_rate": 0.00011182731709213659,
      "loss": 0.8827,
      "step": 53
    },
    {
      "epoch": 0.0005907385325617268,
      "grad_norm": 1.1642330884933472,
      "learning_rate": 0.00010887958953229349,
      "loss": 0.8134,
      "step": 54
    },
    {
      "epoch": 0.0006016781350165735,
      "grad_norm": 1.3035894632339478,
      "learning_rate": 0.00010592406278937144,
      "loss": 0.8263,
      "step": 55
    },
    {
      "epoch": 0.0006126177374714203,
      "grad_norm": 1.1621501445770264,
      "learning_rate": 0.00010296333278225599,
      "loss": 0.6527,
      "step": 56
    },
    {
      "epoch": 0.0006235573399262671,
      "grad_norm": 1.2872167825698853,
      "learning_rate": 0.0001,
      "loss": 1.0528,
      "step": 57
    },
    {
      "epoch": 0.0006344969423811139,
      "grad_norm": 1.092635989189148,
      "learning_rate": 9.703666721774402e-05,
      "loss": 0.58,
      "step": 58
    },
    {
      "epoch": 0.0006454365448359606,
      "grad_norm": 0.777498185634613,
      "learning_rate": 9.407593721062859e-05,
      "loss": 0.6211,
      "step": 59
    },
    {
      "epoch": 0.0006563761472908074,
      "grad_norm": 0.8079946041107178,
      "learning_rate": 9.112041046770653e-05,
      "loss": 0.5593,
      "step": 60
    },
    {
      "epoch": 0.0006673157497456543,
      "grad_norm": 0.8648993372917175,
      "learning_rate": 8.817268290786343e-05,
      "loss": 0.3976,
      "step": 61
    },
    {
      "epoch": 0.0006782553522005011,
      "grad_norm": 1.089052438735962,
      "learning_rate": 8.523534359975189e-05,
      "loss": 0.4685,
      "step": 62
    },
    {
      "epoch": 0.0006891949546553478,
      "grad_norm": 0.7082147598266602,
      "learning_rate": 8.231097248774274e-05,
      "loss": 0.5123,
      "step": 63
    },
    {
      "epoch": 0.0007001345571101946,
      "grad_norm": 0.7694897055625916,
      "learning_rate": 7.940213812589018e-05,
      "loss": 0.4951,
      "step": 64
    },
    {
      "epoch": 0.0007110741595650414,
      "grad_norm": 0.7427469491958618,
      "learning_rate": 7.651139542190164e-05,
      "loss": 0.5472,
      "step": 65
    },
    {
      "epoch": 0.0007220137620198882,
      "grad_norm": 0.7306273579597473,
      "learning_rate": 7.364128339309326e-05,
      "loss": 0.5668,
      "step": 66
    },
    {
      "epoch": 0.000732953364474735,
      "grad_norm": 0.7699610590934753,
      "learning_rate": 7.079432293630244e-05,
      "loss": 0.4213,
      "step": 67
    },
    {
      "epoch": 0.0007438929669295818,
      "grad_norm": 0.5715980529785156,
      "learning_rate": 6.797301461371625e-05,
      "loss": 0.3582,
      "step": 68
    },
    {
      "epoch": 0.0007548325693844286,
      "grad_norm": 0.5842373371124268,
      "learning_rate": 6.517983645656014e-05,
      "loss": 0.3169,
      "step": 69
    },
    {
      "epoch": 0.0007657721718392754,
      "grad_norm": 0.6586354970932007,
      "learning_rate": 6.24172417885762e-05,
      "loss": 0.3128,
      "step": 70
    },
    {
      "epoch": 0.0007767117742941221,
      "grad_norm": 0.5564361810684204,
      "learning_rate": 5.96876570712028e-05,
      "loss": 0.3243,
      "step": 71
    },
    {
      "epoch": 0.0007876513767489689,
      "grad_norm": 0.5922657251358032,
      "learning_rate": 5.699347977234799e-05,
      "loss": 0.3111,
      "step": 72
    },
    {
      "epoch": 0.0007985909792038158,
      "grad_norm": 0.5484919548034668,
      "learning_rate": 5.43370762606287e-05,
      "loss": 0.3717,
      "step": 73
    },
    {
      "epoch": 0.0008095305816586626,
      "grad_norm": 0.6095451712608337,
      "learning_rate": 5.172077972692553e-05,
      "loss": 0.3046,
      "step": 74
    },
    {
      "epoch": 0.0008204701841135093,
      "grad_norm": 0.6488611102104187,
      "learning_rate": 4.914688813507797e-05,
      "loss": 0.3214,
      "step": 75
    },
    {
      "epoch": 0.0008314097865683561,
      "grad_norm": 0.5074838399887085,
      "learning_rate": 4.661766220352097e-05,
      "loss": 0.2663,
      "step": 76
    },
    {
      "epoch": 0.0008423493890232029,
      "grad_norm": 1.2149914503097534,
      "learning_rate": 4.4135323419634766e-05,
      "loss": 0.3432,
      "step": 77
    },
    {
      "epoch": 0.0008532889914780497,
      "grad_norm": 0.5492977499961853,
      "learning_rate": 4.170205208855281e-05,
      "loss": 0.2797,
      "step": 78
    },
    {
      "epoch": 0.0008642285939328964,
      "grad_norm": 0.5156997442245483,
      "learning_rate": 3.931998541814069e-05,
      "loss": 0.234,
      "step": 79
    },
    {
      "epoch": 0.0008751681963877433,
      "grad_norm": 0.527325451374054,
      "learning_rate": 3.69912156418289e-05,
      "loss": 0.2568,
      "step": 80
    },
    {
      "epoch": 0.0008861077988425901,
      "grad_norm": 0.5621181726455688,
      "learning_rate": 3.471778818094785e-05,
      "loss": 0.2735,
      "step": 81
    },
    {
      "epoch": 0.0008970474012974369,
      "grad_norm": 0.5947030186653137,
      "learning_rate": 3.250169984817898e-05,
      "loss": 0.2129,
      "step": 82
    },
    {
      "epoch": 0.0009079870037522836,
      "grad_norm": 0.6252055764198303,
      "learning_rate": 3.034489709370033e-05,
      "loss": 0.2024,
      "step": 83
    },
    {
      "epoch": 0.0009189266062071304,
      "grad_norm": 0.7722494602203369,
      "learning_rate": 2.8249274295566875e-05,
      "loss": 0.2448,
      "step": 84
    },
    {
      "epoch": 0.0009298662086619772,
      "grad_norm": 0.5920766592025757,
      "learning_rate": 2.6216672095827256e-05,
      "loss": 0.2202,
      "step": 85
    },
    {
      "epoch": 0.0009408058111168241,
      "grad_norm": 0.4189487397670746,
      "learning_rate": 2.4248875783837987e-05,
      "loss": 0.2027,
      "step": 86
    },
    {
      "epoch": 0.0009517454135716708,
      "grad_norm": 0.4963751435279846,
      "learning_rate": 2.234761372819577e-05,
      "loss": 0.1741,
      "step": 87
    },
    {
      "epoch": 0.0009626850160265176,
      "grad_norm": 0.5111116170883179,
      "learning_rate": 2.0514555858664663e-05,
      "loss": 0.197,
      "step": 88
    },
    {
      "epoch": 0.0009736246184813644,
      "grad_norm": 0.48015132546424866,
      "learning_rate": 1.875131219943187e-05,
      "loss": 0.1301,
      "step": 89
    },
    {
      "epoch": 0.0009845642209362112,
      "grad_norm": 0.6258588433265686,
      "learning_rate": 1.7059431454979824e-05,
      "loss": 0.162,
      "step": 90
    },
    {
      "epoch": 0.000995503823391058,
      "grad_norm": 0.7073058485984802,
      "learning_rate": 1.5440399649817385e-05,
      "loss": 0.1662,
      "step": 91
    },
    {
      "epoch": 0.0010064434258459049,
      "grad_norm": 0.5089028477668762,
      "learning_rate": 1.3895638823264446e-05,
      "loss": 0.1422,
      "step": 92
    },
    {
      "epoch": 0.0010173830283007515,
      "grad_norm": 0.5740233063697815,
      "learning_rate": 1.2426505780436326e-05,
      "loss": 0.1505,
      "step": 93
    },
    {
      "epoch": 0.0010283226307555983,
      "grad_norm": 0.5951697826385498,
      "learning_rate": 1.103429090052528e-05,
      "loss": 0.1296,
      "step": 94
    },
    {
      "epoch": 0.001039262233210445,
      "grad_norm": 0.562964916229248,
      "learning_rate": 9.720217003425647e-06,
      "loss": 0.1552,
      "step": 95
    },
    {
      "epoch": 0.001050201835665292,
      "grad_norm": 0.48282894492149353,
      "learning_rate": 8.485438275698154e-06,
      "loss": 0.1165,
      "step": 96
    },
    {
      "epoch": 0.0010611414381201387,
      "grad_norm": 0.5573588609695435,
      "learning_rate": 7.331039256816663e-06,
      "loss": 0.1259,
      "step": 97
    },
    {
      "epoch": 0.0010720810405749855,
      "grad_norm": 0.37737372517585754,
      "learning_rate": 6.258033886587911e-06,
      "loss": 0.0923,
      "step": 98
    },
    {
      "epoch": 0.0010830206430298324,
      "grad_norm": 0.489036500453949,
      "learning_rate": 5.267364614580861e-06,
      "loss": 0.117,
      "step": 99
    },
    {
      "epoch": 0.0010939602454846792,
      "grad_norm": 0.48291823267936707,
      "learning_rate": 4.359901572347758e-06,
      "loss": 0.1171,
      "step": 100
    },
    {
      "epoch": 0.0011048998479395258,
      "grad_norm": 0.9629624485969543,
      "learning_rate": 3.5364418091641373e-06,
      "loss": 0.8134,
      "step": 101
    },
    {
      "epoch": 0.0011158394503943726,
      "grad_norm": 0.7662518620491028,
      "learning_rate": 2.7977085919589254e-06,
      "loss": 0.8579,
      "step": 102
    },
    {
      "epoch": 0.0011267790528492194,
      "grad_norm": 0.7305182218551636,
      "learning_rate": 2.144350770049597e-06,
      "loss": 0.775,
      "step": 103
    },
    {
      "epoch": 0.0011377186553040662,
      "grad_norm": 0.8561738729476929,
      "learning_rate": 1.576942205240317e-06,
      "loss": 0.9541,
      "step": 104
    },
    {
      "epoch": 0.001148658257758913,
      "grad_norm": 0.7666715979576111,
      "learning_rate": 1.0959812677835968e-06,
      "loss": 0.7371,
      "step": 105
    },
    {
      "epoch": 0.0011595978602137599,
      "grad_norm": 0.68943852186203,
      "learning_rate": 7.018903986483083e-07,
      "loss": 0.7391,
      "step": 106
    },
    {
      "epoch": 0.0011705374626686067,
      "grad_norm": 0.5695203542709351,
      "learning_rate": 3.950157384783104e-07,
      "loss": 0.5959,
      "step": 107
    },
    {
      "epoch": 0.0011814770651234535,
      "grad_norm": 0.8029201030731201,
      "learning_rate": 1.7562682356786487e-07,
      "loss": 0.5847,
      "step": 108
    },
    {
      "epoch": 0.0011924166675783001,
      "grad_norm": 0.5612571835517883,
      "learning_rate": 4.391634912056519e-08,
      "loss": 0.4163,
      "step": 109
    },
    {
      "epoch": 0.001203356270033147,
      "grad_norm": 0.7386378645896912,
      "learning_rate": 0.0,
      "loss": 0.5065,
      "step": 110
    }
  ],
  "logging_steps": 1,
  "max_steps": 110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7588176152272896.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
