{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.006617654661827507,
  "eval_steps": 500,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 8.272068327284383e-05,
      "grad_norm": 1.5043562650680542,
      "learning_rate": 0.0001,
      "loss": 1.9595,
      "step": 1
    },
    {
      "epoch": 0.00016544136654568766,
      "grad_norm": 1.8306677341461182,
      "learning_rate": 9.990094071072877e-05,
      "loss": 2.3019,
      "step": 2
    },
    {
      "epoch": 0.0002481620498185315,
      "grad_norm": 1.7613961696624756,
      "learning_rate": 9.960415535262671e-05,
      "loss": 2.2783,
      "step": 3
    },
    {
      "epoch": 0.0003308827330913753,
      "grad_norm": 1.9991271495819092,
      "learning_rate": 9.91108198995594e-05,
      "loss": 2.0563,
      "step": 4
    },
    {
      "epoch": 0.00041360341636421916,
      "grad_norm": NaN,
      "learning_rate": 9.91108198995594e-05,
      "loss": 2.2947,
      "step": 5
    },
    {
      "epoch": 0.000496324099637063,
      "grad_norm": 2.020979166030884,
      "learning_rate": 9.842288912990096e-05,
      "loss": 2.2119,
      "step": 6
    },
    {
      "epoch": 0.0005790447829099068,
      "grad_norm": 2.107518434524536,
      "learning_rate": 9.754308888097583e-05,
      "loss": 2.0839,
      "step": 7
    },
    {
      "epoch": 0.0006617654661827506,
      "grad_norm": 2.0635111331939697,
      "learning_rate": 9.647490524827834e-05,
      "loss": 2.0968,
      "step": 8
    },
    {
      "epoch": 0.0007444861494555945,
      "grad_norm": 2.1375210285186768,
      "learning_rate": 9.522257077226717e-05,
      "loss": 2.1344,
      "step": 9
    },
    {
      "epoch": 0.0008272068327284383,
      "grad_norm": 2.2170939445495605,
      "learning_rate": 9.379104766746722e-05,
      "loss": 1.7956,
      "step": 10
    },
    {
      "epoch": 0.0009099275160012822,
      "grad_norm": 2.70408034324646,
      "learning_rate": 9.2186008160332e-05,
      "loss": 1.772,
      "step": 11
    },
    {
      "epoch": 0.000992648199274126,
      "grad_norm": 2.7873737812042236,
      "learning_rate": 9.041381201377468e-05,
      "loss": 1.84,
      "step": 12
    },
    {
      "epoch": 0.00107536888254697,
      "grad_norm": 4.790360927581787,
      "learning_rate": 8.848148132742431e-05,
      "loss": 1.8058,
      "step": 13
    },
    {
      "epoch": 0.0011580895658198137,
      "grad_norm": 3.945890426635742,
      "learning_rate": 8.6396672713458e-05,
      "loss": 1.7737,
      "step": 14
    },
    {
      "epoch": 0.0012408102490926575,
      "grad_norm": 2.960235595703125,
      "learning_rate": 8.416764695825834e-05,
      "loss": 1.543,
      "step": 15
    },
    {
      "epoch": 0.0013235309323655013,
      "grad_norm": 3.493924856185913,
      "learning_rate": 8.180323629010848e-05,
      "loss": 1.3756,
      "step": 16
    },
    {
      "epoch": 0.0014062516156383453,
      "grad_norm": 5.751547336578369,
      "learning_rate": 7.93128093826217e-05,
      "loss": 1.4768,
      "step": 17
    },
    {
      "epoch": 0.001488972298911189,
      "grad_norm": 3.678823471069336,
      "learning_rate": 7.670623423257548e-05,
      "loss": 1.5063,
      "step": 18
    },
    {
      "epoch": 0.0015716929821840329,
      "grad_norm": 2.7539215087890625,
      "learning_rate": 7.399383905924165e-05,
      "loss": 1.4013,
      "step": 19
    },
    {
      "epoch": 0.0016544136654568766,
      "grad_norm": 2.9167375564575195,
      "learning_rate": 7.118637138014396e-05,
      "loss": 1.3577,
      "step": 20
    },
    {
      "epoch": 0.0017371343487297204,
      "grad_norm": 2.256544589996338,
      "learning_rate": 6.829495542540013e-05,
      "loss": 1.2725,
      "step": 21
    },
    {
      "epoch": 0.0018198550320025644,
      "grad_norm": 2.7758729457855225,
      "learning_rate": 6.533104805938873e-05,
      "loss": 1.3249,
      "step": 22
    },
    {
      "epoch": 0.0019025757152754082,
      "grad_norm": 3.7425026893615723,
      "learning_rate": 6.230639338439549e-05,
      "loss": 1.2934,
      "step": 23
    },
    {
      "epoch": 0.001985296398548252,
      "grad_norm": 5.221314907073975,
      "learning_rate": 5.923297620611623e-05,
      "loss": 1.1909,
      "step": 24
    },
    {
      "epoch": 0.002068017081821096,
      "grad_norm": 2.2888824939727783,
      "learning_rate": 5.6122974545403525e-05,
      "loss": 1.2838,
      "step": 25
    },
    {
      "epoch": 0.00215073776509394,
      "grad_norm": 2.5191752910614014,
      "learning_rate": 5.298871138442307e-05,
      "loss": 1.1959,
      "step": 26
    },
    {
      "epoch": 0.0022334584483667836,
      "grad_norm": 2.24515962600708,
      "learning_rate": 4.984260583841951e-05,
      "loss": 1.1333,
      "step": 27
    },
    {
      "epoch": 0.0023161791316396274,
      "grad_norm": 2.2987701892852783,
      "learning_rate": 4.6697123946567227e-05,
      "loss": 1.1369,
      "step": 28
    },
    {
      "epoch": 0.002398899814912471,
      "grad_norm": 3.235107660293579,
      "learning_rate": 4.356472927689109e-05,
      "loss": 1.0308,
      "step": 29
    },
    {
      "epoch": 0.002481620498185315,
      "grad_norm": 3.092144250869751,
      "learning_rate": 4.045783354097893e-05,
      "loss": 1.1718,
      "step": 30
    },
    {
      "epoch": 0.0025643411814581588,
      "grad_norm": 2.702939510345459,
      "learning_rate": 3.73887474141683e-05,
      "loss": 0.9858,
      "step": 31
    },
    {
      "epoch": 0.0026470618647310025,
      "grad_norm": 3.1886661052703857,
      "learning_rate": 3.436963175607658e-05,
      "loss": 1.0431,
      "step": 32
    },
    {
      "epoch": 0.0027297825480038463,
      "grad_norm": 2.6861298084259033,
      "learning_rate": 3.1412449424756474e-05,
      "loss": 1.2254,
      "step": 33
    },
    {
      "epoch": 0.0028125032312766906,
      "grad_norm": 2.322610855102539,
      "learning_rate": 2.8528917875407433e-05,
      "loss": 1.2049,
      "step": 34
    },
    {
      "epoch": 0.0028952239145495343,
      "grad_norm": 3.3600270748138428,
      "learning_rate": 2.5730462731464273e-05,
      "loss": 1.0007,
      "step": 35
    },
    {
      "epoch": 0.002977944597822378,
      "grad_norm": 3.2248644828796387,
      "learning_rate": 2.3028172512031604e-05,
      "loss": 1.0582,
      "step": 36
    },
    {
      "epoch": 0.003060665281095222,
      "grad_norm": 2.5334842205047607,
      "learning_rate": 2.0432754695051136e-05,
      "loss": 0.9331,
      "step": 37
    },
    {
      "epoch": 0.0031433859643680657,
      "grad_norm": 2.458400249481201,
      "learning_rate": 1.795449329029531e-05,
      "loss": 0.9865,
      "step": 38
    },
    {
      "epoch": 0.0032261066476409095,
      "grad_norm": 2.4662415981292725,
      "learning_rate": 1.560320809029948e-05,
      "loss": 0.9434,
      "step": 39
    },
    {
      "epoch": 0.0033088273309137533,
      "grad_norm": 2.526129722595215,
      "learning_rate": 1.3388215760695083e-05,
      "loss": 1.0176,
      "step": 40
    },
    {
      "epoch": 0.003391548014186597,
      "grad_norm": 2.6398019790649414,
      "learning_rate": 1.1318292924118601e-05,
      "loss": 0.8116,
      "step": 41
    },
    {
      "epoch": 0.003474268697459441,
      "grad_norm": 3.184659481048584,
      "learning_rate": 9.401641383971477e-06,
      "loss": 0.8309,
      "step": 42
    },
    {
      "epoch": 0.0035569893807322847,
      "grad_norm": 3.0133354663848877,
      "learning_rate": 7.64585562582767e-06,
      "loss": 0.8475,
      "step": 43
    },
    {
      "epoch": 0.003639710064005129,
      "grad_norm": 2.968069314956665,
      "learning_rate": 6.057892725259717e-06,
      "loss": 0.7816,
      "step": 44
    },
    {
      "epoch": 0.0037224307472779727,
      "grad_norm": 2.7015604972839355,
      "learning_rate": 4.644044781320422e-06,
      "loss": 0.7451,
      "step": 45
    },
    {
      "epoch": 0.0038051514305508165,
      "grad_norm": 2.995434284210205,
      "learning_rate": 3.4099139849083307e-06,
      "loss": 0.8383,
      "step": 46
    },
    {
      "epoch": 0.0038878721138236602,
      "grad_norm": 3.2848455905914307,
      "learning_rate": 2.360390420805869e-06,
      "loss": 0.7847,
      "step": 47
    },
    {
      "epoch": 0.003970592797096504,
      "grad_norm": 3.653118133544922,
      "learning_rate": 1.499632691346381e-06,
      "loss": 0.84,
      "step": 48
    },
    {
      "epoch": 0.004053313480369348,
      "grad_norm": 3.5103344917297363,
      "learning_rate": 8.31051438486441e-07,
      "loss": 0.8116,
      "step": 49
    },
    {
      "epoch": 0.004136034163642192,
      "grad_norm": 4.318592071533203,
      "learning_rate": 3.572958295752049e-07,
      "loss": 0.8914,
      "step": 50
    },
    {
      "epoch": 0.004218754846915035,
      "grad_norm": 2.5561983585357666,
      "learning_rate": 8.02430603689397e-08,
      "loss": 1.4523,
      "step": 51
    },
    {
      "epoch": 0.00430147553018788,
      "grad_norm": 2.3827123641967773,
      "learning_rate": 9.999900908311602e-05,
      "loss": 1.2889,
      "step": 52
    },
    {
      "epoch": 0.004384196213460723,
      "grad_norm": 2.10959529876709,
      "learning_rate": 9.988014657443941e-05,
      "loss": 1.381,
      "step": 53
    },
    {
      "epoch": 0.004466916896733567,
      "grad_norm": 2.2905192375183105,
      "learning_rate": 9.956364039102642e-05,
      "loss": 1.2601,
      "step": 54
    },
    {
      "epoch": 0.0045496375800064106,
      "grad_norm": 2.2840139865875244,
      "learning_rate": 9.905074464798024e-05,
      "loss": 1.362,
      "step": 55
    },
    {
      "epoch": 0.004632358263279255,
      "grad_norm": 2.5473103523254395,
      "learning_rate": 9.83434916288119e-05,
      "loss": 1.4671,
      "step": 56
    },
    {
      "epoch": 0.004715078946552098,
      "grad_norm": 2.331167697906494,
      "learning_rate": 9.744468373277797e-05,
      "loss": 1.3009,
      "step": 57
    },
    {
      "epoch": 0.004797799629824942,
      "grad_norm": 2.356964111328125,
      "learning_rate": 9.635788237073334e-05,
      "loss": 1.3004,
      "step": 58
    },
    {
      "epoch": 0.004880520313097787,
      "grad_norm": 1.935747504234314,
      "learning_rate": 9.508739385349812e-05,
      "loss": 1.279,
      "step": 59
    },
    {
      "epoch": 0.00496324099637063,
      "grad_norm": 2.097308397293091,
      "learning_rate": 9.363825232865413e-05,
      "loss": 1.2061,
      "step": 60
    },
    {
      "epoch": 0.005045961679643474,
      "grad_norm": 2.7191247940063477,
      "learning_rate": 9.201619983338154e-05,
      "loss": 1.3142,
      "step": 61
    },
    {
      "epoch": 0.0051286823629163175,
      "grad_norm": 2.8408358097076416,
      "learning_rate": 9.0227663542374e-05,
      "loss": 1.3354,
      "step": 62
    },
    {
      "epoch": 0.005211403046189162,
      "grad_norm": 2.20768666267395,
      "learning_rate": 8.827973030098448e-05,
      "loss": 1.3382,
      "step": 63
    },
    {
      "epoch": 0.005294123729462005,
      "grad_norm": 2.572021007537842,
      "learning_rate": 8.618011854451056e-05,
      "loss": 1.1975,
      "step": 64
    },
    {
      "epoch": 0.005376844412734849,
      "grad_norm": 2.387615203857422,
      "learning_rate": 8.39371477148859e-05,
      "loss": 1.3162,
      "step": 65
    },
    {
      "epoch": 0.005459565096007693,
      "grad_norm": 2.2671873569488525,
      "learning_rate": 8.155970529596007e-05,
      "loss": 1.3249,
      "step": 66
    },
    {
      "epoch": 0.005542285779280537,
      "grad_norm": 2.1475541591644287,
      "learning_rate": 7.905721159798513e-05,
      "loss": 1.2075,
      "step": 67
    },
    {
      "epoch": 0.005625006462553381,
      "grad_norm": 2.0540103912353516,
      "learning_rate": 7.64395824308462e-05,
      "loss": 1.2061,
      "step": 68
    },
    {
      "epoch": 0.0057077271458262245,
      "grad_norm": 2.283553123474121,
      "learning_rate": 7.371718981393815e-05,
      "loss": 1.2781,
      "step": 69
    },
    {
      "epoch": 0.005790447829099069,
      "grad_norm": 2.343355655670166,
      "learning_rate": 7.090082087837091e-05,
      "loss": 1.0859,
      "step": 70
    },
    {
      "epoch": 0.005873168512371912,
      "grad_norm": 2.1701223850250244,
      "learning_rate": 6.80016351243478e-05,
      "loss": 1.1756,
      "step": 71
    },
    {
      "epoch": 0.005955889195644756,
      "grad_norm": 2.408067464828491,
      "learning_rate": 6.503112020307916e-05,
      "loss": 1.1072,
      "step": 72
    },
    {
      "epoch": 0.0060386098789176,
      "grad_norm": 2.0953032970428467,
      "learning_rate": 6.200104639843982e-05,
      "loss": 1.1853,
      "step": 73
    },
    {
      "epoch": 0.006121330562190444,
      "grad_norm": 2.4414994716644287,
      "learning_rate": 5.8923419988730864e-05,
      "loss": 1.2798,
      "step": 74
    },
    {
      "epoch": 0.006204051245463287,
      "grad_norm": 2.2131426334381104,
      "learning_rate": 5.5810435673343806e-05,
      "loss": 0.9928,
      "step": 75
    },
    {
      "epoch": 0.006286771928736131,
      "grad_norm": 2.310889720916748,
      "learning_rate": 5.267442825283045e-05,
      "loss": 0.9607,
      "step": 76
    },
    {
      "epoch": 0.006369492612008975,
      "grad_norm": 2.5549275875091553,
      "learning_rate": 4.95278237538398e-05,
      "loss": 1.1821,
      "step": 77
    },
    {
      "epoch": 0.006452213295281819,
      "grad_norm": 2.448997974395752,
      "learning_rate": 4.638309019258337e-05,
      "loss": 1.0145,
      "step": 78
    },
    {
      "epoch": 0.006534933978554663,
      "grad_norm": 2.943434953689575,
      "learning_rate": 4.32526881719222e-05,
      "loss": 1.0639,
      "step": 79
    },
    {
      "epoch": 0.006617654661827507,
      "grad_norm": 2.867375373840332,
      "learning_rate": 4.0149021507828265e-05,
      "loss": 1.2538,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4920550012772352.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
