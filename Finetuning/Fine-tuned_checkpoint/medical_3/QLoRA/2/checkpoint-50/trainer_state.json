{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.004136034163642192,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 8.272068327284383e-05,
      "grad_norm": 1.5043562650680542,
      "learning_rate": 0.0001,
      "loss": 1.9595,
      "step": 1
    },
    {
      "epoch": 0.00016544136654568766,
      "grad_norm": 1.8306677341461182,
      "learning_rate": 9.990094071072877e-05,
      "loss": 2.3019,
      "step": 2
    },
    {
      "epoch": 0.0002481620498185315,
      "grad_norm": 1.7613961696624756,
      "learning_rate": 9.960415535262671e-05,
      "loss": 2.2783,
      "step": 3
    },
    {
      "epoch": 0.0003308827330913753,
      "grad_norm": 1.9991271495819092,
      "learning_rate": 9.91108198995594e-05,
      "loss": 2.0563,
      "step": 4
    },
    {
      "epoch": 0.00041360341636421916,
      "grad_norm": NaN,
      "learning_rate": 9.91108198995594e-05,
      "loss": 2.2947,
      "step": 5
    },
    {
      "epoch": 0.000496324099637063,
      "grad_norm": 2.020979166030884,
      "learning_rate": 9.842288912990096e-05,
      "loss": 2.2119,
      "step": 6
    },
    {
      "epoch": 0.0005790447829099068,
      "grad_norm": 2.107518434524536,
      "learning_rate": 9.754308888097583e-05,
      "loss": 2.0839,
      "step": 7
    },
    {
      "epoch": 0.0006617654661827506,
      "grad_norm": 2.0635111331939697,
      "learning_rate": 9.647490524827834e-05,
      "loss": 2.0968,
      "step": 8
    },
    {
      "epoch": 0.0007444861494555945,
      "grad_norm": 2.1375210285186768,
      "learning_rate": 9.522257077226717e-05,
      "loss": 2.1344,
      "step": 9
    },
    {
      "epoch": 0.0008272068327284383,
      "grad_norm": 2.2170939445495605,
      "learning_rate": 9.379104766746722e-05,
      "loss": 1.7956,
      "step": 10
    },
    {
      "epoch": 0.0009099275160012822,
      "grad_norm": 2.70408034324646,
      "learning_rate": 9.2186008160332e-05,
      "loss": 1.772,
      "step": 11
    },
    {
      "epoch": 0.000992648199274126,
      "grad_norm": 2.7873737812042236,
      "learning_rate": 9.041381201377468e-05,
      "loss": 1.84,
      "step": 12
    },
    {
      "epoch": 0.00107536888254697,
      "grad_norm": 4.790360927581787,
      "learning_rate": 8.848148132742431e-05,
      "loss": 1.8058,
      "step": 13
    },
    {
      "epoch": 0.0011580895658198137,
      "grad_norm": 3.945890426635742,
      "learning_rate": 8.6396672713458e-05,
      "loss": 1.7737,
      "step": 14
    },
    {
      "epoch": 0.0012408102490926575,
      "grad_norm": 2.960235595703125,
      "learning_rate": 8.416764695825834e-05,
      "loss": 1.543,
      "step": 15
    },
    {
      "epoch": 0.0013235309323655013,
      "grad_norm": 3.493924856185913,
      "learning_rate": 8.180323629010848e-05,
      "loss": 1.3756,
      "step": 16
    },
    {
      "epoch": 0.0014062516156383453,
      "grad_norm": 5.751547336578369,
      "learning_rate": 7.93128093826217e-05,
      "loss": 1.4768,
      "step": 17
    },
    {
      "epoch": 0.001488972298911189,
      "grad_norm": 3.678823471069336,
      "learning_rate": 7.670623423257548e-05,
      "loss": 1.5063,
      "step": 18
    },
    {
      "epoch": 0.0015716929821840329,
      "grad_norm": 2.7539215087890625,
      "learning_rate": 7.399383905924165e-05,
      "loss": 1.4013,
      "step": 19
    },
    {
      "epoch": 0.0016544136654568766,
      "grad_norm": 2.9167375564575195,
      "learning_rate": 7.118637138014396e-05,
      "loss": 1.3577,
      "step": 20
    },
    {
      "epoch": 0.0017371343487297204,
      "grad_norm": 2.256544589996338,
      "learning_rate": 6.829495542540013e-05,
      "loss": 1.2725,
      "step": 21
    },
    {
      "epoch": 0.0018198550320025644,
      "grad_norm": 2.7758729457855225,
      "learning_rate": 6.533104805938873e-05,
      "loss": 1.3249,
      "step": 22
    },
    {
      "epoch": 0.0019025757152754082,
      "grad_norm": 3.7425026893615723,
      "learning_rate": 6.230639338439549e-05,
      "loss": 1.2934,
      "step": 23
    },
    {
      "epoch": 0.001985296398548252,
      "grad_norm": 5.221314907073975,
      "learning_rate": 5.923297620611623e-05,
      "loss": 1.1909,
      "step": 24
    },
    {
      "epoch": 0.002068017081821096,
      "grad_norm": 2.2888824939727783,
      "learning_rate": 5.6122974545403525e-05,
      "loss": 1.2838,
      "step": 25
    },
    {
      "epoch": 0.00215073776509394,
      "grad_norm": 2.5191752910614014,
      "learning_rate": 5.298871138442307e-05,
      "loss": 1.1959,
      "step": 26
    },
    {
      "epoch": 0.0022334584483667836,
      "grad_norm": 2.24515962600708,
      "learning_rate": 4.984260583841951e-05,
      "loss": 1.1333,
      "step": 27
    },
    {
      "epoch": 0.0023161791316396274,
      "grad_norm": 2.2987701892852783,
      "learning_rate": 4.6697123946567227e-05,
      "loss": 1.1369,
      "step": 28
    },
    {
      "epoch": 0.002398899814912471,
      "grad_norm": 3.235107660293579,
      "learning_rate": 4.356472927689109e-05,
      "loss": 1.0308,
      "step": 29
    },
    {
      "epoch": 0.002481620498185315,
      "grad_norm": 3.092144250869751,
      "learning_rate": 4.045783354097893e-05,
      "loss": 1.1718,
      "step": 30
    },
    {
      "epoch": 0.0025643411814581588,
      "grad_norm": 2.702939510345459,
      "learning_rate": 3.73887474141683e-05,
      "loss": 0.9858,
      "step": 31
    },
    {
      "epoch": 0.0026470618647310025,
      "grad_norm": 3.1886661052703857,
      "learning_rate": 3.436963175607658e-05,
      "loss": 1.0431,
      "step": 32
    },
    {
      "epoch": 0.0027297825480038463,
      "grad_norm": 2.6861298084259033,
      "learning_rate": 3.1412449424756474e-05,
      "loss": 1.2254,
      "step": 33
    },
    {
      "epoch": 0.0028125032312766906,
      "grad_norm": 2.322610855102539,
      "learning_rate": 2.8528917875407433e-05,
      "loss": 1.2049,
      "step": 34
    },
    {
      "epoch": 0.0028952239145495343,
      "grad_norm": 3.3600270748138428,
      "learning_rate": 2.5730462731464273e-05,
      "loss": 1.0007,
      "step": 35
    },
    {
      "epoch": 0.002977944597822378,
      "grad_norm": 3.2248644828796387,
      "learning_rate": 2.3028172512031604e-05,
      "loss": 1.0582,
      "step": 36
    },
    {
      "epoch": 0.003060665281095222,
      "grad_norm": 2.5334842205047607,
      "learning_rate": 2.0432754695051136e-05,
      "loss": 0.9331,
      "step": 37
    },
    {
      "epoch": 0.0031433859643680657,
      "grad_norm": 2.458400249481201,
      "learning_rate": 1.795449329029531e-05,
      "loss": 0.9865,
      "step": 38
    },
    {
      "epoch": 0.0032261066476409095,
      "grad_norm": 2.4662415981292725,
      "learning_rate": 1.560320809029948e-05,
      "loss": 0.9434,
      "step": 39
    },
    {
      "epoch": 0.0033088273309137533,
      "grad_norm": 2.526129722595215,
      "learning_rate": 1.3388215760695083e-05,
      "loss": 1.0176,
      "step": 40
    },
    {
      "epoch": 0.003391548014186597,
      "grad_norm": 2.6398019790649414,
      "learning_rate": 1.1318292924118601e-05,
      "loss": 0.8116,
      "step": 41
    },
    {
      "epoch": 0.003474268697459441,
      "grad_norm": 3.184659481048584,
      "learning_rate": 9.401641383971477e-06,
      "loss": 0.8309,
      "step": 42
    },
    {
      "epoch": 0.0035569893807322847,
      "grad_norm": 3.0133354663848877,
      "learning_rate": 7.64585562582767e-06,
      "loss": 0.8475,
      "step": 43
    },
    {
      "epoch": 0.003639710064005129,
      "grad_norm": 2.968069314956665,
      "learning_rate": 6.057892725259717e-06,
      "loss": 0.7816,
      "step": 44
    },
    {
      "epoch": 0.0037224307472779727,
      "grad_norm": 2.7015604972839355,
      "learning_rate": 4.644044781320422e-06,
      "loss": 0.7451,
      "step": 45
    },
    {
      "epoch": 0.0038051514305508165,
      "grad_norm": 2.995434284210205,
      "learning_rate": 3.4099139849083307e-06,
      "loss": 0.8383,
      "step": 46
    },
    {
      "epoch": 0.0038878721138236602,
      "grad_norm": 3.2848455905914307,
      "learning_rate": 2.360390420805869e-06,
      "loss": 0.7847,
      "step": 47
    },
    {
      "epoch": 0.003970592797096504,
      "grad_norm": 3.653118133544922,
      "learning_rate": 1.499632691346381e-06,
      "loss": 0.84,
      "step": 48
    },
    {
      "epoch": 0.004053313480369348,
      "grad_norm": 3.5103344917297363,
      "learning_rate": 8.31051438486441e-07,
      "loss": 0.8116,
      "step": 49
    },
    {
      "epoch": 0.004136034163642192,
      "grad_norm": 4.318592071533203,
      "learning_rate": 3.572958295752049e-07,
      "loss": 0.8914,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2897408510115840.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
