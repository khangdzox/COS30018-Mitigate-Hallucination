{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.012665576019842736,
  "eval_steps": 50,
  "global_step": 30,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004221858673280912,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.4295,
      "step": 1
    },
    {
      "epoch": 0.0008443717346561824,
      "grad_norm": 7.314651012420654,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.4013,
      "step": 2
    },
    {
      "epoch": 0.0012665576019842736,
      "grad_norm": 6.9283037185668945,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.3306,
      "step": 3
    },
    {
      "epoch": 0.0016887434693123647,
      "grad_norm": 6.449963569641113,
      "learning_rate": 2.4e-05,
      "loss": 2.3535,
      "step": 4
    },
    {
      "epoch": 0.002110929336640456,
      "grad_norm": 5.763070106506348,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.1936,
      "step": 5
    },
    {
      "epoch": 0.002533115203968547,
      "grad_norm": 5.586999893188477,
      "learning_rate": 4e-05,
      "loss": 2.3392,
      "step": 6
    },
    {
      "epoch": 0.0029553010712966383,
      "grad_norm": 5.173813343048096,
      "learning_rate": 4.8e-05,
      "loss": 2.1621,
      "step": 7
    },
    {
      "epoch": 0.0033774869386247294,
      "grad_norm": 4.872461318969727,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 2.0381,
      "step": 8
    },
    {
      "epoch": 0.0037996728059528206,
      "grad_norm": 6.684497356414795,
      "learning_rate": 6.400000000000001e-05,
      "loss": 1.8954,
      "step": 9
    },
    {
      "epoch": 0.004221858673280912,
      "grad_norm": 5.05430793762207,
      "learning_rate": 7.2e-05,
      "loss": 1.8105,
      "step": 10
    },
    {
      "epoch": 0.004644044540609003,
      "grad_norm": 5.299234867095947,
      "learning_rate": 8e-05,
      "loss": 1.6391,
      "step": 11
    },
    {
      "epoch": 0.005066230407937094,
      "grad_norm": 5.040134906768799,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.4951,
      "step": 12
    },
    {
      "epoch": 0.005488416275265185,
      "grad_norm": 5.925253868103027,
      "learning_rate": 9.6e-05,
      "loss": 1.2161,
      "step": 13
    },
    {
      "epoch": 0.005910602142593277,
      "grad_norm": 5.698432445526123,
      "learning_rate": 0.00010400000000000001,
      "loss": 1.3234,
      "step": 14
    },
    {
      "epoch": 0.006332788009921368,
      "grad_norm": 3.463573694229126,
      "learning_rate": 0.00011200000000000001,
      "loss": 1.1493,
      "step": 15
    },
    {
      "epoch": 0.006754973877249459,
      "grad_norm": 3.0398921966552734,
      "learning_rate": 0.00012,
      "loss": 1.1639,
      "step": 16
    },
    {
      "epoch": 0.0071771597445775505,
      "grad_norm": 6.070043563842773,
      "learning_rate": 0.00012800000000000002,
      "loss": 1.0663,
      "step": 17
    },
    {
      "epoch": 0.007599345611905641,
      "grad_norm": 2.8851804733276367,
      "learning_rate": 0.00013600000000000003,
      "loss": 1.1686,
      "step": 18
    },
    {
      "epoch": 0.008021531479233733,
      "grad_norm": 2.4904227256774902,
      "learning_rate": 0.000144,
      "loss": 1.0686,
      "step": 19
    },
    {
      "epoch": 0.008443717346561824,
      "grad_norm": 2.134871482849121,
      "learning_rate": 0.000152,
      "loss": 1.12,
      "step": 20
    },
    {
      "epoch": 0.008865903213889916,
      "grad_norm": 2.1338748931884766,
      "learning_rate": 0.00016,
      "loss": 1.1892,
      "step": 21
    },
    {
      "epoch": 0.009288089081218006,
      "grad_norm": 1.800367832183838,
      "learning_rate": 0.000168,
      "loss": 1.0706,
      "step": 22
    },
    {
      "epoch": 0.009710274948546097,
      "grad_norm": 1.8407763242721558,
      "learning_rate": 0.00017600000000000002,
      "loss": 1.0983,
      "step": 23
    },
    {
      "epoch": 0.010132460815874189,
      "grad_norm": 1.9127427339553833,
      "learning_rate": 0.00018400000000000003,
      "loss": 1.0502,
      "step": 24
    },
    {
      "epoch": 0.01055464668320228,
      "grad_norm": 1.7332693338394165,
      "learning_rate": 0.000192,
      "loss": 1.0383,
      "step": 25
    },
    {
      "epoch": 0.01097683255053037,
      "grad_norm": 1.8139773607254028,
      "learning_rate": 0.0002,
      "loss": 1.0738,
      "step": 26
    },
    {
      "epoch": 0.011399018417858462,
      "grad_norm": 1.9561471939086914,
      "learning_rate": 0.00019996500732179695,
      "loss": 1.0276,
      "step": 27
    },
    {
      "epoch": 0.011821204285186553,
      "grad_norm": 1.8228421211242676,
      "learning_rate": 0.00019986005377693825,
      "loss": 1.0166,
      "step": 28
    },
    {
      "epoch": 0.012243390152514645,
      "grad_norm": 1.6558241844177246,
      "learning_rate": 0.00019968521281753642,
      "loss": 1.0102,
      "step": 29
    },
    {
      "epoch": 0.012665576019842736,
      "grad_norm": 1.7567530870437622,
      "learning_rate": 0.00019944060680666002,
      "loss": 0.9556,
      "step": 30
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6946694700908544.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
