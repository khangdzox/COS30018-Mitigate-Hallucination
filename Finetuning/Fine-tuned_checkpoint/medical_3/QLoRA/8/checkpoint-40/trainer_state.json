{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.008443717346561824,
  "eval_steps": 50,
  "global_step": 40,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002110929336640456,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.3691,
      "step": 1
    },
    {
      "epoch": 0.0004221858673280912,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.416,
      "step": 2
    },
    {
      "epoch": 0.0006332788009921368,
      "grad_norm": 6.807020664215088,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.3649,
      "step": 3
    },
    {
      "epoch": 0.0008443717346561824,
      "grad_norm": 7.8769989013671875,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.4075,
      "step": 4
    },
    {
      "epoch": 0.001055464668320228,
      "grad_norm": 6.347095966339111,
      "learning_rate": 2.4e-05,
      "loss": 2.3102,
      "step": 5
    },
    {
      "epoch": 0.0012665576019842736,
      "grad_norm": 6.17477560043335,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.2682,
      "step": 6
    },
    {
      "epoch": 0.0014776505356483192,
      "grad_norm": 5.873278617858887,
      "learning_rate": 4e-05,
      "loss": 2.2759,
      "step": 7
    },
    {
      "epoch": 0.0016887434693123647,
      "grad_norm": 5.096736431121826,
      "learning_rate": 4.8e-05,
      "loss": 2.0541,
      "step": 8
    },
    {
      "epoch": 0.0018998364029764103,
      "grad_norm": 4.552121639251709,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 2.0383,
      "step": 9
    },
    {
      "epoch": 0.002110929336640456,
      "grad_norm": 5.858691215515137,
      "learning_rate": 6.400000000000001e-05,
      "loss": 1.8508,
      "step": 10
    },
    {
      "epoch": 0.0023220222703045014,
      "grad_norm": 5.081319808959961,
      "learning_rate": 7.2e-05,
      "loss": 1.7791,
      "step": 11
    },
    {
      "epoch": 0.002533115203968547,
      "grad_norm": 5.6146016120910645,
      "learning_rate": 8e-05,
      "loss": 1.6885,
      "step": 12
    },
    {
      "epoch": 0.0027442081376325925,
      "grad_norm": 5.249146938323975,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.6433,
      "step": 13
    },
    {
      "epoch": 0.0029553010712966383,
      "grad_norm": 4.616393566131592,
      "learning_rate": 9.6e-05,
      "loss": 1.4483,
      "step": 14
    },
    {
      "epoch": 0.003166394004960684,
      "grad_norm": 5.7103705406188965,
      "learning_rate": 0.00010400000000000001,
      "loss": 1.2204,
      "step": 15
    },
    {
      "epoch": 0.0033774869386247294,
      "grad_norm": 4.104544162750244,
      "learning_rate": 0.00011200000000000001,
      "loss": 1.2242,
      "step": 16
    },
    {
      "epoch": 0.0035885798722887752,
      "grad_norm": 3.869690418243408,
      "learning_rate": 0.00012,
      "loss": 1.2095,
      "step": 17
    },
    {
      "epoch": 0.0037996728059528206,
      "grad_norm": 3.5956668853759766,
      "learning_rate": 0.00012800000000000002,
      "loss": 1.1398,
      "step": 18
    },
    {
      "epoch": 0.004010765739616866,
      "grad_norm": 3.5690248012542725,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.9695,
      "step": 19
    },
    {
      "epoch": 0.004221858673280912,
      "grad_norm": 3.681173324584961,
      "learning_rate": 0.000144,
      "loss": 1.2005,
      "step": 20
    },
    {
      "epoch": 0.004432951606944958,
      "grad_norm": 3.237403154373169,
      "learning_rate": 0.000152,
      "loss": 0.9994,
      "step": 21
    },
    {
      "epoch": 0.004644044540609003,
      "grad_norm": 3.6076371669769287,
      "learning_rate": 0.00016,
      "loss": 1.0035,
      "step": 22
    },
    {
      "epoch": 0.004855137474273049,
      "grad_norm": 2.4924867153167725,
      "learning_rate": 0.000168,
      "loss": 1.0154,
      "step": 23
    },
    {
      "epoch": 0.005066230407937094,
      "grad_norm": 2.2719027996063232,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.9969,
      "step": 24
    },
    {
      "epoch": 0.00527732334160114,
      "grad_norm": 2.3194985389709473,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.9893,
      "step": 25
    },
    {
      "epoch": 0.005488416275265185,
      "grad_norm": 2.6515984535217285,
      "learning_rate": 0.000192,
      "loss": 1.1147,
      "step": 26
    },
    {
      "epoch": 0.005699509208929231,
      "grad_norm": 2.091484308242798,
      "learning_rate": 0.0002,
      "loss": 1.0238,
      "step": 27
    },
    {
      "epoch": 0.005910602142593277,
      "grad_norm": 3.6143767833709717,
      "learning_rate": 0.00019996500732179695,
      "loss": 1.0308,
      "step": 28
    },
    {
      "epoch": 0.006121695076257322,
      "grad_norm": 2.4553282260894775,
      "learning_rate": 0.00019986005377693825,
      "loss": 1.1369,
      "step": 29
    },
    {
      "epoch": 0.006332788009921368,
      "grad_norm": 2.28863263130188,
      "learning_rate": 0.00019968521281753642,
      "loss": 1.09,
      "step": 30
    },
    {
      "epoch": 0.006543880943585413,
      "grad_norm": 2.741995096206665,
      "learning_rate": 0.00019944060680666002,
      "loss": 1.1347,
      "step": 31
    },
    {
      "epoch": 0.006754973877249459,
      "grad_norm": 3.024139642715454,
      "learning_rate": 0.00019912640693269752,
      "loss": 0.9322,
      "step": 32
    },
    {
      "epoch": 0.006966066810913505,
      "grad_norm": 2.714616537094116,
      "learning_rate": 0.00019874283308955057,
      "loss": 1.0879,
      "step": 33
    },
    {
      "epoch": 0.0071771597445775505,
      "grad_norm": 2.513744354248047,
      "learning_rate": 0.00019829015372274038,
      "loss": 1.0296,
      "step": 34
    },
    {
      "epoch": 0.007388252678241596,
      "grad_norm": 2.2448623180389404,
      "learning_rate": 0.00019776868564153516,
      "loss": 1.0423,
      "step": 35
    },
    {
      "epoch": 0.007599345611905641,
      "grad_norm": 2.577422618865967,
      "learning_rate": 0.00019717879379723012,
      "loss": 1.075,
      "step": 36
    },
    {
      "epoch": 0.007810438545569687,
      "grad_norm": 2.0707976818084717,
      "learning_rate": 0.00019652089102773488,
      "loss": 0.9394,
      "step": 37
    },
    {
      "epoch": 0.008021531479233733,
      "grad_norm": 2.874846935272217,
      "learning_rate": 0.0001957954377686475,
      "loss": 1.1149,
      "step": 38
    },
    {
      "epoch": 0.008232624412897778,
      "grad_norm": 2.101222276687622,
      "learning_rate": 0.00019500294173101687,
      "loss": 1.0876,
      "step": 39
    },
    {
      "epoch": 0.008443717346561824,
      "grad_norm": 2.2608642578125,
      "learning_rate": 0.00019414395754601947,
      "loss": 1.092,
      "step": 40
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4619293776543744.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
