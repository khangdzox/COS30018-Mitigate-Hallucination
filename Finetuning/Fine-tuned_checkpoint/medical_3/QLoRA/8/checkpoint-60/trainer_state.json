{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.012665576019842736,
  "eval_steps": 50,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002110929336640456,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.3691,
      "step": 1
    },
    {
      "epoch": 0.0004221858673280912,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.416,
      "step": 2
    },
    {
      "epoch": 0.0006332788009921368,
      "grad_norm": 6.807020664215088,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.3649,
      "step": 3
    },
    {
      "epoch": 0.0008443717346561824,
      "grad_norm": 7.8769989013671875,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.4075,
      "step": 4
    },
    {
      "epoch": 0.001055464668320228,
      "grad_norm": 6.347095966339111,
      "learning_rate": 2.4e-05,
      "loss": 2.3102,
      "step": 5
    },
    {
      "epoch": 0.0012665576019842736,
      "grad_norm": 6.17477560043335,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.2682,
      "step": 6
    },
    {
      "epoch": 0.0014776505356483192,
      "grad_norm": 5.873278617858887,
      "learning_rate": 4e-05,
      "loss": 2.2759,
      "step": 7
    },
    {
      "epoch": 0.0016887434693123647,
      "grad_norm": 5.096736431121826,
      "learning_rate": 4.8e-05,
      "loss": 2.0541,
      "step": 8
    },
    {
      "epoch": 0.0018998364029764103,
      "grad_norm": 4.552121639251709,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 2.0383,
      "step": 9
    },
    {
      "epoch": 0.002110929336640456,
      "grad_norm": 5.858691215515137,
      "learning_rate": 6.400000000000001e-05,
      "loss": 1.8508,
      "step": 10
    },
    {
      "epoch": 0.0023220222703045014,
      "grad_norm": 5.081319808959961,
      "learning_rate": 7.2e-05,
      "loss": 1.7791,
      "step": 11
    },
    {
      "epoch": 0.002533115203968547,
      "grad_norm": 5.6146016120910645,
      "learning_rate": 8e-05,
      "loss": 1.6885,
      "step": 12
    },
    {
      "epoch": 0.0027442081376325925,
      "grad_norm": 5.249146938323975,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.6433,
      "step": 13
    },
    {
      "epoch": 0.0029553010712966383,
      "grad_norm": 4.616393566131592,
      "learning_rate": 9.6e-05,
      "loss": 1.4483,
      "step": 14
    },
    {
      "epoch": 0.003166394004960684,
      "grad_norm": 5.7103705406188965,
      "learning_rate": 0.00010400000000000001,
      "loss": 1.2204,
      "step": 15
    },
    {
      "epoch": 0.0033774869386247294,
      "grad_norm": 4.104544162750244,
      "learning_rate": 0.00011200000000000001,
      "loss": 1.2242,
      "step": 16
    },
    {
      "epoch": 0.0035885798722887752,
      "grad_norm": 3.869690418243408,
      "learning_rate": 0.00012,
      "loss": 1.2095,
      "step": 17
    },
    {
      "epoch": 0.0037996728059528206,
      "grad_norm": 3.5956668853759766,
      "learning_rate": 0.00012800000000000002,
      "loss": 1.1398,
      "step": 18
    },
    {
      "epoch": 0.004010765739616866,
      "grad_norm": 3.5690248012542725,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.9695,
      "step": 19
    },
    {
      "epoch": 0.004221858673280912,
      "grad_norm": 3.681173324584961,
      "learning_rate": 0.000144,
      "loss": 1.2005,
      "step": 20
    },
    {
      "epoch": 0.004432951606944958,
      "grad_norm": 3.237403154373169,
      "learning_rate": 0.000152,
      "loss": 0.9994,
      "step": 21
    },
    {
      "epoch": 0.004644044540609003,
      "grad_norm": 3.6076371669769287,
      "learning_rate": 0.00016,
      "loss": 1.0035,
      "step": 22
    },
    {
      "epoch": 0.004855137474273049,
      "grad_norm": 2.4924867153167725,
      "learning_rate": 0.000168,
      "loss": 1.0154,
      "step": 23
    },
    {
      "epoch": 0.005066230407937094,
      "grad_norm": 2.2719027996063232,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.9969,
      "step": 24
    },
    {
      "epoch": 0.00527732334160114,
      "grad_norm": 2.3194985389709473,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.9893,
      "step": 25
    },
    {
      "epoch": 0.005488416275265185,
      "grad_norm": 2.6515984535217285,
      "learning_rate": 0.000192,
      "loss": 1.1147,
      "step": 26
    },
    {
      "epoch": 0.005699509208929231,
      "grad_norm": 2.091484308242798,
      "learning_rate": 0.0002,
      "loss": 1.0238,
      "step": 27
    },
    {
      "epoch": 0.005910602142593277,
      "grad_norm": 3.6143767833709717,
      "learning_rate": 0.00019996500732179695,
      "loss": 1.0308,
      "step": 28
    },
    {
      "epoch": 0.006121695076257322,
      "grad_norm": 2.4553282260894775,
      "learning_rate": 0.00019986005377693825,
      "loss": 1.1369,
      "step": 29
    },
    {
      "epoch": 0.006332788009921368,
      "grad_norm": 2.28863263130188,
      "learning_rate": 0.00019968521281753642,
      "loss": 1.09,
      "step": 30
    },
    {
      "epoch": 0.006543880943585413,
      "grad_norm": 2.741995096206665,
      "learning_rate": 0.00019944060680666002,
      "loss": 1.1347,
      "step": 31
    },
    {
      "epoch": 0.006754973877249459,
      "grad_norm": 3.024139642715454,
      "learning_rate": 0.00019912640693269752,
      "loss": 0.9322,
      "step": 32
    },
    {
      "epoch": 0.006966066810913505,
      "grad_norm": 2.714616537094116,
      "learning_rate": 0.00019874283308955057,
      "loss": 1.0879,
      "step": 33
    },
    {
      "epoch": 0.0071771597445775505,
      "grad_norm": 2.513744354248047,
      "learning_rate": 0.00019829015372274038,
      "loss": 1.0296,
      "step": 34
    },
    {
      "epoch": 0.007388252678241596,
      "grad_norm": 2.2448623180389404,
      "learning_rate": 0.00019776868564153516,
      "loss": 1.0423,
      "step": 35
    },
    {
      "epoch": 0.007599345611905641,
      "grad_norm": 2.577422618865967,
      "learning_rate": 0.00019717879379723012,
      "loss": 1.075,
      "step": 36
    },
    {
      "epoch": 0.007810438545569687,
      "grad_norm": 2.0707976818084717,
      "learning_rate": 0.00019652089102773488,
      "loss": 0.9394,
      "step": 37
    },
    {
      "epoch": 0.008021531479233733,
      "grad_norm": 2.874846935272217,
      "learning_rate": 0.0001957954377686475,
      "loss": 1.1149,
      "step": 38
    },
    {
      "epoch": 0.008232624412897778,
      "grad_norm": 2.101222276687622,
      "learning_rate": 0.00019500294173101687,
      "loss": 1.0876,
      "step": 39
    },
    {
      "epoch": 0.008443717346561824,
      "grad_norm": 2.2608642578125,
      "learning_rate": 0.00019414395754601947,
      "loss": 1.092,
      "step": 40
    },
    {
      "epoch": 0.00865481028022587,
      "grad_norm": 2.42745304107666,
      "learning_rate": 0.00019321908637679865,
      "loss": 1.0146,
      "step": 41
    },
    {
      "epoch": 0.008865903213889916,
      "grad_norm": 2.0846669673919678,
      "learning_rate": 0.00019222897549773848,
      "loss": 1.0722,
      "step": 42
    },
    {
      "epoch": 0.00907699614755396,
      "grad_norm": 2.5345687866210938,
      "learning_rate": 0.00019117431784146645,
      "loss": 0.9833,
      "step": 43
    },
    {
      "epoch": 0.009288089081218006,
      "grad_norm": 1.990138292312622,
      "learning_rate": 0.00019005585151390223,
      "loss": 0.8795,
      "step": 44
    },
    {
      "epoch": 0.009499182014882052,
      "grad_norm": 2.339153528213501,
      "learning_rate": 0.00018887435927769137,
      "loss": 0.9318,
      "step": 45
    },
    {
      "epoch": 0.009710274948546097,
      "grad_norm": 2.3918116092681885,
      "learning_rate": 0.00018763066800438636,
      "loss": 1.1038,
      "step": 46
    },
    {
      "epoch": 0.009921367882210144,
      "grad_norm": 2.265064001083374,
      "learning_rate": 0.00018632564809575742,
      "loss": 1.0517,
      "step": 47
    },
    {
      "epoch": 0.010132460815874189,
      "grad_norm": 2.3979196548461914,
      "learning_rate": 0.0001849602128746387,
      "loss": 1.0281,
      "step": 48
    },
    {
      "epoch": 0.010343553749538234,
      "grad_norm": 2.517192840576172,
      "learning_rate": 0.00018353531794573625,
      "loss": 1.0349,
      "step": 49
    },
    {
      "epoch": 0.01055464668320228,
      "grad_norm": 2.0095040798187256,
      "learning_rate": 0.00018205196052684447,
      "loss": 1.0903,
      "step": 50
    },
    {
      "epoch": 0.01055464668320228,
      "eval_loss": 1.0612136125564575,
      "eval_runtime": 768.1333,
      "eval_samples_per_second": 5.194,
      "eval_steps_per_second": 2.597,
      "step": 50
    },
    {
      "epoch": 0.010765739616866325,
      "grad_norm": 2.168612480163574,
      "learning_rate": 0.00018051117875093976,
      "loss": 1.0553,
      "step": 51
    },
    {
      "epoch": 0.01097683255053037,
      "grad_norm": 2.135178327560425,
      "learning_rate": 0.00017891405093963938,
      "loss": 1.0162,
      "step": 52
    },
    {
      "epoch": 0.011187925484194417,
      "grad_norm": 2.4843032360076904,
      "learning_rate": 0.00017726169484853438,
      "loss": 0.9276,
      "step": 53
    },
    {
      "epoch": 0.011399018417858462,
      "grad_norm": 2.158724784851074,
      "learning_rate": 0.00017555526688492422,
      "loss": 1.0896,
      "step": 54
    },
    {
      "epoch": 0.011610111351522508,
      "grad_norm": 2.0862364768981934,
      "learning_rate": 0.00017379596129850098,
      "loss": 1.0947,
      "step": 55
    },
    {
      "epoch": 0.011821204285186553,
      "grad_norm": 2.0012271404266357,
      "learning_rate": 0.00017198500934554966,
      "loss": 0.9604,
      "step": 56
    },
    {
      "epoch": 0.012032297218850598,
      "grad_norm": 2.193112850189209,
      "learning_rate": 0.00017012367842724887,
      "loss": 0.9985,
      "step": 57
    },
    {
      "epoch": 0.012243390152514645,
      "grad_norm": 2.053908586502075,
      "learning_rate": 0.00016821327120267567,
      "loss": 1.024,
      "step": 58
    },
    {
      "epoch": 0.01245448308617869,
      "grad_norm": 1.8910744190216064,
      "learning_rate": 0.000166255124677135,
      "loss": 1.1621,
      "step": 59
    },
    {
      "epoch": 0.012665576019842736,
      "grad_norm": 1.6811447143554688,
      "learning_rate": 0.00016425060926645167,
      "loss": 0.8969,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6939890489106432.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
