{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.00397456279809221,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 6.624271330153684e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.2689,
      "step": 1
    },
    {
      "epoch": 0.00013248542660307367,
      "grad_norm": 3.935640573501587,
      "learning_rate": 2e-05,
      "loss": 2.3392,
      "step": 2
    },
    {
      "epoch": 0.0001987281399046105,
      "grad_norm": NaN,
      "learning_rate": 2e-05,
      "loss": 2.328,
      "step": 3
    },
    {
      "epoch": 0.00026497085320614734,
      "grad_norm": 3.172327995300293,
      "learning_rate": 4e-05,
      "loss": 2.23,
      "step": 4
    },
    {
      "epoch": 0.00033121356650768415,
      "grad_norm": 4.042605876922607,
      "learning_rate": 6e-05,
      "loss": 2.324,
      "step": 5
    },
    {
      "epoch": 0.000397456279809221,
      "grad_norm": 4.5806450843811035,
      "learning_rate": 8e-05,
      "loss": 2.3925,
      "step": 6
    },
    {
      "epoch": 0.0004636989931107578,
      "grad_norm": 3.348752498626709,
      "learning_rate": 0.0001,
      "loss": 2.1809,
      "step": 7
    },
    {
      "epoch": 0.0005299417064122947,
      "grad_norm": 3.5855343341827393,
      "learning_rate": 9.999899300364532e-05,
      "loss": 2.181,
      "step": 8
    },
    {
      "epoch": 0.0005961844197138314,
      "grad_norm": 3.9782562255859375,
      "learning_rate": 9.999597205514297e-05,
      "loss": 2.2029,
      "step": 9
    },
    {
      "epoch": 0.0006624271330153683,
      "grad_norm": 3.451857089996338,
      "learning_rate": 9.99909372761763e-05,
      "loss": 1.825,
      "step": 10
    },
    {
      "epoch": 0.0007286698463169052,
      "grad_norm": 3.3541646003723145,
      "learning_rate": 9.998388886954547e-05,
      "loss": 1.9844,
      "step": 11
    },
    {
      "epoch": 0.000794912559618442,
      "grad_norm": 4.102404594421387,
      "learning_rate": 9.997482711915927e-05,
      "loss": 2.1533,
      "step": 12
    },
    {
      "epoch": 0.0008611552729199788,
      "grad_norm": 5.836984634399414,
      "learning_rate": 9.996375239002369e-05,
      "loss": 1.9529,
      "step": 13
    },
    {
      "epoch": 0.0009273979862215156,
      "grad_norm": 4.671607971191406,
      "learning_rate": 9.99506651282272e-05,
      "loss": 1.7419,
      "step": 14
    },
    {
      "epoch": 0.0009936406995230524,
      "grad_norm": 6.9419403076171875,
      "learning_rate": 9.993556586092281e-05,
      "loss": 1.6356,
      "step": 15
    },
    {
      "epoch": 0.0010598834128245894,
      "grad_norm": 5.967659950256348,
      "learning_rate": 9.991845519630678e-05,
      "loss": 1.6832,
      "step": 16
    },
    {
      "epoch": 0.0011261261261261261,
      "grad_norm": 6.001219272613525,
      "learning_rate": 9.989933382359422e-05,
      "loss": 1.3467,
      "step": 17
    },
    {
      "epoch": 0.0011923688394276629,
      "grad_norm": 7.259174823760986,
      "learning_rate": 9.987820251299122e-05,
      "loss": 1.3676,
      "step": 18
    },
    {
      "epoch": 0.0012586115527291998,
      "grad_norm": 7.373693943023682,
      "learning_rate": 9.985506211566388e-05,
      "loss": 1.2509,
      "step": 19
    },
    {
      "epoch": 0.0013248542660307366,
      "grad_norm": 7.179003715515137,
      "learning_rate": 9.982991356370404e-05,
      "loss": 1.3077,
      "step": 20
    },
    {
      "epoch": 0.0013910969793322733,
      "grad_norm": 4.5587239265441895,
      "learning_rate": 9.98027578700917e-05,
      "loss": 1.5136,
      "step": 21
    },
    {
      "epoch": 0.0014573396926338103,
      "grad_norm": 4.268433570861816,
      "learning_rate": 9.977359612865423e-05,
      "loss": 1.2645,
      "step": 22
    },
    {
      "epoch": 0.001523582405935347,
      "grad_norm": 4.881389141082764,
      "learning_rate": 9.974242951402235e-05,
      "loss": 1.3434,
      "step": 23
    },
    {
      "epoch": 0.001589825119236884,
      "grad_norm": 4.863972187042236,
      "learning_rate": 9.970925928158274e-05,
      "loss": 1.3195,
      "step": 24
    },
    {
      "epoch": 0.0016560678325384208,
      "grad_norm": 17.17622947692871,
      "learning_rate": 9.967408676742751e-05,
      "loss": 1.3572,
      "step": 25
    },
    {
      "epoch": 0.0017223105458399576,
      "grad_norm": 3.2035300731658936,
      "learning_rate": 9.963691338830044e-05,
      "loss": 1.2448,
      "step": 26
    },
    {
      "epoch": 0.0017885532591414945,
      "grad_norm": 3.4512383937835693,
      "learning_rate": 9.959774064153977e-05,
      "loss": 1.2655,
      "step": 27
    },
    {
      "epoch": 0.0018547959724430313,
      "grad_norm": 2.893615245819092,
      "learning_rate": 9.955657010501806e-05,
      "loss": 1.232,
      "step": 28
    },
    {
      "epoch": 0.001921038685744568,
      "grad_norm": 3.7472167015075684,
      "learning_rate": 9.951340343707852e-05,
      "loss": 1.4194,
      "step": 29
    },
    {
      "epoch": 0.001987281399046105,
      "grad_norm": 3.8347768783569336,
      "learning_rate": 9.946824237646824e-05,
      "loss": 1.2648,
      "step": 30
    },
    {
      "epoch": 0.0020535241123476418,
      "grad_norm": 3.21195125579834,
      "learning_rate": 9.942108874226811e-05,
      "loss": 1.3137,
      "step": 31
    },
    {
      "epoch": 0.0021197668256491787,
      "grad_norm": 3.4692153930664062,
      "learning_rate": 9.937194443381972e-05,
      "loss": 1.1838,
      "step": 32
    },
    {
      "epoch": 0.0021860095389507153,
      "grad_norm": 3.0090458393096924,
      "learning_rate": 9.93208114306486e-05,
      "loss": 1.3544,
      "step": 33
    },
    {
      "epoch": 0.0022522522522522522,
      "grad_norm": 3.2744686603546143,
      "learning_rate": 9.926769179238466e-05,
      "loss": 1.3004,
      "step": 34
    },
    {
      "epoch": 0.002318494965553789,
      "grad_norm": 2.9766061305999756,
      "learning_rate": 9.921258765867919e-05,
      "loss": 1.2653,
      "step": 35
    },
    {
      "epoch": 0.0023847376788553257,
      "grad_norm": 3.0921878814697266,
      "learning_rate": 9.915550124911866e-05,
      "loss": 1.1329,
      "step": 36
    },
    {
      "epoch": 0.0024509803921568627,
      "grad_norm": 2.7303004264831543,
      "learning_rate": 9.909643486313533e-05,
      "loss": 1.089,
      "step": 37
    },
    {
      "epoch": 0.0025172231054583997,
      "grad_norm": 3.438199758529663,
      "learning_rate": 9.903539087991462e-05,
      "loss": 1.3225,
      "step": 38
    },
    {
      "epoch": 0.0025834658187599362,
      "grad_norm": 2.709054470062256,
      "learning_rate": 9.897237175829926e-05,
      "loss": 1.1871,
      "step": 39
    },
    {
      "epoch": 0.002649708532061473,
      "grad_norm": 2.9012386798858643,
      "learning_rate": 9.890738003669029e-05,
      "loss": 1.2922,
      "step": 40
    },
    {
      "epoch": 0.00271595124536301,
      "grad_norm": 3.2810704708099365,
      "learning_rate": 9.884041833294476e-05,
      "loss": 1.1932,
      "step": 41
    },
    {
      "epoch": 0.0027821939586645467,
      "grad_norm": 2.953472852706909,
      "learning_rate": 9.877148934427037e-05,
      "loss": 0.9832,
      "step": 42
    },
    {
      "epoch": 0.0028484366719660837,
      "grad_norm": 3.304927349090576,
      "learning_rate": 9.870059584711668e-05,
      "loss": 0.967,
      "step": 43
    },
    {
      "epoch": 0.0029146793852676206,
      "grad_norm": 3.002321720123291,
      "learning_rate": 9.862774069706346e-05,
      "loss": 1.1302,
      "step": 44
    },
    {
      "epoch": 0.0029809220985691576,
      "grad_norm": 3.673306465148926,
      "learning_rate": 9.855292682870551e-05,
      "loss": 1.1649,
      "step": 45
    },
    {
      "epoch": 0.003047164811870694,
      "grad_norm": 3.451751232147217,
      "learning_rate": 9.847615725553456e-05,
      "loss": 1.1961,
      "step": 46
    },
    {
      "epoch": 0.003113407525172231,
      "grad_norm": 3.4889540672302246,
      "learning_rate": 9.839743506981782e-05,
      "loss": 1.1033,
      "step": 47
    },
    {
      "epoch": 0.003179650238473768,
      "grad_norm": 3.8954901695251465,
      "learning_rate": 9.831676344247342e-05,
      "loss": 1.0559,
      "step": 48
    },
    {
      "epoch": 0.0032458929517753046,
      "grad_norm": 3.8720455169677734,
      "learning_rate": 9.82341456229428e-05,
      "loss": 1.2445,
      "step": 49
    },
    {
      "epoch": 0.0033121356650768416,
      "grad_norm": 2.5133635997772217,
      "learning_rate": 9.814958493905963e-05,
      "loss": 0.9382,
      "step": 50
    },
    {
      "epoch": 0.0033783783783783786,
      "grad_norm": 3.5231356620788574,
      "learning_rate": 9.806308479691595e-05,
      "loss": 1.2273,
      "step": 51
    },
    {
      "epoch": 0.003444621091679915,
      "grad_norm": 3.230523109436035,
      "learning_rate": 9.797464868072488e-05,
      "loss": 1.2495,
      "step": 52
    },
    {
      "epoch": 0.003510863804981452,
      "grad_norm": 3.12392520904541,
      "learning_rate": 9.788428015268027e-05,
      "loss": 1.2135,
      "step": 53
    },
    {
      "epoch": 0.003577106518282989,
      "grad_norm": 3.016922950744629,
      "learning_rate": 9.779198285281325e-05,
      "loss": 1.1439,
      "step": 54
    },
    {
      "epoch": 0.0036433492315845256,
      "grad_norm": 3.000917673110962,
      "learning_rate": 9.769776049884563e-05,
      "loss": 1.1964,
      "step": 55
    },
    {
      "epoch": 0.0037095919448860626,
      "grad_norm": 3.609166145324707,
      "learning_rate": 9.760161688604008e-05,
      "loss": 1.0649,
      "step": 56
    },
    {
      "epoch": 0.0037758346581875995,
      "grad_norm": 3.220571517944336,
      "learning_rate": 9.750355588704727e-05,
      "loss": 1.2922,
      "step": 57
    },
    {
      "epoch": 0.003842077371489136,
      "grad_norm": 3.3062751293182373,
      "learning_rate": 9.740358145174998e-05,
      "loss": 1.2174,
      "step": 58
    },
    {
      "epoch": 0.003908320084790673,
      "grad_norm": 3.251234769821167,
      "learning_rate": 9.730169760710386e-05,
      "loss": 1.2926,
      "step": 59
    },
    {
      "epoch": 0.00397456279809221,
      "grad_norm": 3.6804213523864746,
      "learning_rate": 9.719790845697533e-05,
      "loss": 0.9211,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3928013100564480.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
