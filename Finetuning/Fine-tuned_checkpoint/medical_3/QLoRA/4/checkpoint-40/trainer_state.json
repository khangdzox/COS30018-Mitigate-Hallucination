{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.002649708532061473,
  "eval_steps": 500,
  "global_step": 40,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 6.624271330153684e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.2689,
      "step": 1
    },
    {
      "epoch": 0.00013248542660307367,
      "grad_norm": 3.935640573501587,
      "learning_rate": 2e-05,
      "loss": 2.3392,
      "step": 2
    },
    {
      "epoch": 0.0001987281399046105,
      "grad_norm": NaN,
      "learning_rate": 2e-05,
      "loss": 2.328,
      "step": 3
    },
    {
      "epoch": 0.00026497085320614734,
      "grad_norm": 3.172327995300293,
      "learning_rate": 4e-05,
      "loss": 2.23,
      "step": 4
    },
    {
      "epoch": 0.00033121356650768415,
      "grad_norm": 4.042605876922607,
      "learning_rate": 6e-05,
      "loss": 2.324,
      "step": 5
    },
    {
      "epoch": 0.000397456279809221,
      "grad_norm": 4.5806450843811035,
      "learning_rate": 8e-05,
      "loss": 2.3925,
      "step": 6
    },
    {
      "epoch": 0.0004636989931107578,
      "grad_norm": 3.348752498626709,
      "learning_rate": 0.0001,
      "loss": 2.1809,
      "step": 7
    },
    {
      "epoch": 0.0005299417064122947,
      "grad_norm": 3.5855343341827393,
      "learning_rate": 9.999899300364532e-05,
      "loss": 2.181,
      "step": 8
    },
    {
      "epoch": 0.0005961844197138314,
      "grad_norm": 3.9782562255859375,
      "learning_rate": 9.999597205514297e-05,
      "loss": 2.2029,
      "step": 9
    },
    {
      "epoch": 0.0006624271330153683,
      "grad_norm": 3.451857089996338,
      "learning_rate": 9.99909372761763e-05,
      "loss": 1.825,
      "step": 10
    },
    {
      "epoch": 0.0007286698463169052,
      "grad_norm": 3.3541646003723145,
      "learning_rate": 9.998388886954547e-05,
      "loss": 1.9844,
      "step": 11
    },
    {
      "epoch": 0.000794912559618442,
      "grad_norm": 4.102404594421387,
      "learning_rate": 9.997482711915927e-05,
      "loss": 2.1533,
      "step": 12
    },
    {
      "epoch": 0.0008611552729199788,
      "grad_norm": 5.836984634399414,
      "learning_rate": 9.996375239002369e-05,
      "loss": 1.9529,
      "step": 13
    },
    {
      "epoch": 0.0009273979862215156,
      "grad_norm": 4.671607971191406,
      "learning_rate": 9.99506651282272e-05,
      "loss": 1.7419,
      "step": 14
    },
    {
      "epoch": 0.0009936406995230524,
      "grad_norm": 6.9419403076171875,
      "learning_rate": 9.993556586092281e-05,
      "loss": 1.6356,
      "step": 15
    },
    {
      "epoch": 0.0010598834128245894,
      "grad_norm": 5.967659950256348,
      "learning_rate": 9.991845519630678e-05,
      "loss": 1.6832,
      "step": 16
    },
    {
      "epoch": 0.0011261261261261261,
      "grad_norm": 6.001219272613525,
      "learning_rate": 9.989933382359422e-05,
      "loss": 1.3467,
      "step": 17
    },
    {
      "epoch": 0.0011923688394276629,
      "grad_norm": 7.259174823760986,
      "learning_rate": 9.987820251299122e-05,
      "loss": 1.3676,
      "step": 18
    },
    {
      "epoch": 0.0012586115527291998,
      "grad_norm": 7.373693943023682,
      "learning_rate": 9.985506211566388e-05,
      "loss": 1.2509,
      "step": 19
    },
    {
      "epoch": 0.0013248542660307366,
      "grad_norm": 7.179003715515137,
      "learning_rate": 9.982991356370404e-05,
      "loss": 1.3077,
      "step": 20
    },
    {
      "epoch": 0.0013910969793322733,
      "grad_norm": 4.5587239265441895,
      "learning_rate": 9.98027578700917e-05,
      "loss": 1.5136,
      "step": 21
    },
    {
      "epoch": 0.0014573396926338103,
      "grad_norm": 4.268433570861816,
      "learning_rate": 9.977359612865423e-05,
      "loss": 1.2645,
      "step": 22
    },
    {
      "epoch": 0.001523582405935347,
      "grad_norm": 4.881389141082764,
      "learning_rate": 9.974242951402235e-05,
      "loss": 1.3434,
      "step": 23
    },
    {
      "epoch": 0.001589825119236884,
      "grad_norm": 4.863972187042236,
      "learning_rate": 9.970925928158274e-05,
      "loss": 1.3195,
      "step": 24
    },
    {
      "epoch": 0.0016560678325384208,
      "grad_norm": 17.17622947692871,
      "learning_rate": 9.967408676742751e-05,
      "loss": 1.3572,
      "step": 25
    },
    {
      "epoch": 0.0017223105458399576,
      "grad_norm": 3.2035300731658936,
      "learning_rate": 9.963691338830044e-05,
      "loss": 1.2448,
      "step": 26
    },
    {
      "epoch": 0.0017885532591414945,
      "grad_norm": 3.4512383937835693,
      "learning_rate": 9.959774064153977e-05,
      "loss": 1.2655,
      "step": 27
    },
    {
      "epoch": 0.0018547959724430313,
      "grad_norm": 2.893615245819092,
      "learning_rate": 9.955657010501806e-05,
      "loss": 1.232,
      "step": 28
    },
    {
      "epoch": 0.001921038685744568,
      "grad_norm": 3.7472167015075684,
      "learning_rate": 9.951340343707852e-05,
      "loss": 1.4194,
      "step": 29
    },
    {
      "epoch": 0.001987281399046105,
      "grad_norm": 3.8347768783569336,
      "learning_rate": 9.946824237646824e-05,
      "loss": 1.2648,
      "step": 30
    },
    {
      "epoch": 0.0020535241123476418,
      "grad_norm": 3.21195125579834,
      "learning_rate": 9.942108874226811e-05,
      "loss": 1.3137,
      "step": 31
    },
    {
      "epoch": 0.0021197668256491787,
      "grad_norm": 3.4692153930664062,
      "learning_rate": 9.937194443381972e-05,
      "loss": 1.1838,
      "step": 32
    },
    {
      "epoch": 0.0021860095389507153,
      "grad_norm": 3.0090458393096924,
      "learning_rate": 9.93208114306486e-05,
      "loss": 1.3544,
      "step": 33
    },
    {
      "epoch": 0.0022522522522522522,
      "grad_norm": 3.2744686603546143,
      "learning_rate": 9.926769179238466e-05,
      "loss": 1.3004,
      "step": 34
    },
    {
      "epoch": 0.002318494965553789,
      "grad_norm": 2.9766061305999756,
      "learning_rate": 9.921258765867919e-05,
      "loss": 1.2653,
      "step": 35
    },
    {
      "epoch": 0.0023847376788553257,
      "grad_norm": 3.0921878814697266,
      "learning_rate": 9.915550124911866e-05,
      "loss": 1.1329,
      "step": 36
    },
    {
      "epoch": 0.0024509803921568627,
      "grad_norm": 2.7303004264831543,
      "learning_rate": 9.909643486313533e-05,
      "loss": 1.089,
      "step": 37
    },
    {
      "epoch": 0.0025172231054583997,
      "grad_norm": 3.438199758529663,
      "learning_rate": 9.903539087991462e-05,
      "loss": 1.3225,
      "step": 38
    },
    {
      "epoch": 0.0025834658187599362,
      "grad_norm": 2.709054470062256,
      "learning_rate": 9.897237175829926e-05,
      "loss": 1.1871,
      "step": 39
    },
    {
      "epoch": 0.002649708532061473,
      "grad_norm": 2.9012386798858643,
      "learning_rate": 9.890738003669029e-05,
      "loss": 1.2922,
      "step": 40
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2647362478694400.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
