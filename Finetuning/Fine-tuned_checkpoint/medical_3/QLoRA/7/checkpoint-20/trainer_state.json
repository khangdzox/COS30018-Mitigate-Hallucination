{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.004193256719038696,
  "eval_steps": 50,
  "global_step": 20,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002096628359519348,
      "grad_norm": 3.5371694564819336,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.408,
      "step": 1
    },
    {
      "epoch": 0.0004193256719038696,
      "grad_norm": 3.761871337890625,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.4085,
      "step": 2
    },
    {
      "epoch": 0.0006289885078558044,
      "grad_norm": 2.993016004562378,
      "learning_rate": 2.4e-05,
      "loss": 2.3777,
      "step": 3
    },
    {
      "epoch": 0.0008386513438077392,
      "grad_norm": 3.058147430419922,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.2944,
      "step": 4
    },
    {
      "epoch": 0.001048314179759674,
      "grad_norm": 2.921541213989258,
      "learning_rate": 4e-05,
      "loss": 2.1401,
      "step": 5
    },
    {
      "epoch": 0.0012579770157116088,
      "grad_norm": 2.884770154953003,
      "learning_rate": 4.8e-05,
      "loss": 2.0845,
      "step": 6
    },
    {
      "epoch": 0.0014676398516635435,
      "grad_norm": 3.0192008018493652,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 1.9675,
      "step": 7
    },
    {
      "epoch": 0.0016773026876154783,
      "grad_norm": 3.906329870223999,
      "learning_rate": 6.400000000000001e-05,
      "loss": 1.7404,
      "step": 8
    },
    {
      "epoch": 0.0018869655235674132,
      "grad_norm": 8.74871826171875,
      "learning_rate": 7.2e-05,
      "loss": 1.7543,
      "step": 9
    },
    {
      "epoch": 0.002096628359519348,
      "grad_norm": 3.596379518508911,
      "learning_rate": 8e-05,
      "loss": 1.5254,
      "step": 10
    },
    {
      "epoch": 0.0023062911954712826,
      "grad_norm": 4.321800231933594,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.3095,
      "step": 11
    },
    {
      "epoch": 0.0025159540314232177,
      "grad_norm": 2.9800682067871094,
      "learning_rate": 9.6e-05,
      "loss": 1.3179,
      "step": 12
    },
    {
      "epoch": 0.0027256168673751523,
      "grad_norm": 2.802454948425293,
      "learning_rate": 0.00010400000000000001,
      "loss": 1.1746,
      "step": 13
    },
    {
      "epoch": 0.002935279703327087,
      "grad_norm": 5.052653789520264,
      "learning_rate": 0.00011200000000000001,
      "loss": 1.1156,
      "step": 14
    },
    {
      "epoch": 0.003144942539279022,
      "grad_norm": 2.2398147583007812,
      "learning_rate": 0.00012,
      "loss": 1.035,
      "step": 15
    },
    {
      "epoch": 0.0033546053752309566,
      "grad_norm": 1.8696058988571167,
      "learning_rate": 0.00012800000000000002,
      "loss": 1.1452,
      "step": 16
    },
    {
      "epoch": 0.0035642682111828917,
      "grad_norm": 1.904510259628296,
      "learning_rate": 0.00013600000000000003,
      "loss": 1.1697,
      "step": 17
    },
    {
      "epoch": 0.0037739310471348263,
      "grad_norm": 2.34637451171875,
      "learning_rate": 0.000144,
      "loss": 1.1921,
      "step": 18
    },
    {
      "epoch": 0.003983593883086761,
      "grad_norm": 2.749218702316284,
      "learning_rate": 0.000152,
      "loss": 1.168,
      "step": 19
    },
    {
      "epoch": 0.004193256719038696,
      "grad_norm": 1.444578766822815,
      "learning_rate": 0.00016,
      "loss": 1.1658,
      "step": 20
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2307304306335744.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
