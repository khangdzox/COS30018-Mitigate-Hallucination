{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0033121356650768416,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 6.624271330153684e-05,
      "grad_norm": 1.3809800148010254,
      "learning_rate": 1.6e-06,
      "loss": 2.2689,
      "step": 1
    },
    {
      "epoch": 0.00013248542660307367,
      "grad_norm": 1.6996265649795532,
      "learning_rate": 3.2e-06,
      "loss": 2.3392,
      "step": 2
    },
    {
      "epoch": 0.0001987281399046105,
      "grad_norm": 1.5995228290557861,
      "learning_rate": 4.8e-06,
      "loss": 2.327,
      "step": 3
    },
    {
      "epoch": 0.00026497085320614734,
      "grad_norm": 1.2807488441467285,
      "learning_rate": 6.4e-06,
      "loss": 2.2282,
      "step": 4
    },
    {
      "epoch": 0.00033121356650768415,
      "grad_norm": 1.7918407917022705,
      "learning_rate": 8e-06,
      "loss": 2.3296,
      "step": 5
    },
    {
      "epoch": 0.000397456279809221,
      "grad_norm": 2.1889030933380127,
      "learning_rate": 7.999919440291625e-06,
      "loss": 2.4252,
      "step": 6
    },
    {
      "epoch": 0.0004636989931107578,
      "grad_norm": 1.4946634769439697,
      "learning_rate": 7.999677764411437e-06,
      "loss": 2.2345,
      "step": 7
    },
    {
      "epoch": 0.0005299417064122947,
      "grad_norm": 1.4097577333450317,
      "learning_rate": 7.999274982094103e-06,
      "loss": 2.2835,
      "step": 8
    },
    {
      "epoch": 0.0005961844197138314,
      "grad_norm": 1.5491282939910889,
      "learning_rate": 7.998711109563636e-06,
      "loss": 2.3787,
      "step": 9
    },
    {
      "epoch": 0.0006624271330153683,
      "grad_norm": 1.5071535110473633,
      "learning_rate": 7.99798616953274e-06,
      "loss": 2.084,
      "step": 10
    },
    {
      "epoch": 0.0007286698463169052,
      "grad_norm": 1.3594766855239868,
      "learning_rate": 7.997100191201894e-06,
      "loss": 2.2995,
      "step": 11
    },
    {
      "epoch": 0.000794912559618442,
      "grad_norm": 1.4487510919570923,
      "learning_rate": 7.996053210258175e-06,
      "loss": 2.5685,
      "step": 12
    },
    {
      "epoch": 0.0008611552729199788,
      "grad_norm": 1.9860165119171143,
      "learning_rate": 7.994845268873824e-06,
      "loss": 2.5732,
      "step": 13
    },
    {
      "epoch": 0.0009273979862215156,
      "grad_norm": 1.3641774654388428,
      "learning_rate": 7.993476415704541e-06,
      "loss": 2.2761,
      "step": 14
    },
    {
      "epoch": 0.0009936406995230524,
      "grad_norm": 1.6011816263198853,
      "learning_rate": 7.991946705887537e-06,
      "loss": 2.2512,
      "step": 15
    },
    {
      "epoch": 0.0010598834128245894,
      "grad_norm": 1.6379209756851196,
      "learning_rate": 7.990256201039296e-06,
      "loss": 2.3967,
      "step": 16
    },
    {
      "epoch": 0.0011261261261261261,
      "grad_norm": 1.312429428100586,
      "learning_rate": 7.988404969253109e-06,
      "loss": 2.0369,
      "step": 17
    },
    {
      "epoch": 0.0011923688394276629,
      "grad_norm": 1.5695819854736328,
      "learning_rate": 7.986393085096323e-06,
      "loss": 2.2738,
      "step": 18
    },
    {
      "epoch": 0.0012586115527291998,
      "grad_norm": 1.7151944637298584,
      "learning_rate": 7.984220629607335e-06,
      "loss": 2.2317,
      "step": 19
    },
    {
      "epoch": 0.0013248542660307366,
      "grad_norm": 1.3730355501174927,
      "learning_rate": 7.981887690292338e-06,
      "loss": 2.2022,
      "step": 20
    },
    {
      "epoch": 0.0013910969793322733,
      "grad_norm": 1.6174428462982178,
      "learning_rate": 7.979394361121788e-06,
      "loss": 2.4936,
      "step": 21
    },
    {
      "epoch": 0.0014573396926338103,
      "grad_norm": 1.417569637298584,
      "learning_rate": 7.976740742526617e-06,
      "loss": 2.1494,
      "step": 22
    },
    {
      "epoch": 0.001523582405935347,
      "grad_norm": 1.4038379192352295,
      "learning_rate": 7.973926941394201e-06,
      "loss": 2.2114,
      "step": 23
    },
    {
      "epoch": 0.001589825119236884,
      "grad_norm": 1.4127357006072998,
      "learning_rate": 7.970953071064033e-06,
      "loss": 2.2311,
      "step": 24
    },
    {
      "epoch": 0.0016560678325384208,
      "grad_norm": 1.5051912069320679,
      "learning_rate": 7.96781925132318e-06,
      "loss": 2.215,
      "step": 25
    },
    {
      "epoch": 0.0017223105458399576,
      "grad_norm": 1.38594651222229,
      "learning_rate": 7.964525608401445e-06,
      "loss": 2.1734,
      "step": 26
    },
    {
      "epoch": 0.0017885532591414945,
      "grad_norm": 1.5026637315750122,
      "learning_rate": 7.96107227496628e-06,
      "loss": 2.256,
      "step": 27
    },
    {
      "epoch": 0.0018547959724430313,
      "grad_norm": 1.3919044733047485,
      "learning_rate": 7.957459390117459e-06,
      "loss": 2.1654,
      "step": 28
    },
    {
      "epoch": 0.001921038685744568,
      "grad_norm": 1.4173874855041504,
      "learning_rate": 7.953687099381448e-06,
      "loss": 2.3061,
      "step": 29
    },
    {
      "epoch": 0.001987281399046105,
      "grad_norm": 1.6002627611160278,
      "learning_rate": 7.949755554705577e-06,
      "loss": 2.2258,
      "step": 30
    },
    {
      "epoch": 0.0020535241123476418,
      "grad_norm": 1.5717726945877075,
      "learning_rate": 7.945664914451887e-06,
      "loss": 2.2467,
      "step": 31
    },
    {
      "epoch": 0.0021197668256491787,
      "grad_norm": 1.6920794248580933,
      "learning_rate": 7.941415343390771e-06,
      "loss": 2.1356,
      "step": 32
    },
    {
      "epoch": 0.0021860095389507153,
      "grad_norm": 1.4630272388458252,
      "learning_rate": 7.937007012694335e-06,
      "loss": 2.2694,
      "step": 33
    },
    {
      "epoch": 0.0022522522522522522,
      "grad_norm": 1.5543068647384644,
      "learning_rate": 7.932440099929493e-06,
      "loss": 2.2479,
      "step": 34
    },
    {
      "epoch": 0.002318494965553789,
      "grad_norm": 1.2894253730773926,
      "learning_rate": 7.927714789050827e-06,
      "loss": 2.0509,
      "step": 35
    },
    {
      "epoch": 0.0023847376788553257,
      "grad_norm": 1.5814480781555176,
      "learning_rate": 7.922831270393169e-06,
      "loss": 2.1374,
      "step": 36
    },
    {
      "epoch": 0.0024509803921568627,
      "grad_norm": 1.5754947662353516,
      "learning_rate": 7.917789740663941e-06,
      "loss": 1.9903,
      "step": 37
    },
    {
      "epoch": 0.0025172231054583997,
      "grad_norm": 1.5083675384521484,
      "learning_rate": 7.912590402935222e-06,
      "loss": 2.2261,
      "step": 38
    },
    {
      "epoch": 0.0025834658187599362,
      "grad_norm": 1.5683575868606567,
      "learning_rate": 7.90723346663558e-06,
      "loss": 2.1183,
      "step": 39
    },
    {
      "epoch": 0.002649708532061473,
      "grad_norm": 1.5738838911056519,
      "learning_rate": 7.901719147541628e-06,
      "loss": 2.2268,
      "step": 40
    },
    {
      "epoch": 0.00271595124536301,
      "grad_norm": 1.6617158651351929,
      "learning_rate": 7.896047667769334e-06,
      "loss": 2.1754,
      "step": 41
    },
    {
      "epoch": 0.0027821939586645467,
      "grad_norm": 1.6001683473587036,
      "learning_rate": 7.890219255765076e-06,
      "loss": 1.8818,
      "step": 42
    },
    {
      "epoch": 0.0028484366719660837,
      "grad_norm": 1.7564657926559448,
      "learning_rate": 7.88423414629644e-06,
      "loss": 2.0247,
      "step": 43
    },
    {
      "epoch": 0.0029146793852676206,
      "grad_norm": 1.3842233419418335,
      "learning_rate": 7.878092580442764e-06,
      "loss": 1.9519,
      "step": 44
    },
    {
      "epoch": 0.0029809220985691576,
      "grad_norm": 1.5279793739318848,
      "learning_rate": 7.871794805585425e-06,
      "loss": 2.1173,
      "step": 45
    },
    {
      "epoch": 0.003047164811870694,
      "grad_norm": 1.4517604112625122,
      "learning_rate": 7.865341075397873e-06,
      "loss": 2.0558,
      "step": 46
    },
    {
      "epoch": 0.003113407525172231,
      "grad_norm": 1.494954228401184,
      "learning_rate": 7.858731649835423e-06,
      "loss": 2.0556,
      "step": 47
    },
    {
      "epoch": 0.003179650238473768,
      "grad_norm": 1.8161464929580688,
      "learning_rate": 7.85196679512477e-06,
      "loss": 2.1374,
      "step": 48
    },
    {
      "epoch": 0.0032458929517753046,
      "grad_norm": 1.441933274269104,
      "learning_rate": 7.845046783753275e-06,
      "loss": 2.1359,
      "step": 49
    },
    {
      "epoch": 0.0033121356650768416,
      "grad_norm": 1.527364730834961,
      "learning_rate": 7.837971894457989e-06,
      "loss": 1.8756,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3283291594948608.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
