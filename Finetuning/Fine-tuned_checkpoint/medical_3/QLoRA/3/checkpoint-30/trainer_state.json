{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.001987281399046105,
  "eval_steps": 500,
  "global_step": 30,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 6.624271330153684e-05,
      "grad_norm": 1.4970004558563232,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.2689,
      "step": 1
    },
    {
      "epoch": 0.00013248542660307367,
      "grad_norm": 1.8705312013626099,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.3392,
      "step": 2
    },
    {
      "epoch": 0.0001987281399046105,
      "grad_norm": 1.7034006118774414,
      "learning_rate": 6e-06,
      "loss": 2.3278,
      "step": 3
    },
    {
      "epoch": 0.00026497085320614734,
      "grad_norm": 1.3584656715393066,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.2298,
      "step": 4
    },
    {
      "epoch": 0.00033121356650768415,
      "grad_norm": 1.9928151369094849,
      "learning_rate": 1e-05,
      "loss": 2.3347,
      "step": 5
    },
    {
      "epoch": 0.000397456279809221,
      "grad_norm": 2.5016543865203857,
      "learning_rate": 9.999899300364534e-06,
      "loss": 2.4366,
      "step": 6
    },
    {
      "epoch": 0.0004636989931107578,
      "grad_norm": 1.690055251121521,
      "learning_rate": 9.999597205514298e-06,
      "loss": 2.2477,
      "step": 7
    },
    {
      "epoch": 0.0005299417064122947,
      "grad_norm": 1.7575595378875732,
      "learning_rate": 9.99909372761763e-06,
      "loss": 2.3024,
      "step": 8
    },
    {
      "epoch": 0.0005961844197138314,
      "grad_norm": 1.8188523054122925,
      "learning_rate": 9.998388886954546e-06,
      "loss": 2.4029,
      "step": 9
    },
    {
      "epoch": 0.0006624271330153683,
      "grad_norm": 1.6331565380096436,
      "learning_rate": 9.997482711915926e-06,
      "loss": 2.1143,
      "step": 10
    },
    {
      "epoch": 0.0007286698463169052,
      "grad_norm": 1.5510722398757935,
      "learning_rate": 9.99637523900237e-06,
      "loss": 2.3329,
      "step": 11
    },
    {
      "epoch": 0.000794912559618442,
      "grad_norm": 1.6957931518554688,
      "learning_rate": 9.99506651282272e-06,
      "loss": 2.6105,
      "step": 12
    },
    {
      "epoch": 0.0008611552729199788,
      "grad_norm": 2.3896260261535645,
      "learning_rate": 9.993556586092281e-06,
      "loss": 2.6349,
      "step": 13
    },
    {
      "epoch": 0.0009273979862215156,
      "grad_norm": 1.757253646850586,
      "learning_rate": 9.991845519630679e-06,
      "loss": 2.3271,
      "step": 14
    },
    {
      "epoch": 0.0009936406995230524,
      "grad_norm": 2.1633245944976807,
      "learning_rate": 9.989933382359423e-06,
      "loss": 2.3101,
      "step": 15
    },
    {
      "epoch": 0.0010598834128245894,
      "grad_norm": 2.205782890319824,
      "learning_rate": 9.987820251299121e-06,
      "loss": 2.4668,
      "step": 16
    },
    {
      "epoch": 0.0011261261261261261,
      "grad_norm": 1.5421119928359985,
      "learning_rate": 9.985506211566388e-06,
      "loss": 2.0993,
      "step": 17
    },
    {
      "epoch": 0.0011923688394276629,
      "grad_norm": 1.7906676530838013,
      "learning_rate": 9.982991356370404e-06,
      "loss": 2.3551,
      "step": 18
    },
    {
      "epoch": 0.0012586115527291998,
      "grad_norm": 1.837649941444397,
      "learning_rate": 9.98027578700917e-06,
      "loss": 2.3151,
      "step": 19
    },
    {
      "epoch": 0.0013248542660307366,
      "grad_norm": 1.637629508972168,
      "learning_rate": 9.977359612865424e-06,
      "loss": 2.2879,
      "step": 20
    },
    {
      "epoch": 0.0013910969793322733,
      "grad_norm": 1.7980852127075195,
      "learning_rate": 9.974242951402236e-06,
      "loss": 2.5938,
      "step": 21
    },
    {
      "epoch": 0.0014573396926338103,
      "grad_norm": 1.7411590814590454,
      "learning_rate": 9.970925928158275e-06,
      "loss": 2.2452,
      "step": 22
    },
    {
      "epoch": 0.001523582405935347,
      "grad_norm": 1.6808277368545532,
      "learning_rate": 9.96740867674275e-06,
      "loss": 2.3103,
      "step": 23
    },
    {
      "epoch": 0.001589825119236884,
      "grad_norm": 2.1479289531707764,
      "learning_rate": 9.963691338830045e-06,
      "loss": 2.3415,
      "step": 24
    },
    {
      "epoch": 0.0016560678325384208,
      "grad_norm": 1.5850452184677124,
      "learning_rate": 9.959774064153977e-06,
      "loss": 2.3253,
      "step": 25
    },
    {
      "epoch": 0.0017223105458399576,
      "grad_norm": 1.8357270956039429,
      "learning_rate": 9.955657010501807e-06,
      "loss": 2.2932,
      "step": 26
    },
    {
      "epoch": 0.0017885532591414945,
      "grad_norm": 1.5581058263778687,
      "learning_rate": 9.951340343707852e-06,
      "loss": 2.3806,
      "step": 27
    },
    {
      "epoch": 0.0018547959724430313,
      "grad_norm": 1.7851380109786987,
      "learning_rate": 9.946824237646823e-06,
      "loss": 2.2936,
      "step": 28
    },
    {
      "epoch": 0.001921038685744568,
      "grad_norm": 1.8013297319412231,
      "learning_rate": 9.942108874226812e-06,
      "loss": 2.4386,
      "step": 29
    },
    {
      "epoch": 0.001987281399046105,
      "grad_norm": 1.7864208221435547,
      "learning_rate": 9.937194443381972e-06,
      "loss": 2.3718,
      "step": 30
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1968451576012800.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
