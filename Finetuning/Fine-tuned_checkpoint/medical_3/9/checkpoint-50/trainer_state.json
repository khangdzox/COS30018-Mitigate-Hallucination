{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.001406341192436697,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 2.812682384873394e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.0254,
      "step": 1
    },
    {
      "epoch": 5.625364769746788e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.223,
      "step": 2
    },
    {
      "epoch": 8.438047154620183e-05,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.0024,
      "step": 3
    },
    {
      "epoch": 0.00011250729539493576,
      "grad_norm": 3.654651403427124,
      "learning_rate": 5e-05,
      "loss": 1.9965,
      "step": 4
    },
    {
      "epoch": 0.0001406341192436697,
      "grad_norm": 3.6641311645507812,
      "learning_rate": 0.0001,
      "loss": 2.1662,
      "step": 5
    },
    {
      "epoch": 0.00016876094309240365,
      "grad_norm": 3.2276928424835205,
      "learning_rate": 0.00015000000000000001,
      "loss": 1.9662,
      "step": 6
    },
    {
      "epoch": 0.00019688776694113758,
      "grad_norm": NaN,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.1661,
      "step": 7
    },
    {
      "epoch": 0.00022501459078987153,
      "grad_norm": NaN,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.1241,
      "step": 8
    },
    {
      "epoch": 0.0002531414146386055,
      "grad_norm": 10.818883895874023,
      "learning_rate": 0.0002,
      "loss": 1.9864,
      "step": 9
    },
    {
      "epoch": 0.0002812682384873394,
      "grad_norm": 11.954747200012207,
      "learning_rate": 0.00019995608365087946,
      "loss": 1.8603,
      "step": 10
    },
    {
      "epoch": 0.00030939506233607333,
      "grad_norm": 3.2824769020080566,
      "learning_rate": 0.00019982437317643217,
      "loss": 2.1121,
      "step": 11
    },
    {
      "epoch": 0.0003375218861848073,
      "grad_norm": 4.427638053894043,
      "learning_rate": 0.0001996049842615217,
      "loss": 2.0901,
      "step": 12
    },
    {
      "epoch": 0.00036564871003354123,
      "grad_norm": 3.9151391983032227,
      "learning_rate": 0.00019929810960135172,
      "loss": 2.0915,
      "step": 13
    },
    {
      "epoch": 0.00039377553388227516,
      "grad_norm": 12.364457130432129,
      "learning_rate": 0.0001989040187322164,
      "loss": 1.8896,
      "step": 14
    },
    {
      "epoch": 0.00042190235773100914,
      "grad_norm": 7.549314022064209,
      "learning_rate": 0.00019842305779475968,
      "loss": 1.918,
      "step": 15
    },
    {
      "epoch": 0.00045002918157974306,
      "grad_norm": 5.297351360321045,
      "learning_rate": 0.0001978556492299504,
      "loss": 1.6217,
      "step": 16
    },
    {
      "epoch": 0.000478156005428477,
      "grad_norm": 7.524197101593018,
      "learning_rate": 0.0001972022914080411,
      "loss": 1.4384,
      "step": 17
    },
    {
      "epoch": 0.000506282829277211,
      "grad_norm": 6.697389602661133,
      "learning_rate": 0.00019646355819083589,
      "loss": 1.5114,
      "step": 18
    },
    {
      "epoch": 0.0005344096531259448,
      "grad_norm": 8.727527618408203,
      "learning_rate": 0.00019564009842765225,
      "loss": 1.5357,
      "step": 19
    },
    {
      "epoch": 0.0005625364769746788,
      "grad_norm": 8.415966987609863,
      "learning_rate": 0.00019473263538541914,
      "loss": 1.3856,
      "step": 20
    },
    {
      "epoch": 0.0005906633008234128,
      "grad_norm": 5.968404293060303,
      "learning_rate": 0.0001937419661134121,
      "loss": 1.578,
      "step": 21
    },
    {
      "epoch": 0.0006187901246721467,
      "grad_norm": 8.259222984313965,
      "learning_rate": 0.00019266896074318334,
      "loss": 1.3338,
      "step": 22
    },
    {
      "epoch": 0.0006469169485208806,
      "grad_norm": 5.222049236297607,
      "learning_rate": 0.00019151456172430183,
      "loss": 1.4854,
      "step": 23
    },
    {
      "epoch": 0.0006750437723696146,
      "grad_norm": NaN,
      "learning_rate": 0.00019151456172430183,
      "loss": 1.2849,
      "step": 24
    },
    {
      "epoch": 0.0007031705962183485,
      "grad_norm": 15.122504234313965,
      "learning_rate": 0.00019027978299657436,
      "loss": 1.1947,
      "step": 25
    },
    {
      "epoch": 0.0007312974200670825,
      "grad_norm": NaN,
      "learning_rate": 0.00019027978299657436,
      "loss": 1.1825,
      "step": 26
    },
    {
      "epoch": 0.0007594242439158164,
      "grad_norm": 20.06264305114746,
      "learning_rate": 0.00018896570909947475,
      "loss": 1.2343,
      "step": 27
    },
    {
      "epoch": 0.0007875510677645503,
      "grad_norm": 6.780210018157959,
      "learning_rate": 0.0001875734942195637,
      "loss": 1.4598,
      "step": 28
    },
    {
      "epoch": 0.0008156778916132843,
      "grad_norm": 6.455131530761719,
      "learning_rate": 0.00018610436117673555,
      "loss": 1.1281,
      "step": 29
    },
    {
      "epoch": 0.0008438047154620183,
      "grad_norm": 9.58215045928955,
      "learning_rate": 0.0001845596003501826,
      "loss": 1.2539,
      "step": 30
    },
    {
      "epoch": 0.0008719315393107521,
      "grad_norm": 12.492953300476074,
      "learning_rate": 0.0001829405685450202,
      "loss": 1.0143,
      "step": 31
    },
    {
      "epoch": 0.0009000583631594861,
      "grad_norm": 7.704143524169922,
      "learning_rate": 0.00018124868780056814,
      "loss": 1.113,
      "step": 32
    },
    {
      "epoch": 0.0009281851870082201,
      "grad_norm": 8.959294319152832,
      "learning_rate": 0.00017948544414133534,
      "loss": 0.9169,
      "step": 33
    },
    {
      "epoch": 0.000956312010856954,
      "grad_norm": 5.029088020324707,
      "learning_rate": 0.00017765238627180424,
      "loss": 1.0252,
      "step": 34
    },
    {
      "epoch": 0.000984438834705688,
      "grad_norm": 4.212282657623291,
      "learning_rate": 0.00017575112421616202,
      "loss": 0.8273,
      "step": 35
    },
    {
      "epoch": 0.001012565658554422,
      "grad_norm": 5.32023811340332,
      "learning_rate": 0.00017378332790417273,
      "loss": 1.0426,
      "step": 36
    },
    {
      "epoch": 0.0010406924824031558,
      "grad_norm": 4.346127510070801,
      "learning_rate": 0.00017175072570443312,
      "loss": 0.7946,
      "step": 37
    },
    {
      "epoch": 0.0010688193062518897,
      "grad_norm": 3.9074459075927734,
      "learning_rate": 0.00016965510290629972,
      "loss": 0.7257,
      "step": 38
    },
    {
      "epoch": 0.0010969461301006238,
      "grad_norm": 5.523314952850342,
      "learning_rate": 0.00016749830015182107,
      "loss": 1.0399,
      "step": 39
    },
    {
      "epoch": 0.0011250729539493576,
      "grad_norm": 4.062892436981201,
      "learning_rate": 0.00016528221181905217,
      "loss": 0.6263,
      "step": 40
    },
    {
      "epoch": 0.0011531997777980915,
      "grad_norm": 4.3087477684021,
      "learning_rate": 0.00016300878435817113,
      "loss": 0.7997,
      "step": 41
    },
    {
      "epoch": 0.0011813266016468256,
      "grad_norm": 5.401496410369873,
      "learning_rate": 0.00016068001458185936,
      "loss": 0.7198,
      "step": 42
    },
    {
      "epoch": 0.0012094534254955594,
      "grad_norm": 5.085467338562012,
      "learning_rate": 0.0001582979479114472,
      "loss": 0.9201,
      "step": 43
    },
    {
      "epoch": 0.0012375802493442933,
      "grad_norm": 4.158808708190918,
      "learning_rate": 0.00015586467658036524,
      "loss": 0.765,
      "step": 44
    },
    {
      "epoch": 0.0012657070731930274,
      "grad_norm": 8.265695571899414,
      "learning_rate": 0.0001533823377964791,
      "loss": 0.8403,
      "step": 45
    },
    {
      "epoch": 0.0012938338970417613,
      "grad_norm": 3.6827871799468994,
      "learning_rate": 0.00015085311186492206,
      "loss": 0.6203,
      "step": 46
    },
    {
      "epoch": 0.0013219607208904951,
      "grad_norm": 3.263596296310425,
      "learning_rate": 0.00014827922027307451,
      "loss": 0.443,
      "step": 47
    },
    {
      "epoch": 0.0013500875447392292,
      "grad_norm": 6.194045066833496,
      "learning_rate": 0.0001456629237393713,
      "loss": 0.774,
      "step": 48
    },
    {
      "epoch": 0.001378214368587963,
      "grad_norm": 5.791253089904785,
      "learning_rate": 0.00014300652022765207,
      "loss": 0.6214,
      "step": 49
    },
    {
      "epoch": 0.001406341192436697,
      "grad_norm": 3.9798855781555176,
      "learning_rate": 0.00014031234292879725,
      "loss": 0.5447,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1891906059878400.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
