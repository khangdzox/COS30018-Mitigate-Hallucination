{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "H4fCxKQJ_No-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from textwrap import dedent\n",
        "from typing import Dict, List\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.colors as colors\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from colored import Back, Fore, Style\n",
        "from datasets import Dataset, load_dataset\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftModel,\n",
        "    TaskType,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        "    PeftConfig\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk import word_tokenize\n",
        "from rouge import rouge\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "COLORS = [\"#bae1ff\", \"#ffb3ba\", \"#ffdfba\", \"#ffffba\", \"#baffc9\"]\n",
        "\n",
        "sns.set( style = \"whitegrid\", palette = \"muted\", font_scale = 1.2 )\n",
        "sns.set_palette(sns.color_palette(COLORS))\n",
        "\n",
        "cmap = colors.LinearSegmentedColormap.from_list(\"custom_cmap\", COLORS[:2])\n",
        "\n",
        "MY_STYLE = {\n",
        "    \"figure.facecolor\": \"black\",\n",
        "    \"axes.facecolor\": \"black\",\n",
        "    \"axes.edgecolor\": \"white\",\n",
        "    \"axes.labelcolor\": \"white\",\n",
        "    \"text.color\": \"white\",\n",
        "    \"axes.linewidth\": 0.5,\n",
        "    \"xtick.color\": \"white\",\n",
        "    \"ytick.color\": \"white\",\n",
        "    \"grid.color\": \"gray\",\n",
        "    \"grid.linestyle\": \"--\",\n",
        "    \"grid.linewidth\":  0.5,\n",
        "    \"axes.grid\": True,\n",
        "    \"xtick.labelsize\": \"medium\",\n",
        "    \"ytick.labelsize\": \"medium\",\n",
        "    \"axes.titlesize\": \"large\",\n",
        "    \"axes.labelsize\": \"large\",\n",
        "    \"lines.color\": COLORS[0],\n",
        "    \"patch.edgecolor\": \"white\",\n",
        "}\n",
        "\n",
        "mpl.rcParams.update( MY_STYLE )\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)"
      ],
      "metadata": {
        "id": "4Jf1x_85vHE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Trained Model**"
      ],
      "metadata": {
        "id": "y7d0EVN4_J-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/khangdzox/COS30018-Mitigate-Hallucination.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7AWr6ts_NcGY",
        "outputId": "f712e17b-a083-4ff5-b944-011180001b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COS30018-Mitigate-Hallucination'...\n",
            "remote: Enumerating objects: 5437, done.\u001b[K\n",
            "remote: Counting objects: 100% (375/375), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(SEED)\n",
        "PAD_TOKEN = \"<|pad|>\"\n",
        "TMODEL_NAME = \"COS30018-Mitigate-Hallucination/Finetuning/QLoRA/6\"\n",
        "NEW_MODEL = \"Llama-3-8B-Project\""
      ],
      "metadata": {
        "id": "--ZwzKMiUit4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "base_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "reg8eOiOwKMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(base_model, TMODEL_NAME, device_map = \"cuda\", torch_dtype = torch.bfloat16)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)"
      ],
      "metadata": {
        "id": "e-wCWJiMa_v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Google Drive"
      ],
      "metadata": {
        "id": "nuMmZuBEUqFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6RJs1bSNNC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# # Replace 'your_zip_file_path' with the path to your zip file in Google Drive\n",
        "# zip_path = '/content/drive/MyDrive/5.zip'\n",
        "# extract_path = '/content/extracted_files'\n",
        "\n",
        "# # Create the directory if it doesn't exist\n",
        "# os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# # Extract the zip file\n",
        "# zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
        "# zip_ref.extractall(extract_path)\n",
        "# zip_ref.close()\n",
        "\n",
        "# # Verify the files are extracted\n",
        "# print(os.listdir(extract_path))"
      ],
      "metadata": {
        "id": "kvThuZ8RNJdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed_everything(SEED)\n",
        "# PAD_TOKEN = \"<|pad|>\"\n",
        "# TMODEL_PATH = \"/content/extracted_files/5\"  # Update this with your model path\n",
        "# NEW_MODEL = \"Llama-3-8B-Project\""
      ],
      "metadata": {
        "id": "mS301quuNK47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "# base_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
        "\n",
        "# model = PeftModel.from_pretrained(base_model, TMODEL_PATH, device_map=\"cuda\", torch_dtype=torch.bfloat16)\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "# tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n",
        "# tokenizer.padding_side = \"right\"\n",
        "\n",
        "# model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)"
      ],
      "metadata": {
        "id": "VaSyf_fONM0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Preprocessing**"
      ],
      "metadata": {
        "id": "IE_Z-ODr-_Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"PatronusAI/HaluBench\")"
      ],
      "metadata": {
        "id": "1VpSSDzWzsgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"test\"][:2]"
      ],
      "metadata": {
        "id": "3wFIqlc00wgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for i in dataset[\"test\"]:\n",
        "    if isinstance(i[\"answer\"], list):\n",
        "        correct_answers = \"; \".join(i[\"answer\"])\n",
        "    else:\n",
        "        correct_answers = str(i[\"answer\"])\n",
        "\n",
        "    rows.append(\n",
        "        {\n",
        "            \"question\": i[\"question\"],\n",
        "            \"context\": i['passage'],\n",
        "            \"correct_answers\": correct_answers,\n",
        "            \"label\": i[\"label\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "df = pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "u0OWbde4qmmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "2p54iEZs11Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().value_counts())\n",
        "fail_count = df['label'].value_counts().get('FAIL', 0)\n",
        "\n",
        "print(f\"Number of 'FAIL' occurrences: {fail_count}\")"
      ],
      "metadata": {
        "id": "v5c0MU_c4rNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(row: dict):\n",
        "    prompt = dedent(\n",
        "        f\"\"\"\n",
        "        ### Instruction:\n",
        "        {row[\"context\"]}\n",
        "\n",
        "        ### Input:\n",
        "        {row[\"question\"]}\n",
        "\n",
        "        ### Response:\n",
        "        {row[\"correct_answers\"]}\n",
        "\n",
        "        ### Evaluation:\n",
        "        \"\"\"\n",
        "    )\n",
        "    messages = (\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Read the passage and evaluate if the provided answer is correct. Respond with 'PASS' if the answer is correct and 'FAIL' if the answer is incorrect.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        },\n",
        "    )\n",
        "    return tokenizer.apply_chat_template(messages, tokenize=False)"
      ],
      "metadata": {
        "id": "fmyOn2kj41uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df.apply(format_example, axis=1)"
      ],
      "metadata": {
        "id": "F-7jrZDC5fvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(row: dict)->int:\n",
        "    return len(\n",
        "        tokenizer(\n",
        "            row[\"text\"],\n",
        "            add_special_tokens=True,\n",
        "            return_attention_mask=False,\n",
        "            )[\"input_ids\"]\n",
        "        )"
      ],
      "metadata": {
        "id": "oDIfeBjhq1Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
      ],
      "metadata": {
        "id": "JV5ik7Kg5-3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Lfd6heO36C72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.text.iloc[0])"
      ],
      "metadata": {
        "id": "_xz19AsG6e04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df.token_count, weights=np.ones(len(df.token_count)) / len(df.token_count))\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "plt.xlabel(\"Token count\")\n",
        "plt.ylabel(\"Percentage\")\n",
        "plt.title(\"Token count distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NRTVjG7M6sTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upper_bound = 1000\n",
        "lower_bound = 10"
      ],
      "metadata": {
        "id": "X6NPheGTYLNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[(df.token_count < upper_bound) & (df.token_count > lower_bound)]), len(df), len(df[(df.token_count < upper_bound)  & (df.token_count > lower_bound)]) / len(df)"
      ],
      "metadata": {
        "id": "T0csLP977L1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num = 500"
      ],
      "metadata": {
        "id": "kqbdCkXZaQha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[(df.token_count < upper_bound) & (df.token_count > lower_bound)]\n",
        "df = df.sample(total_num)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "tmQC-n8f8PIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, temp = train_test_split(df, test_size=0.2, random_state=SEED)\n",
        "# val, test = train_test_split(temp, test_size=0.2, random_state=SEED)"
      ],
      "metadata": {
        "id": "Bs7qHNL89sqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train) / len(df), len(val) / len(df), len(test) / len(df)"
      ],
      "metadata": {
        "id": "qCwxBHiB94MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train), len(val), len(test)"
      ],
      "metadata": {
        "id": "bpaBB8f4-BM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_num = 1500\n",
        "# val_num = 450\n",
        "# test_num = 100"
      ],
      "metadata": {
        "id": "LVrW4qH_aTuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.sample(n=train_num).to_json(\"train.json\", orient=\"records\", lines=True)\n",
        "# val.sample(n=val_num).to_json(\"val.json\", orient=\"records\", lines=True)\n",
        "# test.sample(n=test_num).to_json(\"test.json\", orient=\"records\", lines=True)"
      ],
      "metadata": {
        "id": "LC59jZaS-EF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = load_dataset(\n",
        "#     \"json\",\n",
        "#     data_files={\n",
        "#         \"train\": \"train.json\",\n",
        "#         \"validation\": \"val.json\",\n",
        "#         \"test\": \"test.json\"\n",
        "#         }\n",
        "#     )"
      ],
      "metadata": {
        "id": "9C2vU9fh-WnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = df.sample(n=total_num)"
      ],
      "metadata": {
        "id": "PHYo2XOn8oIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.to_json(\"test.json\", orient=\"records\", lines=True)"
      ],
      "metadata": {
        "id": "9a1TAvFE8apo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\n",
        "        \"test\": \"test.json\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "TfZV4F7f5X-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "mVSuNXSN-iQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"test\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "3C3-ON-a-pXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test Base Model**"
      ],
      "metadata": {
        "id": "y-nJ1IRS-0W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens = 128,\n",
        "    return_full_text = False,\n",
        ")"
      ],
      "metadata": {
        "id": "jCv04xk7-tnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_prompt(data_row):\n",
        "    prompt = dedent(\n",
        "        f\"\"\"\n",
        "        ### Instruction:\n",
        "        {data_row[\"context\"]}\n",
        "\n",
        "        ### Input:\n",
        "        {data_row[\"question\"]}\n",
        "\n",
        "        ### Provided answer:\n",
        "        {data_row[\"correct_answers\"]}\n",
        "\n",
        "        ### Response:\n",
        "        \"\"\"\n",
        "    )\n",
        "    messages = (\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Read the context and evaluate if the provided answer is correct. Respond with 'PASS' if the answer is correct and 'FAIL' if the answer is incorrect.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        },\n",
        "    )\n",
        "    return tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False\n",
        "    )"
      ],
      "metadata": {
        "id": "go0HPeRx_opz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = dataset[\"test\"][0]\n",
        "prompt = create_test_prompt(row)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "PVxYseaxA_8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "output = pipe(prompt)\n",
        "response = f\"\"\"\n",
        "answer: {row[\"label\"]}\n",
        "prediction: {output[0][\"generated_text\"]}\n",
        "\"\"\"\n",
        "print(response)"
      ],
      "metadata": {
        "id": "4nM-sfzWBFMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = dataset[\"test\"][1]\n",
        "prompt = create_test_prompt(row)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "iZF_bg1sBnUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "output = pipe(prompt)\n",
        "response = f\"\"\"\n",
        "answer: {row[\"label\"]}\n",
        "prediction: {output[0][\"generated_text\"]}\n",
        "\"\"\"\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7RLDCQbrBuMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = dataset[\"test\"][2]\n",
        "prompt = create_test_prompt(row)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "7hIT7QhCCLWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "output = pipe(prompt)\n",
        "response = f\"\"\"\n",
        "answer: {row[\"label\"]}\n",
        "prediction: {output[0][\"generated_text\"]}\n",
        "\"\"\"\n",
        "print(response)"
      ],
      "metadata": {
        "id": "mMu-_EULCM9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(prediction, reference):\n",
        "    pred_words = set(word_tokenize(prediction))\n",
        "    ref_words = set(word_tokenize(reference))\n",
        "\n",
        "    common_words = pred_words.intersection(ref_words)\n",
        "\n",
        "    accuracy_pred = len(common_words) / len(pred_words) if pred_words else 0\n",
        "    accuracy_ref = len(common_words) / len(ref_words) if ref_words else 0\n",
        "\n",
        "    return accuracy_pred, accuracy_ref"
      ],
      "metadata": {
        "id": "d7LcTFraVKbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "import nltk\n",
        "rows = []\n",
        "rouge = Rouge()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "for row in tqdm(dataset[\"test\"]):\n",
        "    prompt = create_test_prompt(row)\n",
        "    output = pipe(prompt)\n",
        "    prediction = output[0][\"generated_text\"]\n",
        "    reference = row[\"label\"]\n",
        "\n",
        "    meteor = meteor_score([word_tokenize(reference)], word_tokenize(prediction), alpha=0.9, beta=3, gamma=0.5)\n",
        "\n",
        "    bleu = sentence_bleu([word_tokenize(reference)], word_tokenize(prediction))\n",
        "\n",
        "    rouge_scores = rouge.get_scores(prediction, reference, avg=True)\n",
        "\n",
        "    accuracy_pred, accuracy_ref = calculate_accuracy(prediction, reference)\n",
        "\n",
        "    rows.append(\n",
        "        {\n",
        "            \"question\": row[\"question\"],\n",
        "            \"context\": row[\"context\"],\n",
        "            \"answer\": reference,\n",
        "            \"prediction\": prediction,\n",
        "            \"meteor_score\": meteor,\n",
        "            \"bleu_score\": bleu,\n",
        "            \"rouge_1\": rouge_scores['rouge-1']['f'],\n",
        "            #\"rouge_2\": rouge_scores['rouge-2']['f'],\n",
        "            \"rouge_l\": rouge_scores['rouge-l']['f'],\n",
        "            \"Accuracy_pred\": accuracy_pred,\n",
        "            \"Accuracy_ref\": accuracy_ref,\n",
        "            \"Token_count\": row[\"token_count\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "predictions_df = pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "kles8gQx_8-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('base_eval.csv', index=False)"
      ],
      "metadata": {
        "id": "D0Oo2i2ZZ_6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}